{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d89fae",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<span style=\"color:#C1D3FE;font-size: 32px; font-weight: bold;\">Notebook de Treinamento de Machine Learning: \"Originadora e StartCard\" de 05/08</span>\n",
    "<br> <span style=\"color:#FFD1DC;\"> Feito por Lucas Andrade entre 21 e 22 de Agosto de 2025 </span>\n",
    "<br> <span style=\"color:#FFF5BA;\"> a ser revisado por Felipe Bastos\n",
    "\n",
    "<br>\n",
    "<span style=\"color:#C1D3FE;\">Lucas Rafael de Andrade Desenvolvimento de Software Ltda (59.088.726/0001-70)</span>\n",
    "\n",
    "<span style=\"color:#C1D3FE;\">Solicitado por Porto Real Asset</span>\n",
    "\n",
    "\n",
    "Observação: esse notebook traz como features para o modelo as seguintes séries: \n",
    "Esfera do convênio,\n",
    "Faixa população,\n",
    "CAPAG,\n",
    "Muitos contratos,\n",
    "Tipo de produto,\n",
    "Tipo de empregado,\n",
    "Faixa de Idade,\n",
    "Total de parcelas,\n",
    "Valor da parcela\n",
    "\n",
    "Falta incluir: \n",
    "Dados econômicos (como PIB e População)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f65004",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c50bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "VERSãO: FALTANDO COLOCAR DADOS COMO POPULAçÂO E PIB PER CAPITA\n",
    "\"\"\"\n",
    "#* baza >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "#* modeloj <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "#* Metriko >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "#* Antaŭprilaborado <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#! CUIDADO! Isso pode ser útil )))))))))))))))))))))))))))))))\n",
    "warnings.filterwarnings('ignore')\n",
    "#! )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fcabc4",
   "metadata": {},
   "source": [
    "### Função de Carregamento dos dados e preparação \n",
    "retorna um df com  as features, já"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933aada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "#  FUNÇÂO:\n",
    "#  CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
    "# =============================================================================\n",
    "def carregar_e_preparar_dados_corrigido():\n",
    "    \"\"\"\n",
    "    por enquanto lê só  StarCard.xlsx e Originadores.xlsx\n",
    "     Uso 'Data de Inclusão' para ordenar o seguinte\n",
    "        - duplicacoes de ccb\n",
    "        - _MuitosContratos c/ cum Count (para evitrar leak)\n",
    "        - Idade calculada na Data de Inclusão (fallback em DataGeracao se der m)\n",
    "    Crio labels 'Vencido_{1,30,60,90}d' \n",
    "    \"\"\"\n",
    "    print(\"=\"*88)\n",
    "    print(\"ETAPA 1: Carregando e preparando os dados (VERSÃO FINAL)...\")\n",
    "    print(\"=\"*88)\n",
    "\n",
    "    #! PATHS ----------------------------------------------------------------------\n",
    "    #! COLOQUE CORRETAMENTe na maquina \n",
    "    path_starcard = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\StarCard.xlsx'\n",
    "    path_originadores = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\Originadores.xlsx'\n",
    "    #!------------------------------------------------------------------------------\n",
    "\n",
    "    #******************   Leitura       *************************************************\n",
    "    df_starcard = pd.read_excel(path_starcard)\n",
    "    cols_originadores = ['CCB', 'Data de Inclusão', 'Prazo', 'Valor Parcela', 'Produto', 'Convênio', 'CAPAG']\n",
    "    # CAPAG pode não existir; vamos ler com try simples\n",
    "    try:\n",
    "        df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "    except ValueError:\n",
    "        # <deprec> debug do AC\n",
    "\n",
    "        print(\"[ALERTA] Coluna 'CAPAG' não encontrada em Originadores.xlsx. Esta feature será desconsiderada no modelo.\")\n",
    "        cols_originadores = [c for c in cols_originadores if c != 'CAPAG']\n",
    "        df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "\n",
    "    #* Normalizo garantindo que vai pegar por inlcusao na ordem\n",
    "    if 'Data de Inclusão' in df_originadores.columns:\n",
    "        df_originadores['Data de Inclusão'] = pd.to_datetime(df_originadores['Data de Inclusão'], errors='coerce')\n",
    "        df_originadores = (\n",
    "            df_originadores\n",
    "            .sort_values(['CCB', 'Data de Inclusão'])\n",
    "            .drop_duplicates(subset='CCB', keep='first')\n",
    "        )\n",
    "    \"\"\"faco isso para que ele pegue de forma deterinística a mesma versao da ccb\"\"\"\n",
    "\n",
    "    #* Merge: \n",
    "    #* note que o startcard repete os ccbs em varias linhas e originadores tem apenas uma lina por ccb \n",
    "    df_merged = pd.merge(df_starcard, df_originadores, on='CCB', how='left', suffixes=('', '_orig'))\n",
    "\n",
    "   \n",
    "    df_merged = df_merged.rename(columns={  # Renomeios #*(para ser compatível com fct_consig- outros dados)\n",
    "        'Data Referencia': 'DataGeracao',\n",
    "        'Data Vencimento': 'DataVencimento',\n",
    "        'ID Cliente': 'SacadoID'\n",
    "    }) \n",
    "    #?----------------------------------------------------------------\n",
    "    for col in ['DataGeracao', 'DataVencimento', 'Data de Nascimento']:\n",
    "        if col in df_merged.columns:\n",
    "            df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')     # Tipos de data\n",
    "    #?----------------------------------------------------------------\n",
    "    # Conversão  #? sim, é necessário #----------------------------------------------------------------\n",
    "    if 'Valor Parcela' in df_merged.columns and df_merged['Valor Parcela'].dtype == 'object':\n",
    "        s = df_merged['Valor Parcela'].astype(str)\n",
    "        s = s.str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()\n",
    "        df_merged['Valor Parcela'] = pd.to_numeric(s, errors='coerce')\n",
    "    #?----------------------------------------------------------------\n",
    "    df_base = df_merged.copy() # agora vamos usar esse df\n",
    "    # cleanup da memoria\n",
    "    del df_starcard, df_originadores, df_merged\n",
    "    #?----------------------------------------------------------------\n",
    "    # Limpezas básicas\n",
    "    if 'Produto' in df_base.columns:\n",
    "        df_base['Produto'] = df_base['Produto'].fillna('')\n",
    "    if 'Convênio' in df_base.columns:\n",
    "        df_base['Convênio'] = df_base['Convênio'].fillna('')\n",
    "    #?----------------------------------------------------------------\n",
    "    # feat dias_de_atraso\n",
    "    if 'DataGeracao' in df_base.columns and 'DataVencimento' in df_base.columns:\n",
    "        df_base['dias_de_atraso'] = (df_base['DataGeracao'] - df_base['DataVencimento']).dt.days\n",
    "    #?----------------------------------------------------------------\n",
    "    # buckets de produto/empregado/convênio\n",
    "    condicoes_produto = [\n",
    "        df_base['Produto'].str.contains('Empréstimo', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Cartão RMC', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Cartão Benefício', case=False, na=False)\n",
    "    ]\n",
    "    opcoes_produto = ['Empréstimo', 'Cartão RMC', 'Cartão Benefício']\n",
    "    df_base['_TipoProduto'] = np.select(condicoes_produto, opcoes_produto, default='Outros')\n",
    "    \"\"\"Agrupar em buckets transforma informação\n",
    "    não estruturada em features úteis e reduz a complexidade \n",
    "    para os modelos\"\"\"\n",
    "\n",
    "    #?----------------------------------------------------------------\n",
    "    condicoes_empregado = [\n",
    "        df_base['Produto'].str.contains('Efetivo|Efetivio', case=False, na=False, regex=True),\n",
    "        df_base['Produto'].str.contains('Temporário', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('CONTRATADO', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Comissionado', case=False, na=False)\n",
    "    ]\n",
    "    opcoes_empregado = ['Efetivo', 'Temporário', 'Contratado', 'Comissionado']\n",
    "    df_base['_TipoEmpregado'] = np.select(condicoes_empregado, opcoes_empregado, default='Outros')\n",
    "    #?----------------------------------------------------------------\n",
    "    # Rgx do convênio\n",
    "    condicoes_convenio = [\n",
    "        df_base['Convênio'].str.contains(r'GOV\\.|AGN -', case=False, na=False, regex=True),\n",
    "        df_base['Convênio'].str.contains(r'PREF\\.|PRERF', case=False, na=False, regex=True)\n",
    "    ] #* note que eu ajustei para o typo que observei empiricamente em pref\n",
    "    opcoes_convenio = ['Estadual', 'Municipal']\n",
    "    df_base['_EsferaConvenio'] = np.select(condicoes_convenio, opcoes_convenio, default='Outros')\n",
    "\n",
    "    # ----- Data de Inclusão -----\n",
    "    \"\"\"\n",
    "    explicação do que eu fiz abaixo: \n",
    "    tentei evitar vazamento de dados do futuro. \n",
    "    A feature _MuitosContratos reflete o histórico\n",
    "    do cliente até este momento, e nao o total de contratos\n",
    "    q ele viria a ter. \n",
    "    Da mesma forma, \n",
    "    a idade é a que ele tinha quando assinou o contrato,\n",
    "     que eh a informação que estaria disponivel \n",
    "     para uma analise de credito na época.\"\"\"\n",
    "    if 'Data de Inclusão' not in df_base.columns:\n",
    "        raise ValueError(\"Coluna 'Data de Inclusão' não encontrada após o merge. Verifique Originadores.xlsx.\")\n",
    "    #?----------------------------------------------------------------\n",
    "    # ordeno por inclusão para _MuitosContratos\n",
    "    df_base = df_base.sort_values(['SacadoID', 'Data de Inclusão', 'CCB'])\n",
    "    df_base['_NumContratosAnteriores'] = df_base.groupby('SacadoID').cumcount()\n",
    "    df_base['_MuitosContratos'] = (df_base['_NumContratosAnteriores'] >= 2).astype(int)\n",
    "    #?----------------------------------------------------------------\n",
    "    # Idade na Data de Inclusão \n",
    "    # (fallback em DataGeracao, caso desse errado)\n",
    "    if 'Data de Nascimento' in df_base.columns:\n",
    "        base_idade = df_base['Data de Inclusão'].fillna(df_base.get('DataGeracao'))\n",
    "        df_base['_IdadeCliente'] = (base_idade - df_base['Data de Nascimento']).dt.days / 365.25\n",
    "        bins = [0, 37, 45, 53, 120]\n",
    "        labels = ['Até 37 anos', '38 a 45 anos', '46 a 53 anos', '54 anos ou mais']\n",
    "        df_base['_IdadesBins'] = pd.cut(df_base['_IdadeCliente'], bins=bins, labels=labels, right=True)\n",
    "    #? ---------- Labels por CCB ----------\n",
    "    #? Se tivesse múltiplas linhas por CCB (parcelas/linhas), agregaria o maior atraso\n",
    "    #? <deprec>\n",
    "    #if 'dias_de_atraso' not in df_base.columns:\n",
    "    #    raise ValueError(\"'dias_de_atraso' não foi criado. Verifique 'DataGeracao' e 'DataVencimento'.\")\n",
    "\n",
    "    \"\"\"explicação de abaixo: \n",
    "    o que eu faço é deixar a variável que eu quero prever como unequívoca \n",
    "    para ter como objetivo e ser explicada, para ter a mesma dimensionalidade entr\n",
    "    o contrato e o n de linhas \"\"\"\n",
    "    atraso_por_ccb = (\n",
    "        df_base.groupby('CCB', as_index=False)['dias_de_atraso'].max()\n",
    "        .rename(columns={'dias_de_atraso': 'max_dias_atraso'})\n",
    "    )\n",
    "    for k in [1, 30, 60, 90]:\n",
    "        atraso_por_ccb[f'Vencido_{k}d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= k).astype(int)\n",
    "\n",
    "    # snapshot pela ordem da nclusao\n",
    "    df_base['DataInclRef'] = df_base['Data de Inclusão'].fillna(df_base.get('DataGeracao'))\n",
    "    snapshots = df_base.sort_values(['CCB', 'DataInclRef', 'DataVencimento'])\n",
    "    primeiro_snap = snapshots.groupby('CCB', as_index=False).first()\n",
    "    #! ########################################################################################\n",
    "    #! #####################     IMPORTANTE     ###############################################\n",
    "    features_para_modelo = [\n",
    "        'CCB',  'CAPAG', 'Prazo', 'Valor Parcela', #'Convênio',   ## comente convênio se quisr remver\n",
    "        '_TipoProduto', '_TipoEmpregado', '_EsferaConvenio', '_IdadesBins', '_MuitosContratos'\n",
    "    ]\n",
    "    #! #########################################################################################\n",
    "    ausentes = sorted(list(set(features_para_modelo) - set(primeiro_snap.columns)))\n",
    "    if ausentes: # dbg AC\n",
    "        print(f\"[AVISO] Features ausentes e removidas (não encontradas no snapshot): {ausentes}\")\n",
    "\n",
    "    features_existentes = [f for f in features_para_modelo if f in primeiro_snap.columns]\n",
    "    df_features = primeiro_snap[features_existentes]\n",
    "\n",
    "    # df_ml final #? esse vai ser o df usado no modelo de ML, mesmo\n",
    "    df_ml = pd.merge(df_features, atraso_por_ccb, on='CCB', how='inner').rename(columns={\n",
    "        'Prazo': 'Total_Parcelas',\n",
    "        'Valor Parcela': 'Valor_Parcela',\n",
    "        '_EsferaConvenio': 'Esfera_Convenio',\n",
    "        '_IdadesBins': 'Faixa_Idade',\n",
    "        '_MuitosContratos': 'Muitos_Contratos',\n",
    "        '_TipoProduto': 'Tipo_Produto',\n",
    "        '_TipoEmpregado': 'Tipo_Empregado'\n",
    "    })\n",
    "\n",
    "    #? verificações básicas\n",
    "    #?assert df_ml['CCB'].is_unique, \"CCB não está único no df_ml! Revise o snapshot por CCB.\"\n",
    "    #?assert df_ml[['Vencido_1d_Flag','Vencido_30d_Flag','Vencido_60d_Flag','Vencido_90d_Flag']].notna().all().all(), \\\n",
    "    #?    \"Algum label Vencido_* está com NaN.\"\n",
    "    \n",
    "    print(f\"\\n <DBG> Dataset para ML criado com {df_ml.shape[0]} linhas (CCBs) e {df_ml.shape[1]} colunas.\")\n",
    "    return df_ml\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37aeea",
   "metadata": {},
   "source": [
    "### Função De Treino e Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbfbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# FUNÇÃO: \n",
    "#   TREINAMENTO E AVALIAÇÃO\n",
    "# =============================================================================\n",
    "def treinar_e_avaliar(df_ml):\n",
    "    targets = ['Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
    "    resultados_finais = pd.DataFrame()\n",
    "\n",
    "    for target in targets:\n",
    "        print(\"\\n\" + \"=\"*88)\n",
    "        print(f\"   TREINANDO MODELOS PARA O ALVO: {target}\")\n",
    "        print(\"=\"*88)\n",
    "        #?----------------------------------------------------------------    \n",
    "        # Def X e y  #?(OBS: Removo colunas desncessárias para o train)\n",
    "        X = df_ml.drop(columns=targets + ['CCB', 'max_dias_atraso'])\n",
    "        y = df_ml[target]\n",
    "        #?-----------------  tipos: -----------------------------------------------\n",
    "        numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "        categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        #?-------------------  split: ---------------------------------------------        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.30, random_state=42, stratify=y # OBS:  Split estratificado\n",
    "        )\n",
    "        \"\"\" note que é importante tentar fazer o split o mais rápido possível,\n",
    "        para trabalhar apenas com os padrões que ele pegar no conj de teste, para \n",
    "        garantir que nao tenha nenhuma contaminação \"\"\"\n",
    "\n",
    "        #?---------- torno Dummy (após o split para nao contaminar) ------------------------------------------------------\n",
    "        X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "        X_test  = pd.get_dummies(X_test,  columns=categorical_features, drop_first=True)\n",
    "        X_test  = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "        #?------------------- <debug> ---------------------------------------------\n",
    "        #print(\"#cols treino:\", X_train.shape[1], \"| #cols teste:\", X_test.shape[1])\n",
    "        #assert list(X_train.columns) == list(X_test.columns), \"Treino e teste desalinhados!\"\n",
    "        #?------------------ Imputação + Escalonamento  ----------------------------------------------\n",
    "        # só nas nas numéricas originais (interseção)\n",
    "        #* pelo que eu pesquisei o scalling não é necessário, mas vou deixar para se quiser \n",
    "        #* usar outros modelos, além de que para a reg logistica é útil \n",
    "        num_cols = [c for c in numerical_features if c in X_train.columns]\n",
    "        #? if len(num_cols) > 0: # idente abaixo para <bebug>\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        X_train[num_cols] = imputer.fit_transform(X_train[num_cols])\n",
    "        X_test[num_cols]  = imputer.transform(X_test[num_cols])\n",
    "        #?-----------------------\n",
    "        scaler = StandardScaler()\n",
    "        X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "        X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
    "\n",
    "        #?else:\n",
    "        #?    print(\"[INFO] Nenhuma coluna numérica foi identificada para imputação ou escalonamento.\")\n",
    "\n",
    "        # Log base rates # - coloco isso para estudar o balanceio\n",
    "        print(\"Base rate no treino:\", float(y_train.mean()).__round__(4), \"| no teste:\", float(y_test.mean()).__round__(4))\n",
    "        #?-----------------------------\n",
    "        # scale_pos_weight com guarda\n",
    "\n",
    "        \"\"\"\n",
    "        note que temos um debalanceio muito grande nesse tipo de porblema, fazendo \n",
    "        com que o treinamento fique viesado para um lado. \n",
    "        Isso aqui faz comm que ele de mais peso à classe minoritária\n",
    "        #? obs: o paralelo aqui é o de fraudes em cartão de crédito\n",
    "        \"\"\"\n",
    "        pos = int((y_train == 1).sum())\n",
    "        neg = int((y_train == 0).sum())\n",
    "        if pos == 0:\n",
    "            print(f\"[AVISO] Classe positiva ausente no treino para {target}. Ajustando scale_pos_weight=1.0.\")\n",
    "            scale_pos_weight = 1.0\n",
    "        else:\n",
    "            scale_pos_weight = neg / pos\n",
    "        #?---------------- ------------------------------------------------\n",
    "        #?---------------- MODELOS -----------------------------------------------\n",
    "        #! ####################################################################################################\n",
    "        models = {\n",
    "            \"Regressão Logística\": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
    "            \"Random Forest\":       RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "            \"SVM (Kernel RBF)\":    SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced'),\n",
    "            \"XGBoost\":             xgb.XGBClassifier(random_state=42, eval_metric='logloss',\n",
    "                                                      use_label_encoder=False, scale_pos_weight=scale_pos_weight,\n",
    "                                                      n_jobs=-1),\n",
    "            \"LightGBM\":            lgb.LGBMClassifier(random_state=42, scale_pos_weight=scale_pos_weight,\n",
    "                                                       n_jobs=-1)\n",
    "        }\n",
    "        #! ######################################################################################################\n",
    "\n",
    "        resultados_target = {}\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\n--- Treinando {name} ---\")\n",
    "            model.fit(X_train, y_train)\n",
    "            #?---------------- probabilidades -----------------------------------------------\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            #?----------------metricas -----------------------------------------------\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            ap  = average_precision_score(y_test, y_pred_proba)\n",
    "            resultados_target[name] = {'ROC-AUC': auc, 'PR-AUC(AP)': ap}\n",
    "            print(f\"ROC-AUC: {auc:.4f} | PR-AUC(AP): {ap:.4f}\")\n",
    "            #?---------------- IMPORTANCIAS -----------------------------------------------\n",
    "            \"\"\"note que o objetivo é explicar, entao isso é muito importante \n",
    "            o motivo de usar isso está nas referÊncias\"\"\"\n",
    "            if isinstance(model, xgb.XGBClassifier):\n",
    "                booster = model.get_booster()\n",
    "                imp = booster.get_score(importance_type='gain')\n",
    "                if len(imp) > 0:\n",
    "                    importances = (pd.Series(imp).sort_values(ascending=False).head(10)\n",
    "                                   .rename('Gain').reset_index().rename(columns={'index': 'Feature'}))\n",
    "                    print(\"Top 10 importâncias (XGB, gain):\")\n",
    "                    print(importances)\n",
    "            elif isinstance(model, lgb.LGBMClassifier):\n",
    "                feats = model.feature_name_\n",
    "                gains = model.booster_.feature_importance(importance_type='gain')\n",
    "                importances = (pd.DataFrame({'Feature': feats, 'Gain': gains})\n",
    "                               .sort_values('Gain', ascending=False).head(10))\n",
    "                print(\"Top 10 importâncias (LGBM, gain):\")\n",
    "                print(importances)\n",
    "            elif hasattr(model, 'feature_importances_'):\n",
    "                importances = pd.DataFrame({\n",
    "                    'Feature': X_train.columns,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values('Importance', ascending=False).head(10)\n",
    "                print(\"Top 10 importâncias:\")\n",
    "                print(importances)\n",
    "            elif isinstance(model, LogisticRegression):\n",
    "                # A comparação da magnitude destes coeficientes é válida porque \n",
    "                # as features numéricas foram escalonadas.\n",
    "                coefs = pd.Series(model.coef_[0], index=X_train.columns).sort_values(key=np.abs, ascending=False).head(10)\n",
    "                print(\"Top 10 |coef| (Regressão Logística):\")\n",
    "                print(coefs)\n",
    "\n",
    "        #? Acumula resultados por alvo\n",
    "        df_resultados_target = (pd.DataFrame(resultados_target).T)\n",
    "        #? guarda  ROC-AUC numa tabela comparativa \n",
    "\n",
    "        \n",
    "        resultados_finais = pd.concat([resultados_finais, df_resultados_target['ROC-AUC'].rename(target)], axis=1)\n",
    "\n",
    "        #? Checagens adicionais úteis\n",
    "        #?suspeitas = {'dias_de_atraso', 'max_dias_atraso', 'DataGeracao', 'DataVencimento', 'Data de Inclusão'}\n",
    "        #?suspeitas_presentes = sorted(list(set(X_train.columns) & suspeitas))\n",
    "        #?if suspeitas_presentes:\n",
    "        #?    print(f\"[ALERTA] Colunas suspeitas presentes em X: {suspeitas_presentes}\")\n",
    "\n",
    "    return resultados_finais\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39df0d7",
   "metadata": {},
   "source": [
    "### Execução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f7793",
   "metadata": {},
   "source": [
    "#### Ler dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbd31cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "ETAPA 1: Carregando e preparando os dados (VERSÃO FINAL)...\n",
      "========================================================================================\n",
      "\n",
      " <DBG> Dataset para ML criado com 6838 linhas (CCBs) e 14 colunas.\n",
      "\n",
      "Base rates dos alvos (df_ml):\n",
      "Vencido_1d_Flag     0.8157\n",
      "Vencido_30d_Flag    0.6897\n",
      "Vencido_60d_Flag    0.5294\n",
      "Vencido_90d_Flag    0.3353\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#! demorado (até 4m30s)\n",
    "df_ml = carregar_e_preparar_dados_corrigido()\n",
    "\n",
    "print(\"\\nBase rates dos alvos (df_ml):\") # ( relatório rápido de base rates por label)\n",
    "print(df_ml[['Vencido_1d_Flag','Vencido_30d_Flag','Vencido_60d_Flag','Vencido_90d_Flag']].mean().round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d231755",
   "metadata": {},
   "source": [
    "#### Treinar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de124251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TREINANDO MODELOS... AGUARDE (+-1 MIN)\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_1d_Flag\n",
      "========================================================================================\n",
      "Base rate no treino: 0.8157 | no teste: 0.8158\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.9112 | PR-AUC(AP): 0.9677\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Contratado   -4.139504\n",
      "Tipo_Empregado_Efetivo       3.322750\n",
      "Esfera_Convenio_Municipal   -2.938538\n",
      "Tipo_Empregado_Temporário    2.891798\n",
      "CAPAG_B                     -1.461829\n",
      "CAPAG_N.D.                  -1.403280\n",
      "Tipo_Produto_Empréstimo     -1.209099\n",
      "Tipo_Empregado_Outros        0.695386\n",
      "CAPAG_C                     -0.161676\n",
      "Tipo_Produto_Cartão RMC     -0.140456\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.9375 | PR-AUC(AP): 0.9807\n",
      "Top 10 importâncias:\n",
      "                      Feature  Importance\n",
      "1               Valor_Parcela    0.220520\n",
      "0              Total_Parcelas    0.207176\n",
      "8   Tipo_Empregado_Contratado    0.161193\n",
      "11  Tipo_Empregado_Temporário    0.124871\n",
      "12  Esfera_Convenio_Municipal    0.059075\n",
      "9      Tipo_Empregado_Efetivo    0.052638\n",
      "7     Tipo_Produto_Empréstimo    0.032088\n",
      "4                     CAPAG_C    0.027902\n",
      "5                  CAPAG_N.D.    0.022745\n",
      "2            Muitos_Contratos    0.021535\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.9116 | PR-AUC(AP): 0.9741\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.9337 | PR-AUC(AP): 0.9813\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                     Feature       Gain\n",
      "0  Tipo_Empregado_Contratado  26.427397\n",
      "1  Esfera_Convenio_Municipal  10.578958\n",
      "2     Tipo_Empregado_Efetivo   4.171108\n",
      "3             Total_Parcelas   2.856307\n",
      "4  Tipo_Empregado_Temporário   2.731068\n",
      "5                    CAPAG_B   1.649809\n",
      "6                 CAPAG_N.D.   0.978978\n",
      "7      Tipo_Empregado_Outros   0.961150\n",
      "8    Tipo_Produto_Cartão RMC   0.856992\n",
      "9    Tipo_Produto_Empréstimo   0.685501\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3904, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815712 -> initscore=1.487565\n",
      "[LightGBM] [Info] Start training from score 1.487565\n",
      "ROC-AUC: 0.9400 | PR-AUC(AP): 0.9827\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                      Feature         Gain\n",
      "0              Total_Parcelas  2650.982469\n",
      "8   Tipo_Empregado_Contratado  2614.302729\n",
      "1               Valor_Parcela  1491.733980\n",
      "12  Esfera_Convenio_Municipal  1227.765614\n",
      "9      Tipo_Empregado_Efetivo   448.439438\n",
      "11  Tipo_Empregado_Temporário   251.030250\n",
      "7     Tipo_Produto_Empréstimo   212.549737\n",
      "2            Muitos_Contratos   179.326429\n",
      "3                     CAPAG_B   107.588587\n",
      "13   Faixa_Idade_38_a_45_anos   107.413959\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_30d_Flag\n",
      "========================================================================================\n",
      "Base rate no treino: 0.6897 | no teste: 0.6896\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.8480 | PR-AUC(AP): 0.9034\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Contratado   -3.722323\n",
      "Tipo_Empregado_Efetivo       3.404100\n",
      "Tipo_Empregado_Temporário    2.463495\n",
      "Esfera_Convenio_Municipal   -2.053657\n",
      "CAPAG_B                     -1.998968\n",
      "CAPAG_N.D.                  -1.261466\n",
      "Tipo_Produto_Empréstimo     -1.100754\n",
      "Tipo_Empregado_Outros        1.007112\n",
      "CAPAG_C                     -0.971152\n",
      "Tipo_Produto_Cartão RMC      0.218468\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8822 | PR-AUC(AP): 0.9222\n",
      "Top 10 importâncias:\n",
      "                      Feature  Importance\n",
      "1               Valor_Parcela    0.386320\n",
      "0              Total_Parcelas    0.200179\n",
      "11  Tipo_Empregado_Temporário    0.080499\n",
      "9      Tipo_Empregado_Efetivo    0.079006\n",
      "8   Tipo_Empregado_Contratado    0.072072\n",
      "7     Tipo_Produto_Empréstimo    0.029841\n",
      "12  Esfera_Convenio_Municipal    0.026712\n",
      "2            Muitos_Contratos    0.022458\n",
      "4                     CAPAG_C    0.020375\n",
      "6     Tipo_Produto_Cartão RMC    0.015966\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.8336 | PR-AUC(AP): 0.8779\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8901 | PR-AUC(AP): 0.9314\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                     Feature       Gain\n",
      "0  Tipo_Empregado_Contratado  56.264435\n",
      "1     Tipo_Empregado_Efetivo  11.153292\n",
      "2             Total_Parcelas   3.792136\n",
      "3      Tipo_Empregado_Outros   3.681315\n",
      "4  Tipo_Empregado_Temporário   3.389155\n",
      "5                    CAPAG_B   2.179682\n",
      "6    Tipo_Produto_Empréstimo   2.053640\n",
      "7                    CAPAG_C   1.495817\n",
      "8  Esfera_Convenio_Municipal   1.475026\n",
      "9                 CAPAG_N.D.   1.128388\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3301, number of negative: 1485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.689720 -> initscore=0.798811\n",
      "[LightGBM] [Info] Start training from score 0.798811\n",
      "ROC-AUC: 0.8953 | PR-AUC(AP): 0.9366\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                        Feature         Gain\n",
      "0                Total_Parcelas  3473.228851\n",
      "1                 Valor_Parcela  2755.153510\n",
      "8     Tipo_Empregado_Contratado  2738.051868\n",
      "9        Tipo_Empregado_Efetivo  1895.791638\n",
      "11    Tipo_Empregado_Temporário   658.906985\n",
      "7       Tipo_Produto_Empréstimo   477.440917\n",
      "2              Muitos_Contratos   280.825905\n",
      "3                       CAPAG_B   171.863881\n",
      "4                       CAPAG_C   167.595454\n",
      "15  Faixa_Idade_54_anos_ou_mais   163.971594\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_60d_Flag\n",
      "========================================================================================\n",
      "Base rate no treino: 0.5295 | no teste: 0.5292\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.8513 | PR-AUC(AP): 0.8406\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Efetivo         5.018614\n",
      "Tipo_Empregado_Temporário      3.913306\n",
      "Tipo_Empregado_Outros          3.111446\n",
      "Esfera_Convenio_Municipal     -2.510135\n",
      "Tipo_Empregado_Contratado     -2.139856\n",
      "CAPAG_B                       -2.024931\n",
      "CAPAG_C                       -1.734823\n",
      "Tipo_Produto_Empréstimo       -1.139490\n",
      "CAPAG_N.D.                    -0.824950\n",
      "Faixa_Idade_54 anos ou mais    0.176373\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8663 | PR-AUC(AP): 0.8430\n",
      "Top 10 importâncias:\n",
      "                        Feature  Importance\n",
      "1                 Valor_Parcela    0.424765\n",
      "0                Total_Parcelas    0.133766\n",
      "11    Tipo_Empregado_Temporário    0.101622\n",
      "9        Tipo_Empregado_Efetivo    0.084350\n",
      "8     Tipo_Empregado_Contratado    0.048428\n",
      "4                       CAPAG_C    0.037996\n",
      "12    Esfera_Convenio_Municipal    0.035005\n",
      "7       Tipo_Produto_Empréstimo    0.033121\n",
      "2              Muitos_Contratos    0.023892\n",
      "15  Faixa_Idade_54 anos ou mais    0.013461\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.8541 | PR-AUC(AP): 0.8352\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8790 | PR-AUC(AP): 0.8734\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                     Feature       Gain\n",
      "0  Tipo_Empregado_Contratado  59.031689\n",
      "1  Tipo_Empregado_Temporário  19.572149\n",
      "2      Tipo_Empregado_Outros   8.412154\n",
      "3  Esfera_Convenio_Municipal   5.605096\n",
      "4                    CAPAG_C   5.586591\n",
      "5     Tipo_Empregado_Efetivo   4.591215\n",
      "6             Total_Parcelas   4.249494\n",
      "7                    CAPAG_B   4.030591\n",
      "8                 CAPAG_N.D.   3.201544\n",
      "9    Tipo_Produto_Empréstimo   3.185456\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2534, number of negative: 2252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.529461 -> initscore=0.117980\n",
      "[LightGBM] [Info] Start training from score 0.117980\n",
      "ROC-AUC: 0.8856 | PR-AUC(AP): 0.8776\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                      Feature         Gain\n",
      "0              Total_Parcelas  4119.191002\n",
      "1               Valor_Parcela  3493.711760\n",
      "8   Tipo_Empregado_Contratado  3018.976545\n",
      "11  Tipo_Empregado_Temporário  2517.103756\n",
      "4                     CAPAG_C  1163.450849\n",
      "12  Esfera_Convenio_Municipal   897.775650\n",
      "9      Tipo_Empregado_Efetivo   745.325781\n",
      "7     Tipo_Produto_Empréstimo   736.070876\n",
      "2            Muitos_Contratos   481.759044\n",
      "10      Tipo_Empregado_Outros   331.185243\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_90d_Flag\n",
      "========================================================================================\n",
      "Base rate no treino: 0.3354 | no teste: 0.3353\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.7809 | PR-AUC(AP): 0.6245\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Efetivo       4.382952\n",
      "Tipo_Empregado_Temporário    3.018381\n",
      "Tipo_Empregado_Outros        2.928855\n",
      "Tipo_Empregado_Contratado   -2.319493\n",
      "Esfera_Convenio_Municipal   -2.244051\n",
      "CAPAG_B                     -0.817866\n",
      "Tipo_Produto_Empréstimo     -0.683874\n",
      "Tipo_Produto_Cartão RMC      0.528923\n",
      "CAPAG_N.D.                  -0.399760\n",
      "CAPAG_C                     -0.155562\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.7975 | PR-AUC(AP): 0.6651\n",
      "Top 10 importâncias:\n",
      "                      Feature  Importance\n",
      "1               Valor_Parcela    0.512880\n",
      "0              Total_Parcelas    0.120615\n",
      "9      Tipo_Empregado_Efetivo    0.065673\n",
      "11  Tipo_Empregado_Temporário    0.061301\n",
      "12  Esfera_Convenio_Municipal    0.042776\n",
      "7     Tipo_Produto_Empréstimo    0.038719\n",
      "8   Tipo_Empregado_Contratado    0.035169\n",
      "2            Muitos_Contratos    0.033954\n",
      "4                     CAPAG_C    0.017279\n",
      "6     Tipo_Produto_Cartão RMC    0.014196\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.7841 | PR-AUC(AP): 0.6013\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8290 | PR-AUC(AP): 0.7052\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                     Feature       Gain\n",
      "0  Tipo_Empregado_Contratado  53.870216\n",
      "1  Esfera_Convenio_Municipal  12.179648\n",
      "2  Tipo_Empregado_Temporário  10.360579\n",
      "3     Tipo_Empregado_Efetivo   8.830858\n",
      "4      Tipo_Empregado_Outros   6.107745\n",
      "5             Total_Parcelas   4.938339\n",
      "6    Tipo_Produto_Empréstimo   3.915785\n",
      "7                    CAPAG_C   3.176491\n",
      "8           Muitos_Contratos   2.799209\n",
      "9                    CAPAG_B   1.950188\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1605, number of negative: 3181\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335353 -> initscore=-0.684072\n",
      "[LightGBM] [Info] Start training from score -0.684072\n",
      "ROC-AUC: 0.8371 | PR-AUC(AP): 0.7202\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                      Feature         Gain\n",
      "1               Valor_Parcela  4678.520853\n",
      "0              Total_Parcelas  4557.654179\n",
      "8   Tipo_Empregado_Contratado  2940.261268\n",
      "12  Esfera_Convenio_Municipal  2520.615667\n",
      "9      Tipo_Empregado_Efetivo  1455.677869\n",
      "2            Muitos_Contratos  1396.630777\n",
      "11  Tipo_Empregado_Temporário  1368.635075\n",
      "7     Tipo_Produto_Empréstimo   920.595465\n",
      "4                     CAPAG_C   431.865465\n",
      "10      Tipo_Empregado_Outros   387.612271\n"
     ]
    }
   ],
   "source": [
    "print (\" TREINANDO MODELOS... AGUARDE (+-1 MIN)\")\n",
    "resultados_finais = treinar_e_avaliar(df_ml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74233caa",
   "metadata": {},
   "source": [
    "#### Resultado Final: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f32eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================\n",
      "   RESUMO COMPARATIVO FINAL - ROC-AUC\n",
      "========================================================================================\n",
      "                     Vencido_1d_Flag  Vencido_30d_Flag  Vencido_60d_Flag  \\\n",
      "Regressão Logística           0.9112            0.8480            0.8513   \n",
      "Random Forest                 0.9375            0.8822            0.8663   \n",
      "SVM (Kernel RBF)              0.9116            0.8336            0.8541   \n",
      "XGBoost                       0.9337            0.8901            0.8790   \n",
      "LightGBM                      0.9400            0.8953            0.8856   \n",
      "\n",
      "                     Vencido_90d_Flag  \n",
      "Regressão Logística            0.7809  \n",
      "Random Forest                  0.7975  \n",
      "SVM (Kernel RBF)               0.7841  \n",
      "XGBoost                        0.8290  \n",
      "LightGBM                       0.8371  \n",
      "\n",
      "----------------------------------------------------------------------------------------\n",
      "Considerando a média de ROC-AUC em todos os alvos, o melhor modelo parece ser: 'LightGBM'\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*88)\n",
    "print(\"   RESUMO COMPARATIVO FINAL - ROC-AUC\")\n",
    "print(\"=\"*88)\n",
    "print(resultados_finais.round(4))\n",
    "\n",
    "melhor_modelo_geral = resultados_finais.mean(axis=1).idxmax()\n",
    "print(\"\\n\" + \"-\"*88)\n",
    "print(f\"Considerando a média de ROC-AUC em todos os alvos, o melhor modelo parece ser: '{melhor_modelo_geral}'\")\n",
    "print(\"-\"*88)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000b851c",
   "metadata": {},
   "source": [
    "## Referências\n",
    "Abaixo estão os links que eu visitei para consultar dúvidas: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e24463",
   "metadata": {},
   "source": [
    "machine learning - How to deal with possible data leakage in time series data? - Data Science Stack Exchange\n",
    "https://datascience.stackexchange.com/questions/45575/how-to-deal-with-possible-data-leakage-in-time-series-data\n",
    "Python Pandas: Keeping only dataframe rows containing first occurrence of an item - Stack Overflow\n",
    "https://stackoverflow.com/questions/24136620/python-pandas-keeping-only-dataframe-rows-containing-first-occurrence-of-an-ite/24137060\n",
    "python - Add column with number of days between dates in DataFrame pandas - Stack Overflow\n",
    "https://stackoverflow.com/questions/22132525/add-column-with-number-of-days-between-dates-in-dataframe-pandas\n",
    "Python Pandas max value in a group as a new column - Stack Overflow\n",
    "https://stackoverflow.com/questions/35640364/python-pandas-max-value-in-a-group-as-a-new-column\n",
    "python - Assign conditions from a list np.select and create a new column (pandas) - Stack Overflow\n",
    "https://stackoverflow.com/questions/69824116/assign-conditions-from-a-list-np-select-and-create-a-new-column-pandas\n",
    "python - Pandas get the age from a date (example: date of birth) - Stack Overflow\n",
    "https://stackoverflow.com/questions/26788854/pandas-get-the-age-from-a-date-example-date-of-birth\n",
    "Why do we use stratify in train_test_split | by aymuosmukherjee | Medium\n",
    "https://medium.com/@aymuosmukherjee/why-do-we-use-stratify-in-train-test-split-e3eb296a5494\n",
    "python - How can I align pandas get_dummies across training / validation / testing? - Stack Overflow\n",
    "https://stackoverflow.com/questions/56738267/how-can-i-align-pandas-get-dummies-across-training-validation-testing\n",
    "Feature Engineering in a Pipeline - Weijian Zhang\n",
    "https://weijianzhg.com/blog/2021/feature-engineering/\n",
    "Column Transformer with Mixed Types — scikit-learn 1.7.1 documentation\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "How Does the class_weight Parameter in Scikit-Learn Work? - GeeksforGeeks\n",
    "https://www.geeksforgeeks.org/machine-learning/how-does-the-classweight-parameter-in-scikit-learn-work/\n",
    "unbalanced classes - What is the proper usage of scale_pos_weight in xgboost for imbalanced datasets? - Cross Validated\n",
    "https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n",
    "roc_auc_score — scikit-learn 1.7.1 documentation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "F1 Score vs ROC AUC vs Accuracy vs PR AUC - Neptune.ai\n",
    "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc\n",
    "python - XGBoostClassifier: model.get_booster().get_score(importance_type=\"gain\") not return entire feature importance - Stack Overflow\n",
    "https://stackoverflow.com/questions/74067871/xgboostclassifier-model-get-booster-get-scoreimportance-type-gain-not-ret\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
