{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script de Análise e Preparação de Dados para Modelagem de Machine Learning\n",
    "\n",
    "Objetivo:\n",
    "1.  Carregar e preparar os dados da carteira.\n",
    "2.  Agregar os dados para o nível de CONTRATO (CCB).\n",
    "3.  Criar as variáveis-alvo (flags de inadimplência para 1, 30, 60, 90 dias).\n",
    "4.  Realizar uma Análise Exploratória de Dados (EDA) para entender:\n",
    "    - Distribuição das variáveis-alvo (desbalanceamento).\n",
    "    - Dados faltantes.\n",
    "    - Cardinalidade das variáveis categóricas.\n",
    "    - Relação inicial entre as features e o alvo.\n",
    "\n",
    "Este script deve ser executado ANTES do treinamento de qualquer modelo.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LEITURA E PREPARAÇÃO DOS DADOS (Baseado no script original)\n",
    "# =============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"ETAPA 1: Carregando e limpando os dados...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "#! PATHS ----------------------------------------------------------------------\n",
    "#! ----------------------------------------------------------------------------\n",
    "# ATENÇÃO: REDIFINIR AQUI OS PATHS PARA A SUA MÁQUINA\n",
    "path_starcard = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\StarCard.xlsx'\n",
    "path_originadores = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\Originadores.xlsx'\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# Carregando os dados\n",
    "df_starcard = pd.read_excel(path_starcard)\n",
    "cols_originadores = [\n",
    "    'CCB', 'Prazo', 'Valor Parcela', 'Valor IOF', 'Valor Liquido Cliente',\n",
    "    'Data Primeiro Vencimento', 'Data Último Vencimento', 'Data de Inclusão',\n",
    "    'CET Mensal', 'Taxa CCB', 'Produto', 'Tabela', 'Promotora',\n",
    "    'Valor Split Originador', 'Valor Split FIDC', 'Valor Split Compra de Divida',\n",
    "    'Taxa Originador Split', 'Taxa Split FIDC'\n",
    "]\n",
    "df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "\n",
    "# Unindo as fontes de dados\n",
    "if not df_originadores['CCB'].is_unique:\n",
    "    print(\"[AVISO] CCBs duplicados em Originadores.xlsx. Removendo duplicatas e mantendo a primeira ocorrência.\")\n",
    "    df_originadores = df_originadores.drop_duplicates(subset='CCB', keep='first')\n",
    "\n",
    "df_merged = pd.merge(df_starcard, df_originadores, on='CCB', how='left', suffixes=('', '_orig'))\n",
    "\n",
    "# Renomeando e limpando colunas\n",
    "df_merged = df_merged.rename(columns={\n",
    "    'Data Referencia': 'DataGeracao', 'Data Aquisicao': 'DataAquisicao',\n",
    "    'Data Vencimento': 'DataVencimento', 'Status': 'Situacao',\n",
    "    'PDD Total': 'PDDTotal', 'Valor Nominal': 'ValorNominal',\n",
    "    'Valor Presente': 'ValorPresente', 'Valor Aquisicao': 'ValorAquisicao',\n",
    "    'ID Cliente': 'SacadoID', 'Pagamento Parcial': 'PagamentoParcial'\n",
    "})\n",
    "\n",
    "cols_monetarias = ['ValorAquisicao', 'ValorNominal', 'ValorPresente', 'PDDTotal', 'Valor Parcela']\n",
    "for col in cols_monetarias:\n",
    "    if df_merged[col].dtype == 'object':\n",
    "        df_merged[col] = df_merged[col].astype(str).str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()\n",
    "        df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "cols_data = ['DataGeracao', 'DataAquisicao', 'DataVencimento', 'Data de Nascimento']\n",
    "for col in cols_data:\n",
    "    df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')\n",
    "\n",
    "print(\"Dados carregados e limpos.\")\n",
    "df_base = df_merged.copy()\n",
    "del df_starcard, df_originadores, df_merged # Libera memória\n",
    "\n",
    "# =============================================================================\n",
    "# 2. ENGENHARIA DE FEATURES (Nível Parcela)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ETAPA 2: Engenharia de Features a nível de parcela...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Criando dias de atraso\n",
    "df_base['dias_de_atraso'] = (df_base['DataGeracao'] - df_base['DataVencimento']).dt.days\n",
    "\n",
    "# Criando as features categóricas customizadas do script original\n",
    "df_base['Produto'] = df_base['Produto'].fillna('')\n",
    "df_base['Convênio'] = df_base['Convênio'].fillna('')\n",
    "\n",
    "# _TipoProduto\n",
    "condicoes_produto = [\n",
    "    df_base['Produto'].str.contains('Empréstimo', case=False, na=False),\n",
    "    df_base['Produto'].str.contains('Cartão RMC', case=False, na=False),\n",
    "    df_base['Produto'].str.contains('Cartão Benefício', case=False, na=False)\n",
    "]\n",
    "opcoes_produto = ['Empréstimo', 'Cartão RMC', 'Cartão Benefício']\n",
    "df_base['_TipoProduto'] = np.select(condicoes_produto, opcoes_produto, default='Outros')\n",
    "\n",
    "# _TipoEmpregado\n",
    "condicoes_empregado = [\n",
    "    df_base['Produto'].str.contains('Efetivo|Efetivio', case=False, na=False, regex=True),\n",
    "    df_base['Produto'].str.contains('Temporário', case=False, na=False),\n",
    "    df_base['Produto'].str.contains('CONTRATADO', case=False, na=False),\n",
    "    df_base['Produto'].str.contains('Comissionado', case=False, na=False)\n",
    "]\n",
    "opcoes_empregado = ['Efetivo', 'Temporário', 'Contratado', 'Comissionado']\n",
    "df_base['_TipoEmpregado'] = np.select(condicoes_empregado, opcoes_empregado, default='Outros')\n",
    "\n",
    "# _EsferaConvenio\n",
    "condicoes_convenio = [\n",
    "    df_base['Convênio'].str.contains(r'GOV\\.|AGN -', case=False, na=False, regex=True),\n",
    "    df_base['Convênio'].str.contains(r'PREF\\.|PRERF', case=False, na=False, regex=True)\n",
    "]\n",
    "opcoes_convenio = ['Estadual', 'Municipal']\n",
    "df_base['_EsferaConvenio'] = np.select(condicoes_convenio, opcoes_convenio, default='Outros')\n",
    "\n",
    "# _IdadeCliente e _IdadesBins\n",
    "if 'Data de Nascimento' in df_base.columns and 'DataGeracao' in df_base.columns:\n",
    "    df_base['_IdadeCliente'] = ((df_base['DataGeracao'] - df_base['Data de Nascimento']).dt.days / 365.25)\n",
    "    bins = [0, 37, 45, 53, 120]\n",
    "    labels = ['Até 37 anos', '38 a 45 anos', '46 a 53 anos', '54 anos ou mais']\n",
    "    df_base['_IdadesBins'] = pd.cut(df_base['_IdadeCliente'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Flags _MuitosContratos e _MuitosEntes\n",
    "sacado_contratos = df_base.groupby('SacadoID')['CCB'].nunique()\n",
    "sacado_contratos_alto = sacado_contratos[sacado_contratos >= 3].index\n",
    "df_base['_MuitosContratos'] = df_base['SacadoID'].isin(sacado_contratos_alto).astype(int)\n",
    "\n",
    "sacados_entes = df_base.groupby('SacadoID')['Convênio'].nunique()\n",
    "sacados_entes_alto = sacados_entes[sacados_entes >= 3].index\n",
    "df_base['_MuitosEntes'] = df_base['SacadoID'].isin(sacados_entes_alto).astype(int)\n",
    "\n",
    "print(\"Features criadas.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. AGREGAÇÃO PARA O NÍVEL DE CONTRATO (CCB) E CRIAÇÃO DOS ALVOS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ETAPA 3: Agregando dados e criando variáveis-alvo...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Agrupando por CCB para obter o máximo de dias de atraso por contrato\n",
    "atraso_por_ccb = df_base.groupby('CCB')['dias_de_atraso'].max().reset_index()\n",
    "atraso_por_ccb = atraso_por_ccb.rename(columns={'dias_de_atraso': 'max_dias_atraso'})\n",
    "\n",
    "# Criando as flags de inadimplência (variáveis-alvo)\n",
    "atraso_por_ccb['Vencido_1d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 1).astype(int)\n",
    "atraso_por_ccb['Vencido_30d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 30).astype(int)\n",
    "atraso_por_ccb['Vencido_60d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 60).astype(int)\n",
    "atraso_por_ccb['Vencido_90d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 90).astype(int)\n",
    "\n",
    "# Selecionando as features que queremos usar no modelo\n",
    "# Como elas devem ser constantes por contrato, podemos pegar o primeiro valor\n",
    "features_para_modelo = [\n",
    "    'CCB', 'Originador', 'Convênio', 'CAPAG', 'Prazo', 'Valor Parcela',\n",
    "    '_TipoProduto', '_TipoEmpregado', '_EsferaConvenio', '_IdadesBins',\n",
    "    '_MuitosContratos', '_MuitosEntes'\n",
    "]\n",
    "# Garante que as colunas existem no dataframe antes de usar\n",
    "features_existentes = [f for f in features_para_modelo if f in df_base.columns]\n",
    "df_features = df_base[features_existentes].drop_duplicates(subset='CCB', keep='first')\n",
    "\n",
    "# Unindo as features com as variáveis-alvo\n",
    "df_ml = pd.merge(df_features, atraso_por_ccb, on='CCB')\n",
    "\n",
    "# --- Engenharia de Features Adicionais (Nível Contrato) ---\n",
    "\n",
    "# Total de Parcelas\n",
    "df_ml = df_ml.rename(columns={'Prazo': 'Total_Parcelas'})\n",
    "\n",
    "# Parcela Atual / Parcelas Restantes (Proxy)\n",
    "# Contando o número de parcelas futuras para cada CCB\n",
    "parcelas_futuras = df_base[df_base['dias_de_atraso'] < 0].groupby('CCB').size().reset_index(name='Parcelas_Restantes')\n",
    "df_ml = pd.merge(df_ml, parcelas_futuras, on='CCB', how='left')\n",
    "df_ml['Parcelas_Restantes'] = df_ml['Parcelas_Restantes'].fillna(0)\n",
    "df_ml['Numero_Proxima_Parcela'] = df_ml['Total_Parcelas'] - df_ml['Parcelas_Restantes']\n",
    "\n",
    "# TODO: Lógica para Faixa de População\n",
    "# Esta feature não existe nos dados originais. Você precisaria de uma tabela\n",
    "# de apoio (de-para) que mapeie Convênio ou UF para uma faixa populacional.\n",
    "# Exemplo: DE-PARA: {'PREF. COTIA': '100k-500k', 'GOV. GOIAS': '>1M'}\n",
    "print(\"[AVISO] A feature 'Faixa_Populacao' não foi criada. É necessário implementar a lógica de mapeamento.\")\n",
    "df_ml['Faixa_Populacao'] = 'N/A' # Placeholder\n",
    "\n",
    "# Renomeando colunas para o padrão do pedido\n",
    "df_ml = df_ml.rename(columns={\n",
    "    '_EsferaConvenio': 'Esfera_Convenio',\n",
    "    '_IdadesBins': 'Faixa_Idade',\n",
    "    '_MuitosContratos': 'Muitos_Contratos',\n",
    "    '_MuitosEntes': 'Muitos_Entes',\n",
    "    '_TipoProduto': 'Tipo_Produto',\n",
    "    '_TipoEmpregado': 'Tipo_Empregado',\n",
    "    'Valor Parcela': 'Valor_Parcela',\n",
    "})\n",
    "\n",
    "print(f\"Dataset para ML criado com {df_ml.shape[0]} contratos (linhas) e {df_ml.shape[1]} features (colunas).\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. ANÁLISE EXPLORATÓRIA DE DADOS (EDA) - \"DEBUGGING\"\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ETAPA 4: Análise Exploratória dos Dados para ML\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- 4.1 Informações Gerais e Dados Faltantes ---\n",
    "print(\"\\n--- 4.1 Informações Gerais e Dados Faltantes ---\")\n",
    "print(\"df_ml.info():\")\n",
    "df_ml.info()\n",
    "\n",
    "missing_values = df_ml.isnull().sum()\n",
    "missing_percent = (missing_values / len(df_ml) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Valores Faltantes': missing_values, '% Faltante': missing_percent})\n",
    "print(\"\\nAnálise de Dados Faltantes:\")\n",
    "print(missing_df[missing_df['Valores Faltantes'] > 0])\n",
    "\n",
    "# --- 4.2 Análise do Desbalanceamento das Classes ---\n",
    "print(\"\\n--- 4.2 Análise do Desbalanceamento das Classes (Variáveis-Alvo) ---\")\n",
    "targets = ['Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
    "for target in targets:\n",
    "    print(f\"\\nDistribuição para '{target}':\")\n",
    "    counts = df_ml[target].value_counts()\n",
    "    percentages = df_ml[target].value_counts(normalize=True) * 100\n",
    "    dist_df = pd.DataFrame({'Contagem': counts, 'Percentual (%)': percentages.round(2)})\n",
    "    print(dist_df)\n",
    "    print(\"-\"*30)\n",
    "\n",
    "# --- 4.3 Análise de Cardinalidade das Variáveis Categóricas ---\n",
    "print(\"\\n--- 4.3 Análise de Cardinalidade (Valores Únicos) das Features Categóricas ---\")\n",
    "categorical_features = df_ml.select_dtypes(include=['object', 'category']).columns\n",
    "for feature in categorical_features:\n",
    "    unique_count = df_ml[feature].nunique()\n",
    "    print(f\"- '{feature}': {unique_count} valores únicos.\")\n",
    "    if unique_count > 50:\n",
    "        print(f\"  [ATENÇÃO] Alta cardinalidade! Pode ser necessário agrupar ou usar Target Encoding.\")\n",
    "\n",
    "# --- 4.4 Análise Bivariada (Relação Feature vs. Alvo) ---\n",
    "print(\"\\n--- 4.4 Análise Bivariada: Taxa de Inadimplência por Categoria ---\")\n",
    "print(\"Analisando a taxa de inadimplência para o alvo 'Vencido_30d_Flag'\")\n",
    "\n",
    "features_to_analyze = [\n",
    "    'Esfera_Convenio', 'Faixa_Populacao', 'CAPAG', 'Muitos_Contratos',\n",
    "    'Tipo_Produto', 'Tipo_Empregado', 'Faixa_Idade', 'Originador', 'Muitos_Entes'\n",
    "]\n",
    "features_to_analyze = [f for f in features_to_analyze if f in df_ml.columns] # Garantir que existem\n",
    "\n",
    "for feature in features_to_analyze:\n",
    "    # Ignora features com muitos valores únicos para não poluir a saída\n",
    "    if df_ml[feature].nunique() > 30 and df_ml[feature].dtype == 'object':\n",
    "        print(f\"\\nFeature '{feature}' tem alta cardinalidade ({df_ml[feature].nunique()}) - pulando a exibição detalhada.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- Taxa de inadimplência (Vencido_30d_Flag) por '{feature}' ---\")\n",
    "    # Calcula a média da flag (que é a taxa de inadimplência) e a contagem de contratos\n",
    "    analysis = df_ml.groupby(feature)['Vencido_30d_Flag'].agg(['mean', 'count']).reset_index()\n",
    "    analysis['mean'] = (analysis['mean'] * 100).round(2)\n",
    "    analysis = analysis.rename(columns={'mean': 'Taxa Inadimplência (%)', 'count': 'Nº Contratos'})\n",
    "    print(analysis.sort_values(by='Taxa Inadimplência (%)', ascending=False))\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISE DE PREPARAÇÃO CONCLUÍDA!\")\n",
    "print(\"Use os insights acima para definir a estratégia de pré-processamento e modelagem.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144a4c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\leo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (20.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement install (from versions: none)\n",
      "ERROR: No matching distribution found for install\n",
      "WARNING: You are using pip version 20.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install pip install pandas numpy scikit-learn xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afb1456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbmNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\leo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\leo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from lightgbm) (2.0.2)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac25e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_1d_Flag (COM MELHORIAS)\n",
      "================================================================================\n",
      "Dados divididos: 4786 para treino, 2052 para teste.\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC Score: 0.9321\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC Score: 0.9297\n",
      "Top 10 Features mais importantes:\n",
      "                      Feature  Importance\n",
      "0              Total_Parcelas    0.208804\n",
      "1               Valor_Parcela    0.174818\n",
      "34  Tipo_Empregado_Contratado    0.151244\n",
      "37  Tipo_Empregado_Temporário    0.112349\n",
      "35     Tipo_Empregado_Efetivo    0.051624\n",
      "33    Tipo_Produto_Empréstimo    0.030710\n",
      "3         Convênio_GOV. GOIAS    0.025748\n",
      "38  Esfera_Convenio_Municipal    0.024749\n",
      "2            Muitos_Contratos    0.020859\n",
      "32    Tipo_Produto_Cartão RMC    0.019955\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC Score: 0.9217\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC Score: 0.9419\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "34         Tipo_Empregado_Contratado    0.368344\n",
      "38         Esfera_Convenio_Municipal    0.272613\n",
      "6          Convênio_PREF. ANANINDEUA    0.055534\n",
      "0                     Total_Parcelas    0.046351\n",
      "7           Convênio_PREF. ARAÇATUBA    0.023072\n",
      "37         Tipo_Empregado_Temporário    0.019689\n",
      "10              Convênio_PREF. COTIA    0.019493\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.017006\n",
      "35            Tipo_Empregado_Efetivo    0.015723\n",
      "12        Convênio_PREF. HORTOLANDIA    0.013199\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3904, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 327\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815712 -> initscore=1.487565\n",
      "[LightGBM] [Info] Start training from score 1.487565\n",
      "ROC-AUC Score: 0.9468\n",
      "Top 10 Features mais importantes:\n",
      "                        Feature  Importance\n",
      "1                 Valor_Parcela        1307\n",
      "0                Total_Parcelas         442\n",
      "2              Muitos_Contratos         130\n",
      "33      Tipo_Produto_Empréstimo         116\n",
      "39     Faixa_Idade_38 a 45 anos         110\n",
      "40     Faixa_Idade_46 a 53 anos         101\n",
      "41  Faixa_Idade_54 anos ou mais          86\n",
      "34    Tipo_Empregado_Contratado          76\n",
      "35       Tipo_Empregado_Efetivo          63\n",
      "6     Convênio_PREF. ANANINDEUA          62\n",
      "\n",
      "================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_30d_Flag (COM MELHORIAS)\n",
      "================================================================================\n",
      "Dados divididos: 4786 para treino, 2052 para teste.\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC Score: 0.8668\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC Score: 0.8917\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.355233\n",
      "0                     Total_Parcelas    0.170393\n",
      "34         Tipo_Empregado_Contratado    0.085054\n",
      "35            Tipo_Empregado_Efetivo    0.072062\n",
      "37         Tipo_Empregado_Temporário    0.068252\n",
      "33           Tipo_Produto_Empréstimo    0.032262\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.022594\n",
      "2                   Muitos_Contratos    0.020220\n",
      "38         Esfera_Convenio_Municipal    0.015763\n",
      "7           Convênio_PREF. ARAÇATUBA    0.014984\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC Score: 0.8496\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC Score: 0.9072\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "34         Tipo_Empregado_Contratado    0.391201\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.120139\n",
      "6          Convênio_PREF. ANANINDEUA    0.116801\n",
      "37         Tipo_Empregado_Temporário    0.052620\n",
      "35            Tipo_Empregado_Efetivo    0.043200\n",
      "12        Convênio_PREF. HORTOLANDIA    0.025499\n",
      "0                     Total_Parcelas    0.024824\n",
      "33           Tipo_Produto_Empréstimo    0.018510\n",
      "7           Convênio_PREF. ARAÇATUBA    0.018491\n",
      "9    Convênio_PREF. CAMPOS DO JORDÃO    0.013984\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3301, number of negative: 1485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.689720 -> initscore=0.798811\n",
      "[LightGBM] [Info] Start training from score 0.798811\n",
      "ROC-AUC Score: 0.9078\n",
      "Top 10 Features mais importantes:\n",
      "                        Feature  Importance\n",
      "1                 Valor_Parcela        1366\n",
      "0                Total_Parcelas         439\n",
      "35       Tipo_Empregado_Efetivo         133\n",
      "39     Faixa_Idade_38 a 45 anos         103\n",
      "33      Tipo_Produto_Empréstimo          98\n",
      "2              Muitos_Contratos          83\n",
      "37    Tipo_Empregado_Temporário          68\n",
      "41  Faixa_Idade_54 anos ou mais          66\n",
      "40     Faixa_Idade_46 a 53 anos          62\n",
      "7      Convênio_PREF. ARAÇATUBA          59\n",
      "\n",
      "================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_60d_Flag (COM MELHORIAS)\n",
      "================================================================================\n",
      "Dados divididos: 4786 para treino, 2052 para teste.\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC Score: 0.8666\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC Score: 0.8634\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.375871\n",
      "0                     Total_Parcelas    0.122839\n",
      "37         Tipo_Empregado_Temporário    0.104640\n",
      "35            Tipo_Empregado_Efetivo    0.075937\n",
      "34         Tipo_Empregado_Contratado    0.049323\n",
      "7           Convênio_PREF. ARAÇATUBA    0.031747\n",
      "33           Tipo_Produto_Empréstimo    0.030171\n",
      "38         Esfera_Convenio_Municipal    0.021068\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.020624\n",
      "2                   Muitos_Contratos    0.019270\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC Score: 0.8591\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC Score: 0.8880\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "34         Tipo_Empregado_Contratado    0.280789\n",
      "35            Tipo_Empregado_Efetivo    0.095936\n",
      "37         Tipo_Empregado_Temporário    0.088334\n",
      "7           Convênio_PREF. ARAÇATUBA    0.085530\n",
      "38         Esfera_Convenio_Municipal    0.081551\n",
      "6          Convênio_PREF. ANANINDEUA    0.059815\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.043226\n",
      "36             Tipo_Empregado_Outros    0.037224\n",
      "23              Convênio_PREF. SALTO    0.024221\n",
      "9    Convênio_PREF. CAMPOS DO JORDÃO    0.024119\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2534, number of negative: 2252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.529461 -> initscore=0.117980\n",
      "[LightGBM] [Info] Start training from score 0.117980\n",
      "ROC-AUC Score: 0.8931\n",
      "Top 10 Features mais importantes:\n",
      "                        Feature  Importance\n",
      "1                 Valor_Parcela        1446\n",
      "0                Total_Parcelas         412\n",
      "33      Tipo_Produto_Empréstimo         111\n",
      "2              Muitos_Contratos          93\n",
      "35       Tipo_Empregado_Efetivo          84\n",
      "39     Faixa_Idade_38 a 45 anos          81\n",
      "37    Tipo_Empregado_Temporário          73\n",
      "40     Faixa_Idade_46 a 53 anos          64\n",
      "41  Faixa_Idade_54 anos ou mais          58\n",
      "7      Convênio_PREF. ARAÇATUBA          57\n",
      "\n",
      "================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_90d_Flag (COM MELHORIAS)\n",
      "================================================================================\n",
      "Dados divididos: 4786 para treino, 2052 para teste.\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC Score: 0.8027\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC Score: 0.8144\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.492011\n",
      "0                     Total_Parcelas    0.106463\n",
      "36            Tipo_Empregado_Efetivo    0.075104\n",
      "38         Tipo_Empregado_Temporário    0.053820\n",
      "34           Tipo_Produto_Empréstimo    0.038976\n",
      "35         Tipo_Empregado_Contratado    0.031875\n",
      "2                   Muitos_Contratos    0.021435\n",
      "39         Esfera_Convenio_Municipal    0.018611\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.016028\n",
      "33           Tipo_Produto_Cartão RMC    0.015258\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC Score: 0.8113\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC Score: 0.8505\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "35         Tipo_Empregado_Contratado    0.238821\n",
      "39         Esfera_Convenio_Municipal    0.157035\n",
      "38         Tipo_Empregado_Temporário    0.084723\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.081362\n",
      "37             Tipo_Empregado_Outros    0.049634\n",
      "36            Tipo_Empregado_Efetivo    0.046094\n",
      "9    Convênio_PREF. CAMPOS DO JORDÃO    0.033920\n",
      "34           Tipo_Produto_Empréstimo    0.031857\n",
      "6          Convênio_PREF. ANANINDEUA    0.028823\n",
      "31                           CAPAG_C    0.025210\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1605, number of negative: 3181\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335353 -> initscore=-0.684072\n",
      "[LightGBM] [Info] Start training from score -0.684072\n",
      "ROC-AUC Score: 0.8545\n",
      "Top 10 Features mais importantes:\n",
      "                        Feature  Importance\n",
      "1                 Valor_Parcela        1415\n",
      "0                Total_Parcelas         427\n",
      "42  Faixa_Idade_54 anos ou mais          99\n",
      "40     Faixa_Idade_38 a 45 anos          97\n",
      "33      Tipo_Produto_Cartão RMC          87\n",
      "2              Muitos_Contratos          87\n",
      "34      Tipo_Produto_Empréstimo          83\n",
      "36       Tipo_Empregado_Efetivo          70\n",
      "31                      CAPAG_C          68\n",
      "41     Faixa_Idade_46 a 53 anos          67\n",
      "\n",
      "================================================================================\n",
      "   RESUMO COMPARATIVO FINAL - ROC-AUC SCORE (COM MELHORIAS)\n",
      "================================================================================\n",
      "                     Vencido_1d_Flag  Vencido_30d_Flag  Vencido_60d_Flag  \\\n",
      "Regressão Logística           0.9321            0.8668            0.8666   \n",
      "Random Forest                 0.9297            0.8917            0.8634   \n",
      "SVM (Kernel RBF)              0.9217            0.8496            0.8591   \n",
      "XGBoost                       0.9419            0.9072            0.8880   \n",
      "LightGBM                      0.9468            0.9078            0.8931   \n",
      "\n",
      "                     Vencido_90d_Flag  \n",
      "Regressão Logística            0.8027  \n",
      "Random Forest                  0.8144  \n",
      "SVM (Kernel RBF)               0.8113  \n",
      "XGBoost                        0.8505  \n",
      "LightGBM                       0.8545  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Considerando a média de desempenho em todos os alvos, o melhor modelo parece ser: 'LightGBM'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script de Treinamento e Avaliação de Modelos de Machine Learning\n",
    "VERSÃO COM MELHORIAS IMPLEMENTADAS\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 1: CARREGAMENTO E PREPARAÇÃO DOS DADOS (Função consolidada)\n",
    "# =============================================================================\n",
    "def carregar_e_preparar_dados_corrigido():\n",
    "    \"\"\"\n",
    "    Função corrigida para não criar as features que causam vazamento de dados\n",
    "    e para calcular a feature _MuitosContratos de forma temporalmente consciente.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ETAPA 1: Carregando e preparando os dados (VERSÃO CORRIGIDA)...\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    #! PATHS ----------------------------------------------------------------------\n",
    "    # ATENÇÃO: REDIFINIR AQUI OS PATHS PARA A SUA MÁQUINA\n",
    "    path_starcard = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\StarCard.xlsx'\n",
    "    path_originadores = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\Originadores.xlsx'\n",
    "    #------------------------------------------------------------------------------\n",
    "\n",
    "    df_starcard = pd.read_excel(path_starcard)\n",
    "    \n",
    "    # <--- ALTERAÇÃO 1: Incluir 'Data de Inclusão' na lista de colunas a serem carregadas\n",
    "    cols_originadores = ['CCB', 'Data de Inclusão', 'Prazo', 'Valor Parcela', 'Produto', 'Convênio']\n",
    "    df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "\n",
    "    if not df_originadores['CCB'].is_unique:\n",
    "        df_originadores = df_originadores.drop_duplicates(subset='CCB', keep='first')\n",
    "\n",
    "    df_merged = pd.merge(df_starcard, df_originadores, on='CCB', how='left', suffixes=('', '_orig'))\n",
    "\n",
    "    df_merged = df_merged.rename(columns={\n",
    "        'Data Referencia': 'DataGeracao', 'Data Vencimento': 'DataVencimento',\n",
    "        'ID Cliente': 'SacadoID'\n",
    "    })\n",
    "\n",
    "    cols_monetarias = ['Valor Parcela']\n",
    "    for col in cols_monetarias:\n",
    "        if df_merged[col].dtype == 'object':\n",
    "            df_merged[col] = df_merged[col].astype(str).str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()\n",
    "            df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "    # <--- ALTERAÇÃO 2: Garantir que 'Data de Inclusão' seja tratada como data\n",
    "    cols_data = ['DataGeracao', 'DataVencimento', 'Data de Nascimento', 'Data de Inclusão']\n",
    "    for col in cols_data:\n",
    "        # Adicionado um verificador para não dar erro se a coluna não existir\n",
    "        if col in df_merged.columns:\n",
    "            df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')\n",
    "\n",
    "    df_base = df_merged.copy()\n",
    "    del df_starcard, df_originadores, df_merged\n",
    "\n",
    "    df_base['dias_de_atraso'] = (df_base['DataGeracao'] - df_base['DataVencimento']).dt.days\n",
    "    df_base['Produto'] = df_base['Produto'].fillna('')\n",
    "    df_base['Convênio'] = df_base['Convênio'].fillna('')\n",
    "    condicoes_produto = [df_base['Produto'].str.contains('Empréstimo', case=False, na=False), df_base['Produto'].str.contains('Cartão RMC', case=False, na=False), df_base['Produto'].str.contains('Cartão Benefício', case=False, na=False)]\n",
    "    opcoes_produto = ['Empréstimo', 'Cartão RMC', 'Cartão Benefício']\n",
    "    df_base['_TipoProduto'] = np.select(condicoes_produto, opcoes_produto, default='Outros')\n",
    "    condicoes_empregado = [df_base['Produto'].str.contains('Efetivo|Efetivio', case=False, na=False, regex=True), df_base['Produto'].str.contains('Temporário', case=False, na=False), df_base['Produto'].str.contains('CONTRATADO', case=False, na=False), df_base['Produto'].str.contains('Comissionado', case=False, na=False)]\n",
    "    opcoes_empregado = ['Efetivo', 'Temporário', 'Contratado', 'Comissionado']\n",
    "    df_base['_TipoEmpregado'] = np.select(condicoes_empregado, opcoes_empregado, default='Outros')\n",
    "    condicoes_convenio = [df_base['Convênio'].str.contains(r'GOV\\.|AGN -', case=False, na=False, regex=True), df_base['Convênio'].str.contains(r'PREF\\.|PRERF', case=False, na=False, regex=True)]\n",
    "    opcoes_convenio = ['Estadual', 'Municipal']\n",
    "    df_base['_EsferaConvenio'] = np.select(condicoes_convenio, opcoes_convenio, default='Outros')\n",
    "    if 'Data de Nascimento' in df_base.columns:\n",
    "        df_base['_IdadeCliente'] = ((df_base['DataGeracao'] - df_base['Data de Nascimento']).dt.days / 365.25)\n",
    "        bins = [0, 37, 45, 53, 120]\n",
    "        labels = ['Até 37 anos', '38 a 45 anos', '46 a 53 anos', '54 anos ou mais']\n",
    "        df_base['_IdadesBins'] = pd.cut(df_base['_IdadeCliente'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # Lógica temporalmente consciente para '_MuitosContratos'\n",
    "    df_base = df_base.sort_values(by=['SacadoID', 'Data de Inclusão'])\n",
    "    df_base['_NumContratosAnteriores'] = df_base.groupby('SacadoID').cumcount()\n",
    "    df_base['_MuitosContratos'] = (df_base['_NumContratosAnteriores'] >= 2).astype(int)\n",
    "\n",
    "    atraso_por_ccb = df_base.groupby('CCB')['dias_de_atraso'].max().reset_index()\n",
    "    atraso_por_ccb = atraso_por_ccb.rename(columns={'dias_de_atraso': 'max_dias_atraso'})\n",
    "    atraso_por_ccb['Vencido_1d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 1).astype(int)\n",
    "    atraso_por_ccb['Vencido_30d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 30).astype(int)\n",
    "    atraso_por_ccb['Vencido_60d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 60).astype(int)\n",
    "    atraso_por_ccb['Vencido_90d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 90).astype(int)\n",
    "\n",
    "    features_para_modelo = ['CCB', 'Convênio', 'CAPAG', 'Prazo', 'Valor Parcela', '_TipoProduto', '_TipoEmpregado', '_EsferaConvenio', '_IdadesBins', '_MuitosContratos']\n",
    "    features_existentes = [f for f in features_para_modelo if f in df_base.columns]\n",
    "    \n",
    "    df_features = df_base[features_existentes].drop_duplicates(subset='CCB', keep='first')\n",
    "    df_ml = pd.merge(df_features, atraso_por_ccb, on='CCB')\n",
    "    \n",
    "    df_ml = df_ml.rename(columns={\n",
    "        'Prazo': 'Total_Parcelas', 'Valor Parcela': 'Valor_Parcela', '_EsferaConvenio': 'Esfera_Convenio',\n",
    "        '_IdadesBins': 'Faixa_Idade', '_MuitosContratos': 'Muitos_Contratos',\n",
    "        '_TipoProduto': 'Tipo_Produto', '_TipoEmpregado': 'Tipo_Empregado'\n",
    "    })\n",
    "    print(\"Dataset para ML criado (com feature de múltiplos contratos temporalmente correta).\")\n",
    "    return df_ml\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 2: TREINAMENTO E AVALIAÇÃO (COM MELHORIAS)\n",
    "# =============================================================================\n",
    "\n",
    "#df_ml = carregar_e_preparar_dados_corrigido()\n",
    "\n",
    "targets = ['Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
    "resultados_finais = pd.DataFrame()\n",
    "\n",
    "for target in targets:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"   TREINANDO MODELOS PARA O ALVO: {target} (COM MELHORIAS)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    X = df_ml.drop(columns=targets + ['CCB', 'max_dias_atraso'])\n",
    "    y = df_ml[target]\n",
    "\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # A Dummification foi movida para DEPOIS do train_test_split\n",
    "    # X = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # --- MELHORIA 2: Aplicar Dummification APÓS a divisão Treino/Teste ---\n",
    "    # Isso garante que nenhuma informação sobre categorias do conjunto de teste vaze para o treino.\n",
    "    X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "\n",
    "    # Alinha as colunas para garantir que treino e teste tenham as mesmas features.\n",
    "    # Isso lida com casos onde uma categoria pode aparecer no treino mas não no teste ou vice-versa.\n",
    "    training_columns = X_train.columns\n",
    "    X_test = X_test.reindex(columns=training_columns, fill_value=0)\n",
    "    \n",
    "    # É importante garantir que as colunas numéricas para o scaler sejam as que existem APÓS o dummification\n",
    "    numerical_features_after_dummies = [col for col in numerical_features if col in X_train.columns]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train[numerical_features_after_dummies] = scaler.fit_transform(X_train[numerical_features_after_dummies])\n",
    "    X_test[numerical_features_after_dummies] = scaler.transform(X_test[numerical_features_after_dummies])\n",
    "\n",
    "    print(f\"Dados divididos: {len(X_train)} para treino, {len(X_test)} para teste.\")\n",
    "\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "    models = {\n",
    "        \"Regressão Logística\": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "        # --- MELHORIA 3: Alterado para kernel 'rbf' para capturar relações não-lineares ---\n",
    "        \"SVM (Kernel RBF)\": SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced'),\n",
    "        \"XGBoost\": xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight, n_jobs=-1),\n",
    "        \"LightGBM\": lgb.LGBMClassifier(random_state=42, scale_pos_weight=scale_pos_weight, n_jobs=-1)\n",
    "    }\n",
    "\n",
    "    resultados_target = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Treinando {name} ---\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        resultados_target[name] = auc\n",
    "        print(f\"ROC-AUC Score: {auc:.4f}\")\n",
    "\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = pd.DataFrame({\n",
    "                'Feature': X_train.columns,\n",
    "                'Importance': model.feature_importances_\n",
    "            }).sort_values('Importance', ascending=False).head(10)\n",
    "            print(\"Top 10 Features mais importantes:\")\n",
    "            print(importances)\n",
    "\n",
    "    df_resultados_target = pd.DataFrame.from_dict(\n",
    "        resultados_target, orient='index', columns=[target]\n",
    "    )\n",
    "    resultados_finais = pd.concat([resultados_finais, df_resultados_target], axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 3: EXIBIÇÃO DO RESUMO FINAL\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"   RESUMO COMPARATIVO FINAL - ROC-AUC SCORE (COM MELHORIAS)\")\n",
    "print(\"=\"*80)\n",
    "print(resultados_finais.round(4))\n",
    "\n",
    "melhor_modelo_geral = resultados_finais.mean(axis=1).idxmax()\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"Considerando a média de desempenho em todos os alvos, o melhor modelo parece ser: '{melhor_modelo_geral}'\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23af767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "ETAPA 1: Carregando e preparando os dados (VERSÃO FINAL)...\n",
      "========================================================================================\n",
      "Dataset para ML criado com 1 linha por CCB (snapshot na Data de Inclusão) e labels agregados.\n",
      "\n",
      "Base rates dos alvos (df_ml):\n",
      "Vencido_1d_Flag     0.8157\n",
      "Vencido_30d_Flag    0.6897\n",
      "Vencido_60d_Flag    0.5294\n",
      "Vencido_90d_Flag    0.3353\n",
      "dtype: float64\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_1d_Flag\n",
      "========================================================================================\n",
      "#cols treino: 43 | #cols teste: 43\n",
      "Base rate no treino: 0.8157 | no teste: 0.8158\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.9372 | PR-AUC(AP): 0.9819\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Contratado         -4.054948\n",
      "Convênio_PREF. ANANINDEUA         -3.682524\n",
      "Tipo_Empregado_Temporário          3.488191\n",
      "Tipo_Empregado_Efetivo             2.488744\n",
      "Convênio_PREF. CAMPOS DO JORDÃO    2.305191\n",
      "Tipo_Produto_Empréstimo           -1.713887\n",
      "Convênio_PREF. COTIA               1.706626\n",
      "Convênio_PREF. EMBU DAS ARTES     -1.546657\n",
      "Convênio_PREF. SANTA LUZIA         1.468440\n",
      "Esfera_Convenio_Municipal         -1.463444\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.9420 | PR-AUC(AP): 0.9808\n",
      "Top 10 importâncias:\n",
      "                      Feature  Importance\n",
      "0              Total_Parcelas    0.192702\n",
      "1               Valor_Parcela    0.187390\n",
      "34  Tipo_Empregado_Contratado    0.168285\n",
      "37  Tipo_Empregado_Temporário    0.111029\n",
      "35     Tipo_Empregado_Efetivo    0.047886\n",
      "33    Tipo_Produto_Empréstimo    0.029256\n",
      "38  Esfera_Convenio_Municipal    0.027040\n",
      "2            Muitos_Contratos    0.022381\n",
      "6   Convênio_PREF. ANANINDEUA    0.020536\n",
      "3         Convênio_GOV. GOIAS    0.019571\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.9331 | PR-AUC(AP): 0.9810\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.9484 | PR-AUC(AP): 0.9863\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                            Feature       Gain\n",
      "0         Esfera_Convenio_Municipal  33.885242\n",
      "1         Tipo_Empregado_Contratado  29.187881\n",
      "2            Tipo_Empregado_Efetivo   4.770521\n",
      "3         Tipo_Empregado_Temporário   3.859263\n",
      "4                    Total_Parcelas   3.314641\n",
      "5         Convênio_PREF. ANANINDEUA   2.274945\n",
      "6          Convênio_PREF. ARAÇATUBA   1.898137\n",
      "7              Convênio_PREF. SALTO   1.884457\n",
      "8              Convênio_PREF. COTIA   1.702878\n",
      "9  Convênio_PREF. JUAZEIRO DO NORTE   1.576027\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3904, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815712 -> initscore=1.487565\n",
      "[LightGBM] [Info] Start training from score 1.487565\n",
      "ROC-AUC: 0.9508 | PR-AUC(AP): 0.9869\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                      Feature         Gain\n",
      "34  Tipo_Empregado_Contratado  2603.465463\n",
      "0              Total_Parcelas  2593.074954\n",
      "1               Valor_Parcela  1431.391408\n",
      "38  Esfera_Convenio_Municipal  1115.476324\n",
      "35     Tipo_Empregado_Efetivo   346.447706\n",
      "37  Tipo_Empregado_Temporário   332.629987\n",
      "6   Convênio_PREF._ANANINDEUA   226.279177\n",
      "33    Tipo_Produto_Empréstimo   178.698612\n",
      "2            Muitos_Contratos   178.079929\n",
      "7    Convênio_PREF._ARAÇATUBA   117.252454\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_30d_Flag\n",
      "========================================================================================\n",
      "#cols treino: 43 | #cols teste: 43\n",
      "Base rate no treino: 0.6897 | no teste: 0.6896\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.8758 | PR-AUC(AP): 0.9223\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Contratado          -3.523508\n",
      "Convênio_PREF. ANANINDEUA          -3.097653\n",
      "Tipo_Empregado_Efetivo              3.085102\n",
      "Tipo_Empregado_Temporário           2.678431\n",
      "Convênio_PREF. CAMPOS DO JORDÃO     2.054734\n",
      "Convênio_PREF. EMBU DAS ARTES      -2.045484\n",
      "Convênio_PREF. JUAZEIRO DO NORTE   -2.007333\n",
      "Convênio_PREF. COTIA                1.896630\n",
      "Esfera_Convenio_Municipal          -1.682417\n",
      "Convênio_PREF. SANTA LUZIA          1.615778\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8923 | PR-AUC(AP): 0.9298\n",
      "Top 10 importâncias:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.354039\n",
      "0                     Total_Parcelas    0.176699\n",
      "34         Tipo_Empregado_Contratado    0.080145\n",
      "35            Tipo_Empregado_Efetivo    0.070807\n",
      "37         Tipo_Empregado_Temporário    0.062067\n",
      "33           Tipo_Produto_Empréstimo    0.027068\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.026768\n",
      "2                   Muitos_Contratos    0.020507\n",
      "6          Convênio_PREF. ANANINDEUA    0.017099\n",
      "7           Convênio_PREF. ARAÇATUBA    0.016787\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.8515 | PR-AUC(AP): 0.8935\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.9037 | PR-AUC(AP): 0.9401\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                            Feature       Gain\n",
      "0         Tipo_Empregado_Contratado  59.010044\n",
      "1         Convênio_PREF. ANANINDEUA  15.344117\n",
      "2  Convênio_PREF. JUAZEIRO DO NORTE  13.317809\n",
      "3            Tipo_Empregado_Efetivo   8.901773\n",
      "4         Tipo_Empregado_Temporário   4.953709\n",
      "5          Convênio_PREF. ARAÇATUBA   4.506571\n",
      "6                    Total_Parcelas   3.694864\n",
      "7         Esfera_Convenio_Municipal   3.428147\n",
      "8             Tipo_Empregado_Outros   3.210012\n",
      "9   Convênio_PREF. CAMPOS DO JORDÃO   3.018659\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3301, number of negative: 1485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.689720 -> initscore=0.798811\n",
      "[LightGBM] [Info] Start training from score 0.798811\n",
      "ROC-AUC: 0.9050 | PR-AUC(AP): 0.9436\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                             Feature         Gain\n",
      "0                     Total_Parcelas  2816.139303\n",
      "34         Tipo_Empregado_Contratado  2734.364401\n",
      "1                      Valor_Parcela  2439.600972\n",
      "6          Convênio_PREF._ANANINDEUA  1089.587671\n",
      "14  Convênio_PREF._JUAZEIRO_DO_NORTE  1042.780587\n",
      "35            Tipo_Empregado_Efetivo   891.671092\n",
      "37         Tipo_Empregado_Temporário   683.432411\n",
      "33           Tipo_Produto_Empréstimo   316.187781\n",
      "2                   Muitos_Contratos   222.807222\n",
      "7           Convênio_PREF._ARAÇATUBA   186.609157\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_60d_Flag\n",
      "========================================================================================\n",
      "#cols treino: 42 | #cols teste: 42\n",
      "Base rate no treino: 0.5295 | no teste: 0.5292\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.8773 | PR-AUC(AP): 0.8697\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Efetivo              4.757073\n",
      "Tipo_Empregado_Temporário           4.121720\n",
      "Tipo_Empregado_Outros               3.139517\n",
      "Convênio_PREF. ANANINDEUA          -2.760890\n",
      "Convênio_PREF. CAMPOS DO JORDÃO     2.293900\n",
      "Convênio_PREF. JUAZEIRO DO NORTE   -2.238141\n",
      "Convênio_PREF. COTIA                2.172997\n",
      "Tipo_Empregado_Contratado          -1.945169\n",
      "Esfera_Convenio_Municipal          -1.942097\n",
      "Convênio_PREF. ARAÇATUBA            1.934173\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8747 | PR-AUC(AP): 0.8537\n",
      "Top 10 importâncias:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.387278\n",
      "0                     Total_Parcelas    0.118706\n",
      "34            Tipo_Empregado_Efetivo    0.083945\n",
      "36         Tipo_Empregado_Temporário    0.083616\n",
      "33         Tipo_Empregado_Contratado    0.052711\n",
      "7           Convênio_PREF. ARAÇATUBA    0.030508\n",
      "32           Tipo_Produto_Empréstimo    0.029651\n",
      "2                   Muitos_Contratos    0.022465\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.020289\n",
      "37         Esfera_Convenio_Municipal    0.018141\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.8639 | PR-AUC(AP): 0.8440\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8971 | PR-AUC(AP): 0.8936\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                            Feature       Gain\n",
      "0         Tipo_Empregado_Contratado  62.079494\n",
      "1         Esfera_Convenio_Municipal  19.690325\n",
      "2         Tipo_Empregado_Temporário  16.682697\n",
      "3            Tipo_Empregado_Efetivo  15.837033\n",
      "4  Convênio_PREF. JUAZEIRO DO NORTE  15.316132\n",
      "5         Convênio_PREF. ANANINDEUA  11.095028\n",
      "6          Convênio_PREF. ARAÇATUBA  10.613433\n",
      "7             Tipo_Empregado_Outros   9.748263\n",
      "8   Convênio_PREF. CAMPOS DO JORDÃO   7.016922\n",
      "9              Convênio_PREF. SALTO   6.234475\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2534, number of negative: 2252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.529461 -> initscore=0.117980\n",
      "[LightGBM] [Info] Start training from score 0.117980\n",
      "ROC-AUC: 0.8994 | PR-AUC(AP): 0.8936\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                             Feature         Gain\n",
      "0                     Total_Parcelas  3539.281460\n",
      "1                      Valor_Parcela  3093.084733\n",
      "33         Tipo_Empregado_Contratado  3021.354140\n",
      "36         Tipo_Empregado_Temporário  2316.134112\n",
      "7           Convênio_PREF._ARAÇATUBA  1213.586001\n",
      "37         Esfera_Convenio_Municipal   892.450835\n",
      "14  Convênio_PREF._JUAZEIRO_DO_NORTE   883.655868\n",
      "32           Tipo_Produto_Empréstimo   810.461424\n",
      "34            Tipo_Empregado_Efetivo   667.683942\n",
      "6          Convênio_PREF._ANANINDEUA   608.857904\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_90d_Flag\n",
      "========================================================================================\n",
      "#cols treino: 44 | #cols teste: 44\n",
      "Base rate no treino: 0.3354 | no teste: 0.3353\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.7973 | PR-AUC(AP): 0.6383\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Efetivo              4.324904\n",
      "Tipo_Empregado_Temporário           3.017531\n",
      "Convênio_PREF. JUAZEIRO DO NORTE   -2.942102\n",
      "Tipo_Empregado_Outros               2.877902\n",
      "Convênio_PREF. SANTA LUZIA          2.475085\n",
      "Tipo_Empregado_Contratado          -2.243557\n",
      "Esfera_Convenio_Municipal          -2.038175\n",
      "Convênio_PREF. ANANINDEUA          -1.581359\n",
      "Convênio_PREF. COTIA                1.432552\n",
      "Convênio_PREF. IATI                 1.375572\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8061 | PR-AUC(AP): 0.6830\n",
      "Top 10 importâncias:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.481237\n",
      "0                     Total_Parcelas    0.111476\n",
      "36            Tipo_Empregado_Efetivo    0.067914\n",
      "38         Tipo_Empregado_Temporário    0.051040\n",
      "34           Tipo_Produto_Empréstimo    0.036698\n",
      "35         Tipo_Empregado_Contratado    0.036000\n",
      "2                   Muitos_Contratos    0.031126\n",
      "39         Esfera_Convenio_Municipal    0.024438\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.018221\n",
      "33           Tipo_Produto_Cartão RMC    0.014670\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.7935 | PR-AUC(AP): 0.6223\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8466 | PR-AUC(AP): 0.7343\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                            Feature       Gain\n",
      "0         Tipo_Empregado_Contratado  59.614407\n",
      "1  Convênio_PREF. JUAZEIRO DO NORTE  32.513329\n",
      "2         Esfera_Convenio_Municipal  32.173077\n",
      "3         Tipo_Empregado_Temporário  16.664646\n",
      "4         Convênio_PREF. ANANINDEUA  16.566357\n",
      "5            Tipo_Empregado_Efetivo   9.523769\n",
      "6        Convênio_PREF. SANTA LUZIA   8.151536\n",
      "7           Tipo_Produto_Empréstimo   6.967861\n",
      "8             Tipo_Empregado_Outros   6.246767\n",
      "9               Convênio_GOV. GOIAS   4.775796\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1605, number of negative: 3181\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335353 -> initscore=-0.684072\n",
      "[LightGBM] [Info] Start training from score -0.684072\n",
      "ROC-AUC: 0.8503 | PR-AUC(AP): 0.7442\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                             Feature         Gain\n",
      "1                      Valor_Parcela  4349.965948\n",
      "0                     Total_Parcelas  4141.356128\n",
      "35         Tipo_Empregado_Contratado  2941.717724\n",
      "39         Esfera_Convenio_Municipal  2017.784275\n",
      "14  Convênio_PREF._JUAZEIRO_DO_NORTE  1410.462801\n",
      "38         Tipo_Empregado_Temporário  1281.809645\n",
      "2                   Muitos_Contratos  1249.531951\n",
      "34           Tipo_Produto_Empréstimo  1127.386580\n",
      "36            Tipo_Empregado_Efetivo   933.259082\n",
      "6          Convênio_PREF._ANANINDEUA   657.010165\n",
      "\n",
      "========================================================================================\n",
      "   RESUMO COMPARATIVO FINAL - ROC-AUC\n",
      "========================================================================================\n",
      "                     Vencido_1d_Flag  Vencido_30d_Flag  Vencido_60d_Flag  \\\n",
      "Regressão Logística           0.9372            0.8758            0.8773   \n",
      "Random Forest                 0.9420            0.8923            0.8747   \n",
      "SVM (Kernel RBF)              0.9331            0.8515            0.8639   \n",
      "XGBoost                       0.9484            0.9037            0.8971   \n",
      "LightGBM                      0.9508            0.9050            0.8994   \n",
      "\n",
      "                     Vencido_90d_Flag  \n",
      "Regressão Logística            0.7973  \n",
      "Random Forest                  0.8061  \n",
      "SVM (Kernel RBF)               0.7935  \n",
      "XGBoost                        0.8466  \n",
      "LightGBM                       0.8503  \n",
      "\n",
      "----------------------------------------------------------------------------------------\n",
      "Considerando a média de ROC-AUC em todos os alvos, o melhor modelo parece ser: 'LightGBM'\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script de Treinamento e Avaliação de Modelos de Machine Learning\n",
    "VERSÃO FINAL — ancorado em 'Data de Inclusão', sem vazamentos, com checagens\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 1: CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
    "# =============================================================================\n",
    "def carregar_e_preparar_dados_corrigido():\n",
    "    \"\"\"\n",
    "    1) Lê StarCard.xlsx e Originadores.xlsx\n",
    "    2) Usa 'Data de Inclusão' como relógio:\n",
    "       - snapshot determinístico por CCB = menor Data de Inclusão disponível\n",
    "       - _MuitosContratos por ordenação temporal (cumcount)\n",
    "       - Idade calculada na Data de Inclusão (fallback em DataGeracao se nula)\n",
    "    3) Cria labels 'Vencido_{1,30,60,90}d' com base em dias_de_atraso no snapshot.\n",
    "    4) Evita vazamentos: não inclui colunas temporais/labels em X.\n",
    "    \"\"\"\n",
    "    print(\"=\"*88)\n",
    "    print(\"ETAPA 1: Carregando e preparando os dados (VERSÃO FINAL)...\")\n",
    "    print(\"=\"*88)\n",
    "\n",
    "    #! PATHS ----------------------------------------------------------------------\n",
    "    # ATENÇÃO: REDIFINIR AQUI OS PATHS PARA A SUA MÁQUINA\n",
    "    path_starcard = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\StarCard.xlsx'\n",
    "    path_originadores = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\Originadores.xlsx'\n",
    "    #------------------------------------------------------------------------------\n",
    "\n",
    "    # ---------- Leitura ----------\n",
    "    df_starcard = pd.read_excel(path_starcard)\n",
    "    cols_originadores = ['CCB', 'Data de Inclusão', 'Prazo', 'Valor Parcela', 'Produto', 'Convênio', 'CAPAG']\n",
    "    # CAPAG pode não existir; vamos ler com try simples\n",
    "    try:\n",
    "        df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "    except ValueError:\n",
    "        # remove CAPAG se não existir\n",
    "        cols_originadores = [c for c in cols_originadores if c != 'CAPAG']\n",
    "        df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "\n",
    "    # Normaliza datas e unicidade por CCB (primeira inclusão)\n",
    "    if 'Data de Inclusão' in df_originadores.columns:\n",
    "        df_originadores['Data de Inclusão'] = pd.to_datetime(df_originadores['Data de Inclusão'], errors='coerce')\n",
    "        df_originadores = (\n",
    "            df_originadores\n",
    "            .sort_values(['CCB', 'Data de Inclusão'])\n",
    "            .drop_duplicates(subset='CCB', keep='first')\n",
    "        )\n",
    "\n",
    "    # Merge\n",
    "    df_merged = pd.merge(df_starcard, df_originadores, on='CCB', how='left', suffixes=('', '_orig'))\n",
    "\n",
    "    # Renomeios\n",
    "    df_merged = df_merged.rename(columns={\n",
    "        'Data Referencia': 'DataGeracao',\n",
    "        'Data Vencimento': 'DataVencimento',\n",
    "        'ID Cliente': 'SacadoID'\n",
    "    })\n",
    "\n",
    "    # Tipos de data\n",
    "    for col in ['DataGeracao', 'DataVencimento', 'Data de Nascimento']:\n",
    "        if col in df_merged.columns:\n",
    "            df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')\n",
    "\n",
    "    # Conversão monetária\n",
    "    if 'Valor Parcela' in df_merged.columns and df_merged['Valor Parcela'].dtype == 'object':\n",
    "        s = df_merged['Valor Parcela'].astype(str)\n",
    "        s = s.str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()\n",
    "        df_merged['Valor Parcela'] = pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    # Base\n",
    "    df_base = df_merged.copy()\n",
    "    del df_starcard, df_originadores, df_merged\n",
    "\n",
    "    # Limpezas básicas\n",
    "    if 'Produto' in df_base.columns:\n",
    "        df_base['Produto'] = df_base['Produto'].fillna('')\n",
    "    if 'Convênio' in df_base.columns:\n",
    "        df_base['Convênio'] = df_base['Convênio'].fillna('')\n",
    "\n",
    "    # Feature dias_de_atraso (com DataGeracao do snapshot; se DataGeracao é constante, vira “situação no dia da extração”)\n",
    "    if 'DataGeracao' in df_base.columns and 'DataVencimento' in df_base.columns:\n",
    "        df_base['dias_de_atraso'] = (df_base['DataGeracao'] - df_base['DataVencimento']).dt.days\n",
    "\n",
    "    # Buckets de produto/empregado/convênio\n",
    "    condicoes_produto = [\n",
    "        df_base['Produto'].str.contains('Empréstimo', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Cartão RMC', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Cartão Benefício', case=False, na=False)\n",
    "    ]\n",
    "    opcoes_produto = ['Empréstimo', 'Cartão RMC', 'Cartão Benefício']\n",
    "    df_base['_TipoProduto'] = np.select(condicoes_produto, opcoes_produto, default='Outros')\n",
    "\n",
    "    condicoes_empregado = [\n",
    "        df_base['Produto'].str.contains('Efetivo|Efetivio', case=False, na=False, regex=True),\n",
    "        df_base['Produto'].str.contains('Temporário', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('CONTRATADO', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Comissionado', case=False, na=False)\n",
    "    ]\n",
    "    opcoes_empregado = ['Efetivo', 'Temporário', 'Contratado', 'Comissionado']\n",
    "    df_base['_TipoEmpregado'] = np.select(condicoes_empregado, opcoes_empregado, default='Outros')\n",
    "\n",
    "    # Regex de convênio (ajustada para 'PREF' genérico; mantém 'AGN -' e 'GOV.')\n",
    "    condicoes_convenio = [\n",
    "        df_base['Convênio'].str.contains(r'GOV\\.|AGN -', case=False, na=False, regex=True),\n",
    "        df_base['Convênio'].str.contains(r'PREF', case=False, na=False, regex=True)\n",
    "    ]\n",
    "    opcoes_convenio = ['Estadual', 'Municipal']\n",
    "    df_base['_EsferaConvenio'] = np.select(condicoes_convenio, opcoes_convenio, default='Outros')\n",
    "\n",
    "    # ----- Relógio: Data de Inclusão -----\n",
    "    if 'Data de Inclusão' not in df_base.columns:\n",
    "        raise ValueError(\"Coluna 'Data de Inclusão' não encontrada após o merge. Verifique Originadores.xlsx.\")\n",
    "\n",
    "    # Ordenação temporal por inclusão para _MuitosContratos\n",
    "    df_base = df_base.sort_values(['SacadoID', 'Data de Inclusão', 'CCB'])\n",
    "    df_base['_NumContratosAnteriores'] = df_base.groupby('SacadoID').cumcount()\n",
    "    df_base['_MuitosContratos'] = (df_base['_NumContratosAnteriores'] >= 2).astype(int)\n",
    "\n",
    "    # Idade na Data de Inclusão (fallback em DataGeracao, se inclusão nula)\n",
    "    if 'Data de Nascimento' in df_base.columns:\n",
    "        base_idade = df_base['Data de Inclusão'].fillna(df_base.get('DataGeracao'))\n",
    "        df_base['_IdadeCliente'] = (base_idade - df_base['Data de Nascimento']).dt.days / 365.25\n",
    "        bins = [0, 37, 45, 53, 120]\n",
    "        labels = ['Até 37 anos', '38 a 45 anos', '46 a 53 anos', '54 anos ou mais']\n",
    "        df_base['_IdadesBins'] = pd.cut(df_base['_IdadeCliente'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # ---------- Labels por CCB ----------\n",
    "    # Se tiver múltiplas linhas por CCB (parcelas/linhas), agregue o maior atraso\n",
    "    if 'dias_de_atraso' not in df_base.columns:\n",
    "        raise ValueError(\"'dias_de_atraso' não foi criado. Verifique 'DataGeracao' e 'DataVencimento'.\")\n",
    "\n",
    "    atraso_por_ccb = (\n",
    "        df_base.groupby('CCB', as_index=False)['dias_de_atraso'].max()\n",
    "        .rename(columns={'dias_de_atraso': 'max_dias_atraso'})\n",
    "    )\n",
    "    for k in [1, 30, 60, 90]:\n",
    "        atraso_por_ccb[f'Vencido_{k}d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= k).astype(int)\n",
    "\n",
    "    # ---------- Snapshot determinístico por CCB ----------\n",
    "    # referência temporal: Data de Inclusão (fallback DataGeracao)\n",
    "    df_base['DataInclRef'] = df_base['Data de Inclusão'].fillna(df_base.get('DataGeracao'))\n",
    "    snapshots = df_base.sort_values(['CCB', 'DataInclRef', 'DataVencimento'])\n",
    "    primeiro_snap = snapshots.groupby('CCB', as_index=False).first()\n",
    "\n",
    "    features_para_modelo = [\n",
    "        'CCB', 'Convênio', 'CAPAG', 'Prazo', 'Valor Parcela',\n",
    "        '_TipoProduto', '_TipoEmpregado', '_EsferaConvenio', '_IdadesBins', '_MuitosContratos'\n",
    "    ]\n",
    "    ausentes = sorted(list(set(features_para_modelo) - set(primeiro_snap.columns)))\n",
    "    if ausentes:\n",
    "        print(f\"[AVISO] Features ausentes e removidas (não encontradas no snapshot): {ausentes}\")\n",
    "\n",
    "    features_existentes = [f for f in features_para_modelo if f in primeiro_snap.columns]\n",
    "    df_features = primeiro_snap[features_existentes]\n",
    "\n",
    "    # df_ml final\n",
    "    df_ml = pd.merge(df_features, atraso_por_ccb, on='CCB', how='inner').rename(columns={\n",
    "        'Prazo': 'Total_Parcelas',\n",
    "        'Valor Parcela': 'Valor_Parcela',\n",
    "        '_EsferaConvenio': 'Esfera_Convenio',\n",
    "        '_IdadesBins': 'Faixa_Idade',\n",
    "        '_MuitosContratos': 'Muitos_Contratos',\n",
    "        '_TipoProduto': 'Tipo_Produto',\n",
    "        '_TipoEmpregado': 'Tipo_Empregado'\n",
    "    })\n",
    "\n",
    "    # Checagens úteis\n",
    "    assert df_ml['CCB'].is_unique, \"CCB não está único no df_ml! Revise o snapshot por CCB.\"\n",
    "    assert df_ml[['Vencido_1d_Flag','Vencido_30d_Flag','Vencido_60d_Flag','Vencido_90d_Flag']].notna().all().all(), \\\n",
    "        \"Algum label Vencido_* está com NaN.\"\n",
    "\n",
    "    print(\"Dataset para ML criado com 1 linha por CCB (snapshot na Data de Inclusão) e labels agregados.\")\n",
    "    return df_ml\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 2: TREINAMENTO E AVALIAÇÃO\n",
    "# =============================================================================\n",
    "def treinar_e_avaliar(df_ml):\n",
    "    targets = ['Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
    "    resultados_finais = pd.DataFrame()\n",
    "\n",
    "    for target in targets:\n",
    "        print(\"\\n\" + \"=\"*88)\n",
    "        print(f\"   TREINANDO MODELOS PARA O ALVO: {target}\")\n",
    "        print(\"=\"*88)\n",
    "\n",
    "        # Define X e y removendo colunas proibidas\n",
    "        X = df_ml.drop(columns=targets + ['CCB', 'max_dias_atraso'])\n",
    "        y = df_ml[target]\n",
    "\n",
    "        # Identifica colunas numéricas originais (antes de dummies)\n",
    "        numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "        categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        # Split estratificado\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.30, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # Dummification APÓS o split + alinhamento\n",
    "        X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "        X_test  = pd.get_dummies(X_test,  columns=categorical_features, drop_first=True)\n",
    "        X_test  = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "        # Guardas básicas\n",
    "        print(\"#cols treino:\", X_train.shape[1], \"| #cols teste:\", X_test.shape[1])\n",
    "        assert list(X_train.columns) == list(X_test.columns), \"Treino e teste desalinhados!\"\n",
    "\n",
    "        # Imputação + Escalonamento SOMENTE nas numéricas originais (interseção)\n",
    "        num_cols = [c for c in numerical_features if c in X_train.columns]\n",
    "        if len(num_cols) > 0:\n",
    "            imputer = SimpleImputer(strategy='median')\n",
    "            X_train[num_cols] = imputer.fit_transform(X_train[num_cols])\n",
    "            X_test[num_cols]  = imputer.transform(X_test[num_cols])\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "            X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
    "\n",
    "        # Log base rates\n",
    "        print(\"Base rate no treino:\", float(y_train.mean()).__round__(4), \"| no teste:\", float(y_test.mean()).__round__(4))\n",
    "\n",
    "        # scale_pos_weight com guarda\n",
    "        pos = int((y_train == 1).sum())\n",
    "        neg = int((y_train == 0).sum())\n",
    "        if pos == 0:\n",
    "            print(f\"[AVISO] Classe positiva ausente no treino para {target}. Ajustando scale_pos_weight=1.0.\")\n",
    "            scale_pos_weight = 1.0\n",
    "        else:\n",
    "            scale_pos_weight = neg / pos\n",
    "\n",
    "        # Modelos\n",
    "        models = {\n",
    "            \"Regressão Logística\": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
    "            \"Random Forest\":       RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "            \"SVM (Kernel RBF)\":    SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced'),\n",
    "            \"XGBoost\":             xgb.XGBClassifier(random_state=42, eval_metric='logloss',\n",
    "                                                     use_label_encoder=False, scale_pos_weight=scale_pos_weight,\n",
    "                                                     n_jobs=-1),\n",
    "            \"LightGBM\":            lgb.LGBMClassifier(random_state=42, scale_pos_weight=scale_pos_weight,\n",
    "                                                      n_jobs=-1)\n",
    "        }\n",
    "\n",
    "        resultados_target = {}\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\n--- Treinando {name} ---\")\n",
    "            model.fit(X_train, y_train)\n",
    "            # Probabilidades\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            # Métricas\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            ap  = average_precision_score(y_test, y_pred_proba)\n",
    "            resultados_target[name] = {'ROC-AUC': auc, 'PR-AUC(AP)': ap}\n",
    "            print(f\"ROC-AUC: {auc:.4f} | PR-AUC(AP): {ap:.4f}\")\n",
    "\n",
    "            # Importâncias — árvores/GBMs\n",
    "            if isinstance(model, xgb.XGBClassifier):\n",
    "                booster = model.get_booster()\n",
    "                imp = booster.get_score(importance_type='gain')\n",
    "                if len(imp) > 0:\n",
    "                    importances = (pd.Series(imp).sort_values(ascending=False).head(10)\n",
    "                                   .rename('Gain').reset_index().rename(columns={'index': 'Feature'}))\n",
    "                    print(\"Top 10 importâncias (XGB, gain):\")\n",
    "                    print(importances)\n",
    "            elif isinstance(model, lgb.LGBMClassifier):\n",
    "                feats = model.feature_name_\n",
    "                gains = model.booster_.feature_importance(importance_type='gain')\n",
    "                importances = (pd.DataFrame({'Feature': feats, 'Gain': gains})\n",
    "                               .sort_values('Gain', ascending=False).head(10))\n",
    "                print(\"Top 10 importâncias (LGBM, gain):\")\n",
    "                print(importances)\n",
    "            elif hasattr(model, 'feature_importances_'):\n",
    "                importances = pd.DataFrame({\n",
    "                    'Feature': X_train.columns,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values('Importance', ascending=False).head(10)\n",
    "                print(\"Top 10 importâncias:\")\n",
    "                print(importances)\n",
    "            elif isinstance(model, LogisticRegression):\n",
    "                coefs = pd.Series(model.coef_[0], index=X_train.columns).sort_values(key=np.abs, ascending=False).head(10)\n",
    "                print(\"Top 10 |coef| (Regressão Logística):\")\n",
    "                print(coefs)\n",
    "\n",
    "        # Acumula resultados por alvo\n",
    "        df_resultados_target = (pd.DataFrame(resultados_target).T)\n",
    "        # guarda apenas ROC-AUC numa tabela comparativa “clássica”\n",
    "        resultados_finais = pd.concat([resultados_finais, df_resultados_target['ROC-AUC'].rename(target)], axis=1)\n",
    "\n",
    "        # Checagens adicionais úteis\n",
    "        suspeitas = {'dias_de_atraso', 'max_dias_atraso', 'DataGeracao', 'DataVencimento', 'Data de Inclusão'}\n",
    "        suspeitas_presentes = sorted(list(set(X_train.columns) & suspeitas))\n",
    "        if suspeitas_presentes:\n",
    "            print(f\"[ALERTA] Colunas suspeitas presentes em X: {suspeitas_presentes}\")\n",
    "\n",
    "    return resultados_finais\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 3: EXECUÇÃO\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df_ml = carregar_e_preparar_dados_corrigido()\n",
    "\n",
    "    # Relatório rápido de base rates por label\n",
    "    print(\"\\nBase rates dos alvos (df_ml):\")\n",
    "    print(df_ml[['Vencido_1d_Flag','Vencido_30d_Flag','Vencido_60d_Flag','Vencido_90d_Flag']].mean().round(4))\n",
    "\n",
    "    resultados_finais = treinar_e_avaliar(df_ml)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*88)\n",
    "    print(\"   RESUMO COMPARATIVO FINAL - ROC-AUC\")\n",
    "    print(\"=\"*88)\n",
    "    print(resultados_finais.round(4))\n",
    "\n",
    "    melhor_modelo_geral = resultados_finais.mean(axis=1).idxmax()\n",
    "    print(\"\\n\" + \"-\"*88)\n",
    "    print(f\"Considerando a média de ROC-AUC em todos os alvos, o melhor modelo parece ser: '{melhor_modelo_geral}'\")\n",
    "    print(\"-\"*88)\n",
    "\n",
    "\n",
    "## esse aqui estava bom, mas nao reconhece o CAPAG e nao depura direito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bb6614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "ETAPA 1: Carregando e preparando os dados (VERSÃO FINAL)...\n",
      "========================================================================================\n",
      "\n",
      "Dataset para ML criado com 6838 linhas (CCBs) e 15 colunas.\n",
      "\n",
      "Base rates dos alvos (df_ml):\n",
      "Vencido_1d_Flag     0.8157\n",
      "Vencido_30d_Flag    0.6897\n",
      "Vencido_60d_Flag    0.5294\n",
      "Vencido_90d_Flag    0.3353\n",
      "dtype: float64\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_1d_Flag\n",
      "========================================================================================\n",
      "#cols treino: 43 | #cols teste: 43\n",
      "Base rate no treino: 0.8157 | no teste: 0.8158\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.9372 | PR-AUC(AP): 0.9819\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Contratado         -4.054948\n",
      "Convênio_PREF. ANANINDEUA         -3.682524\n",
      "Tipo_Empregado_Temporário          3.488191\n",
      "Tipo_Empregado_Efetivo             2.488744\n",
      "Convênio_PREF. CAMPOS DO JORDÃO    2.305191\n",
      "Tipo_Produto_Empréstimo           -1.713887\n",
      "Convênio_PREF. COTIA               1.706626\n",
      "Convênio_PREF. EMBU DAS ARTES     -1.546657\n",
      "Convênio_PREF. SANTA LUZIA         1.468440\n",
      "Esfera_Convenio_Municipal         -1.463444\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.9420 | PR-AUC(AP): 0.9808\n",
      "Top 10 importâncias:\n",
      "                      Feature  Importance\n",
      "0              Total_Parcelas    0.192702\n",
      "1               Valor_Parcela    0.187390\n",
      "34  Tipo_Empregado_Contratado    0.168285\n",
      "37  Tipo_Empregado_Temporário    0.111029\n",
      "35     Tipo_Empregado_Efetivo    0.047886\n",
      "33    Tipo_Produto_Empréstimo    0.029256\n",
      "38  Esfera_Convenio_Municipal    0.027040\n",
      "2            Muitos_Contratos    0.022381\n",
      "6   Convênio_PREF. ANANINDEUA    0.020536\n",
      "3         Convênio_GOV. GOIAS    0.019571\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.9331 | PR-AUC(AP): 0.9810\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.9484 | PR-AUC(AP): 0.9863\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                            Feature       Gain\n",
      "0         Esfera_Convenio_Municipal  33.885242\n",
      "1         Tipo_Empregado_Contratado  29.187881\n",
      "2            Tipo_Empregado_Efetivo   4.770521\n",
      "3         Tipo_Empregado_Temporário   3.859263\n",
      "4                    Total_Parcelas   3.314641\n",
      "5         Convênio_PREF. ANANINDEUA   2.274945\n",
      "6          Convênio_PREF. ARAÇATUBA   1.898137\n",
      "7              Convênio_PREF. SALTO   1.884457\n",
      "8              Convênio_PREF. COTIA   1.702878\n",
      "9  Convênio_PREF. JUAZEIRO DO NORTE   1.576027\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3904, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815712 -> initscore=1.487565\n",
      "[LightGBM] [Info] Start training from score 1.487565\n",
      "ROC-AUC: 0.9508 | PR-AUC(AP): 0.9869\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                      Feature         Gain\n",
      "34  Tipo_Empregado_Contratado  2603.465463\n",
      "0              Total_Parcelas  2593.074954\n",
      "1               Valor_Parcela  1431.391408\n",
      "38  Esfera_Convenio_Municipal  1115.476324\n",
      "35     Tipo_Empregado_Efetivo   346.447706\n",
      "37  Tipo_Empregado_Temporário   332.629987\n",
      "6   Convênio_PREF._ANANINDEUA   226.279177\n",
      "33    Tipo_Produto_Empréstimo   178.698612\n",
      "2            Muitos_Contratos   178.079929\n",
      "7    Convênio_PREF._ARAÇATUBA   117.252454\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_30d_Flag\n",
      "========================================================================================\n",
      "#cols treino: 43 | #cols teste: 43\n",
      "Base rate no treino: 0.6897 | no teste: 0.6896\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.8758 | PR-AUC(AP): 0.9223\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Contratado          -3.523508\n",
      "Convênio_PREF. ANANINDEUA          -3.097653\n",
      "Tipo_Empregado_Efetivo              3.085102\n",
      "Tipo_Empregado_Temporário           2.678431\n",
      "Convênio_PREF. CAMPOS DO JORDÃO     2.054734\n",
      "Convênio_PREF. EMBU DAS ARTES      -2.045484\n",
      "Convênio_PREF. JUAZEIRO DO NORTE   -2.007333\n",
      "Convênio_PREF. COTIA                1.896630\n",
      "Esfera_Convenio_Municipal          -1.682417\n",
      "Convênio_PREF. SANTA LUZIA          1.615778\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8923 | PR-AUC(AP): 0.9298\n",
      "Top 10 importâncias:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.354039\n",
      "0                     Total_Parcelas    0.176699\n",
      "34         Tipo_Empregado_Contratado    0.080145\n",
      "35            Tipo_Empregado_Efetivo    0.070807\n",
      "37         Tipo_Empregado_Temporário    0.062067\n",
      "33           Tipo_Produto_Empréstimo    0.027068\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.026768\n",
      "2                   Muitos_Contratos    0.020507\n",
      "6          Convênio_PREF. ANANINDEUA    0.017099\n",
      "7           Convênio_PREF. ARAÇATUBA    0.016787\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.8515 | PR-AUC(AP): 0.8935\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.9037 | PR-AUC(AP): 0.9401\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                            Feature       Gain\n",
      "0         Tipo_Empregado_Contratado  59.010044\n",
      "1         Convênio_PREF. ANANINDEUA  15.344117\n",
      "2  Convênio_PREF. JUAZEIRO DO NORTE  13.317809\n",
      "3            Tipo_Empregado_Efetivo   8.901773\n",
      "4         Tipo_Empregado_Temporário   4.953709\n",
      "5          Convênio_PREF. ARAÇATUBA   4.506571\n",
      "6                    Total_Parcelas   3.694864\n",
      "7         Esfera_Convenio_Municipal   3.428147\n",
      "8             Tipo_Empregado_Outros   3.210012\n",
      "9   Convênio_PREF. CAMPOS DO JORDÃO   3.018659\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3301, number of negative: 1485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.689720 -> initscore=0.798811\n",
      "[LightGBM] [Info] Start training from score 0.798811\n",
      "ROC-AUC: 0.9050 | PR-AUC(AP): 0.9436\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                             Feature         Gain\n",
      "0                     Total_Parcelas  2816.139303\n",
      "34         Tipo_Empregado_Contratado  2734.364401\n",
      "1                      Valor_Parcela  2439.600972\n",
      "6          Convênio_PREF._ANANINDEUA  1089.587671\n",
      "14  Convênio_PREF._JUAZEIRO_DO_NORTE  1042.780587\n",
      "35            Tipo_Empregado_Efetivo   891.671092\n",
      "37         Tipo_Empregado_Temporário   683.432411\n",
      "33           Tipo_Produto_Empréstimo   316.187781\n",
      "2                   Muitos_Contratos   222.807222\n",
      "7           Convênio_PREF._ARAÇATUBA   186.609157\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_60d_Flag\n",
      "========================================================================================\n",
      "#cols treino: 42 | #cols teste: 42\n",
      "Base rate no treino: 0.5295 | no teste: 0.5292\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.8773 | PR-AUC(AP): 0.8697\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Efetivo              4.757073\n",
      "Tipo_Empregado_Temporário           4.121720\n",
      "Tipo_Empregado_Outros               3.139517\n",
      "Convênio_PREF. ANANINDEUA          -2.760890\n",
      "Convênio_PREF. CAMPOS DO JORDÃO     2.293900\n",
      "Convênio_PREF. JUAZEIRO DO NORTE   -2.238141\n",
      "Convênio_PREF. COTIA                2.172997\n",
      "Tipo_Empregado_Contratado          -1.945169\n",
      "Esfera_Convenio_Municipal          -1.942097\n",
      "Convênio_PREF. ARAÇATUBA            1.934173\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8747 | PR-AUC(AP): 0.8537\n",
      "Top 10 importâncias:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.387278\n",
      "0                     Total_Parcelas    0.118706\n",
      "34            Tipo_Empregado_Efetivo    0.083945\n",
      "36         Tipo_Empregado_Temporário    0.083616\n",
      "33         Tipo_Empregado_Contratado    0.052711\n",
      "7           Convênio_PREF. ARAÇATUBA    0.030508\n",
      "32           Tipo_Produto_Empréstimo    0.029651\n",
      "2                   Muitos_Contratos    0.022465\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.020289\n",
      "37         Esfera_Convenio_Municipal    0.018141\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.8639 | PR-AUC(AP): 0.8440\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8971 | PR-AUC(AP): 0.8936\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                            Feature       Gain\n",
      "0         Tipo_Empregado_Contratado  62.079494\n",
      "1         Esfera_Convenio_Municipal  19.690325\n",
      "2         Tipo_Empregado_Temporário  16.682697\n",
      "3            Tipo_Empregado_Efetivo  15.837033\n",
      "4  Convênio_PREF. JUAZEIRO DO NORTE  15.316132\n",
      "5         Convênio_PREF. ANANINDEUA  11.095028\n",
      "6          Convênio_PREF. ARAÇATUBA  10.613433\n",
      "7             Tipo_Empregado_Outros   9.748263\n",
      "8   Convênio_PREF. CAMPOS DO JORDÃO   7.016922\n",
      "9              Convênio_PREF. SALTO   6.234475\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2534, number of negative: 2252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.529461 -> initscore=0.117980\n",
      "[LightGBM] [Info] Start training from score 0.117980\n",
      "ROC-AUC: 0.8994 | PR-AUC(AP): 0.8936\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                             Feature         Gain\n",
      "0                     Total_Parcelas  3539.281460\n",
      "1                      Valor_Parcela  3093.084733\n",
      "33         Tipo_Empregado_Contratado  3021.354140\n",
      "36         Tipo_Empregado_Temporário  2316.134112\n",
      "7           Convênio_PREF._ARAÇATUBA  1213.586001\n",
      "37         Esfera_Convenio_Municipal   892.450835\n",
      "14  Convênio_PREF._JUAZEIRO_DO_NORTE   883.655868\n",
      "32           Tipo_Produto_Empréstimo   810.461424\n",
      "34            Tipo_Empregado_Efetivo   667.683942\n",
      "6          Convênio_PREF._ANANINDEUA   608.857904\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_90d_Flag\n",
      "========================================================================================\n",
      "#cols treino: 44 | #cols teste: 44\n",
      "Base rate no treino: 0.3354 | no teste: 0.3353\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.7973 | PR-AUC(AP): 0.6383\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Efetivo              4.324904\n",
      "Tipo_Empregado_Temporário           3.017531\n",
      "Convênio_PREF. JUAZEIRO DO NORTE   -2.942102\n",
      "Tipo_Empregado_Outros               2.877902\n",
      "Convênio_PREF. SANTA LUZIA          2.475085\n",
      "Tipo_Empregado_Contratado          -2.243557\n",
      "Esfera_Convenio_Municipal          -2.038175\n",
      "Convênio_PREF. ANANINDEUA          -1.581359\n",
      "Convênio_PREF. COTIA                1.432552\n",
      "Convênio_PREF. IATI                 1.375572\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8061 | PR-AUC(AP): 0.6830\n",
      "Top 10 importâncias:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.481237\n",
      "0                     Total_Parcelas    0.111476\n",
      "36            Tipo_Empregado_Efetivo    0.067914\n",
      "38         Tipo_Empregado_Temporário    0.051040\n",
      "34           Tipo_Produto_Empréstimo    0.036698\n",
      "35         Tipo_Empregado_Contratado    0.036000\n",
      "2                   Muitos_Contratos    0.031126\n",
      "39         Esfera_Convenio_Municipal    0.024438\n",
      "14  Convênio_PREF. JUAZEIRO DO NORTE    0.018221\n",
      "33           Tipo_Produto_Cartão RMC    0.014670\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.7935 | PR-AUC(AP): 0.6223\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8466 | PR-AUC(AP): 0.7343\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                            Feature       Gain\n",
      "0         Tipo_Empregado_Contratado  59.614407\n",
      "1  Convênio_PREF. JUAZEIRO DO NORTE  32.513329\n",
      "2         Esfera_Convenio_Municipal  32.173077\n",
      "3         Tipo_Empregado_Temporário  16.664646\n",
      "4         Convênio_PREF. ANANINDEUA  16.566357\n",
      "5            Tipo_Empregado_Efetivo   9.523769\n",
      "6        Convênio_PREF. SANTA LUZIA   8.151536\n",
      "7           Tipo_Produto_Empréstimo   6.967861\n",
      "8             Tipo_Empregado_Outros   6.246767\n",
      "9               Convênio_GOV. GOIAS   4.775796\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1605, number of negative: 3181\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335353 -> initscore=-0.684072\n",
      "[LightGBM] [Info] Start training from score -0.684072\n",
      "ROC-AUC: 0.8503 | PR-AUC(AP): 0.7442\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                             Feature         Gain\n",
      "1                      Valor_Parcela  4349.965948\n",
      "0                     Total_Parcelas  4141.356128\n",
      "35         Tipo_Empregado_Contratado  2941.717724\n",
      "39         Esfera_Convenio_Municipal  2017.784275\n",
      "14  Convênio_PREF._JUAZEIRO_DO_NORTE  1410.462801\n",
      "38         Tipo_Empregado_Temporário  1281.809645\n",
      "2                   Muitos_Contratos  1249.531951\n",
      "34           Tipo_Produto_Empréstimo  1127.386580\n",
      "36            Tipo_Empregado_Efetivo   933.259082\n",
      "6          Convênio_PREF._ANANINDEUA   657.010165\n",
      "\n",
      "========================================================================================\n",
      "   RESUMO COMPARATIVO FINAL - ROC-AUC\n",
      "========================================================================================\n",
      "                     Vencido_1d_Flag  Vencido_30d_Flag  Vencido_60d_Flag  \\\n",
      "Regressão Logística           0.9372            0.8758            0.8773   \n",
      "Random Forest                 0.9420            0.8923            0.8747   \n",
      "SVM (Kernel RBF)              0.9331            0.8515            0.8639   \n",
      "XGBoost                       0.9484            0.9037            0.8971   \n",
      "LightGBM                      0.9508            0.9050            0.8994   \n",
      "\n",
      "                     Vencido_90d_Flag  \n",
      "Regressão Logística            0.7973  \n",
      "Random Forest                  0.8061  \n",
      "SVM (Kernel RBF)               0.7935  \n",
      "XGBoost                        0.8466  \n",
      "LightGBM                       0.8503  \n",
      "\n",
      "----------------------------------------------------------------------------------------\n",
      "Considerando a média de ROC-AUC em todos os alvos, o melhor modelo parece ser: 'LightGBM'\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script de Treinamento e Avaliação de Modelos de Machine Learning\n",
    "VERSÃO FINAL — ancorado em 'Data de Inclusão', sem vazamentos, com checagens\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 1: CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
    "# =============================================================================\n",
    "def carregar_e_preparar_dados_corrigido():\n",
    "    \"\"\"\n",
    "    1) Lê StarCard.xlsx e Originadores.xlsx\n",
    "    2) Usa 'Data de Inclusão' como relógio:\n",
    "        - snapshot determinístico por CCB = menor Data de Inclusão disponível\n",
    "        - _MuitosContratos por ordenação temporal (cumcount)\n",
    "        - Idade calculada na Data de Inclusão (fallback em DataGeracao se nula)\n",
    "    3) Cria labels 'Vencido_{1,30,60,90}d' com base em dias_de_atraso no snapshot.\n",
    "    4) Evita vazamentos: não inclui colunas temporais/labels em X.\n",
    "    \"\"\"\n",
    "    print(\"=\"*88)\n",
    "    print(\"ETAPA 1: Carregando e preparando os dados (VERSÃO FINAL)...\")\n",
    "    print(\"=\"*88)\n",
    "\n",
    "    #! PATHS ----------------------------------------------------------------------\n",
    "    # ATENÇÃO: REDIFINIR AQUI OS PATHS PARA A SUA MÁQUINA\n",
    "    path_starcard = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\StarCard.xlsx'\n",
    "    path_originadores = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\Originadores.xlsx'\n",
    "    #------------------------------------------------------------------------------\n",
    "\n",
    "    # ---------- Leitura ----------\n",
    "    df_starcard = pd.read_excel(path_starcard)\n",
    "    cols_originadores = ['CCB', 'Data de Inclusão', 'Prazo', 'Valor Parcela', 'Produto', 'Convênio', 'CAPAG']\n",
    "    # CAPAG pode não existir; vamos ler com try simples\n",
    "    try:\n",
    "        df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "    except ValueError:\n",
    "        # <-- SUGESTÃO IMPLEMENTADA\n",
    "        print(\"[ALERTA] Coluna 'CAPAG' não encontrada em Originadores.xlsx. Esta feature será desconsiderada no modelo.\")\n",
    "        cols_originadores = [c for c in cols_originadores if c != 'CAPAG']\n",
    "        df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "\n",
    "    # Normaliza datas e unicidade por CCB (primeira inclusão)\n",
    "    if 'Data de Inclusão' in df_originadores.columns:\n",
    "        df_originadores['Data de Inclusão'] = pd.to_datetime(df_originadores['Data de Inclusão'], errors='coerce')\n",
    "        df_originadores = (\n",
    "            df_originadores\n",
    "            .sort_values(['CCB', 'Data de Inclusão'])\n",
    "            .drop_duplicates(subset='CCB', keep='first')\n",
    "        )\n",
    "\n",
    "    # Merge\n",
    "    df_merged = pd.merge(df_starcard, df_originadores, on='CCB', how='left', suffixes=('', '_orig'))\n",
    "\n",
    "    # Renomeios\n",
    "    df_merged = df_merged.rename(columns={\n",
    "        'Data Referencia': 'DataGeracao',\n",
    "        'Data Vencimento': 'DataVencimento',\n",
    "        'ID Cliente': 'SacadoID'\n",
    "    })\n",
    "\n",
    "    # Tipos de data\n",
    "    for col in ['DataGeracao', 'DataVencimento', 'Data de Nascimento']:\n",
    "        if col in df_merged.columns:\n",
    "            df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')\n",
    "\n",
    "    # Conversão monetária\n",
    "    if 'Valor Parcela' in df_merged.columns and df_merged['Valor Parcela'].dtype == 'object':\n",
    "        s = df_merged['Valor Parcela'].astype(str)\n",
    "        s = s.str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()\n",
    "        df_merged['Valor Parcela'] = pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    # Base\n",
    "    df_base = df_merged.copy()\n",
    "    del df_starcard, df_originadores, df_merged\n",
    "\n",
    "    # Limpezas básicas\n",
    "    if 'Produto' in df_base.columns:\n",
    "        df_base['Produto'] = df_base['Produto'].fillna('')\n",
    "    if 'Convênio' in df_base.columns:\n",
    "        df_base['Convênio'] = df_base['Convênio'].fillna('')\n",
    "\n",
    "    # Feature dias_de_atraso (com DataGeracao do snapshot; se DataGeracao é constante, vira “situação no dia da extração”)\n",
    "    if 'DataGeracao' in df_base.columns and 'DataVencimento' in df_base.columns:\n",
    "        df_base['dias_de_atraso'] = (df_base['DataGeracao'] - df_base['DataVencimento']).dt.days\n",
    "\n",
    "    # Buckets de produto/empregado/convênio\n",
    "    condicoes_produto = [\n",
    "        df_base['Produto'].str.contains('Empréstimo', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Cartão RMC', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Cartão Benefício', case=False, na=False)\n",
    "    ]\n",
    "    opcoes_produto = ['Empréstimo', 'Cartão RMC', 'Cartão Benefício']\n",
    "    df_base['_TipoProduto'] = np.select(condicoes_produto, opcoes_produto, default='Outros')\n",
    "\n",
    "    condicoes_empregado = [\n",
    "        df_base['Produto'].str.contains('Efetivo|Efetivio', case=False, na=False, regex=True),\n",
    "        df_base['Produto'].str.contains('Temporário', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('CONTRATADO', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Comissionado', case=False, na=False)\n",
    "    ]\n",
    "    opcoes_empregado = ['Efetivo', 'Temporário', 'Contratado', 'Comissionado']\n",
    "    df_base['_TipoEmpregado'] = np.select(condicoes_empregado, opcoes_empregado, default='Outros')\n",
    "\n",
    "    # Regex de convênio (ajustada para 'PREF' genérico; mantém 'AGN -' e 'GOV.')\n",
    "    condicoes_convenio = [\n",
    "        df_base['Convênio'].str.contains(r'GOV\\.|AGN -', case=False, na=False, regex=True),\n",
    "        df_base['Convênio'].str.contains(r'PREF', case=False, na=False, regex=True)\n",
    "    ]\n",
    "    opcoes_convenio = ['Estadual', 'Municipal']\n",
    "    df_base['_EsferaConvenio'] = np.select(condicoes_convenio, opcoes_convenio, default='Outros')\n",
    "\n",
    "    # ----- Relógio: Data de Inclusão -----\n",
    "    if 'Data de Inclusão' not in df_base.columns:\n",
    "        raise ValueError(\"Coluna 'Data de Inclusão' não encontrada após o merge. Verifique Originadores.xlsx.\")\n",
    "\n",
    "    # Ordenação temporal por inclusão para _MuitosContratos\n",
    "    df_base = df_base.sort_values(['SacadoID', 'Data de Inclusão', 'CCB'])\n",
    "    df_base['_NumContratosAnteriores'] = df_base.groupby('SacadoID').cumcount()\n",
    "    df_base['_MuitosContratos'] = (df_base['_NumContratosAnteriores'] >= 2).astype(int)\n",
    "\n",
    "    # Idade na Data de Inclusão (fallback em DataGeracao, se inclusão nula)\n",
    "    if 'Data de Nascimento' in df_base.columns:\n",
    "        base_idade = df_base['Data de Inclusão'].fillna(df_base.get('DataGeracao'))\n",
    "        df_base['_IdadeCliente'] = (base_idade - df_base['Data de Nascimento']).dt.days / 365.25\n",
    "        bins = [0, 37, 45, 53, 120]\n",
    "        labels = ['Até 37 anos', '38 a 45 anos', '46 a 53 anos', '54 anos ou mais']\n",
    "        df_base['_IdadesBins'] = pd.cut(df_base['_IdadeCliente'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # ---------- Labels por CCB ----------\n",
    "    # Se tiver múltiplas linhas por CCB (parcelas/linhas), agregue o maior atraso\n",
    "    if 'dias_de_atraso' not in df_base.columns:\n",
    "        raise ValueError(\"'dias_de_atraso' não foi criado. Verifique 'DataGeracao' e 'DataVencimento'.\")\n",
    "\n",
    "    atraso_por_ccb = (\n",
    "        df_base.groupby('CCB', as_index=False)['dias_de_atraso'].max()\n",
    "        .rename(columns={'dias_de_atraso': 'max_dias_atraso'})\n",
    "    )\n",
    "    for k in [1, 30, 60, 90]:\n",
    "        atraso_por_ccb[f'Vencido_{k}d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= k).astype(int)\n",
    "\n",
    "    # ---------- Snapshot determinístico por CCB ----------\n",
    "    # referência temporal: Data de Inclusão (fallback DataGeracao)\n",
    "    df_base['DataInclRef'] = df_base['Data de Inclusão'].fillna(df_base.get('DataGeracao'))\n",
    "    snapshots = df_base.sort_values(['CCB', 'DataInclRef', 'DataVencimento'])\n",
    "    primeiro_snap = snapshots.groupby('CCB', as_index=False).first()\n",
    "\n",
    "    features_para_modelo = [\n",
    "        'CCB', 'Convênio', 'CAPAG', 'Prazo', 'Valor Parcela',\n",
    "        '_TipoProduto', '_TipoEmpregado', '_EsferaConvenio', '_IdadesBins', '_MuitosContratos'\n",
    "    ]\n",
    "    ausentes = sorted(list(set(features_para_modelo) - set(primeiro_snap.columns)))\n",
    "    if ausentes:\n",
    "        print(f\"[AVISO] Features ausentes e removidas (não encontradas no snapshot): {ausentes}\")\n",
    "\n",
    "    features_existentes = [f for f in features_para_modelo if f in primeiro_snap.columns]\n",
    "    df_features = primeiro_snap[features_existentes]\n",
    "\n",
    "    # df_ml final\n",
    "    df_ml = pd.merge(df_features, atraso_por_ccb, on='CCB', how='inner').rename(columns={\n",
    "        'Prazo': 'Total_Parcelas',\n",
    "        'Valor Parcela': 'Valor_Parcela',\n",
    "        '_EsferaConvenio': 'Esfera_Convenio',\n",
    "        '_IdadesBins': 'Faixa_Idade',\n",
    "        '_MuitosContratos': 'Muitos_Contratos',\n",
    "        '_TipoProduto': 'Tipo_Produto',\n",
    "        '_TipoEmpregado': 'Tipo_Empregado'\n",
    "    })\n",
    "\n",
    "    # Checagens úteis\n",
    "    assert df_ml['CCB'].is_unique, \"CCB não está único no df_ml! Revise o snapshot por CCB.\"\n",
    "    assert df_ml[['Vencido_1d_Flag','Vencido_30d_Flag','Vencido_60d_Flag','Vencido_90d_Flag']].notna().all().all(), \\\n",
    "        \"Algum label Vencido_* está com NaN.\"\n",
    "    \n",
    "    # <-- SUGESTÃO IMPLEMENTADA\n",
    "    print(f\"\\nDataset para ML criado com {df_ml.shape[0]} linhas (CCBs) e {df_ml.shape[1]} colunas.\")\n",
    "    return df_ml\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 2: TREINAMENTO E AVALIAÇÃO\n",
    "# =============================================================================\n",
    "def treinar_e_avaliar(df_ml):\n",
    "    targets = ['Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
    "    resultados_finais = pd.DataFrame()\n",
    "\n",
    "    for target in targets:\n",
    "        print(\"\\n\" + \"=\"*88)\n",
    "        print(f\"   TREINANDO MODELOS PARA O ALVO: {target}\")\n",
    "        print(\"=\"*88)\n",
    "\n",
    "        # Define X e y removendo colunas proibidas\n",
    "        X = df_ml.drop(columns=targets + ['CCB', 'max_dias_atraso'])\n",
    "        y = df_ml[target]\n",
    "\n",
    "        # Identifica colunas numéricas originais (antes de dummies)\n",
    "        numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "        categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        # Split estratificado\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.30, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # Dummification APÓS o split + alinhamento\n",
    "        X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "        X_test  = pd.get_dummies(X_test,  columns=categorical_features, drop_first=True)\n",
    "        X_test  = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "        # Guardas básicas\n",
    "        print(\"#cols treino:\", X_train.shape[1], \"| #cols teste:\", X_test.shape[1])\n",
    "        assert list(X_train.columns) == list(X_test.columns), \"Treino e teste desalinhados!\"\n",
    "\n",
    "        # Imputação + Escalonamento SOMENTE nas numéricas originais (interseção)\n",
    "        num_cols = [c for c in numerical_features if c in X_train.columns]\n",
    "        if len(num_cols) > 0:\n",
    "            imputer = SimpleImputer(strategy='median')\n",
    "            X_train[num_cols] = imputer.fit_transform(X_train[num_cols])\n",
    "            X_test[num_cols]  = imputer.transform(X_test[num_cols])\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "            X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
    "        else:\n",
    "            # <-- SUGESTÃO IMPLEMENTADA\n",
    "            print(\"[INFO] Nenhuma coluna numérica foi identificada para imputação ou escalonamento.\")\n",
    "\n",
    "        # Log base rates\n",
    "        print(\"Base rate no treino:\", float(y_train.mean()).__round__(4), \"| no teste:\", float(y_test.mean()).__round__(4))\n",
    "\n",
    "        # scale_pos_weight com guarda\n",
    "        pos = int((y_train == 1).sum())\n",
    "        neg = int((y_train == 0).sum())\n",
    "        if pos == 0:\n",
    "            print(f\"[AVISO] Classe positiva ausente no treino para {target}. Ajustando scale_pos_weight=1.0.\")\n",
    "            scale_pos_weight = 1.0\n",
    "        else:\n",
    "            scale_pos_weight = neg / pos\n",
    "\n",
    "        # Modelos\n",
    "        models = {\n",
    "            \"Regressão Logística\": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
    "            \"Random Forest\":       RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "            \"SVM (Kernel RBF)\":    SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced'),\n",
    "            \"XGBoost\":             xgb.XGBClassifier(random_state=42, eval_metric='logloss',\n",
    "                                                      use_label_encoder=False, scale_pos_weight=scale_pos_weight,\n",
    "                                                      n_jobs=-1),\n",
    "            \"LightGBM\":            lgb.LGBMClassifier(random_state=42, scale_pos_weight=scale_pos_weight,\n",
    "                                                       n_jobs=-1)\n",
    "        }\n",
    "\n",
    "        resultados_target = {}\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\n--- Treinando {name} ---\")\n",
    "            model.fit(X_train, y_train)\n",
    "            # Probabilidades\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            # Métricas\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            ap  = average_precision_score(y_test, y_pred_proba)\n",
    "            resultados_target[name] = {'ROC-AUC': auc, 'PR-AUC(AP)': ap}\n",
    "            print(f\"ROC-AUC: {auc:.4f} | PR-AUC(AP): {ap:.4f}\")\n",
    "\n",
    "            # Importâncias — árvores/GBMs\n",
    "            if isinstance(model, xgb.XGBClassifier):\n",
    "                booster = model.get_booster()\n",
    "                imp = booster.get_score(importance_type='gain')\n",
    "                if len(imp) > 0:\n",
    "                    importances = (pd.Series(imp).sort_values(ascending=False).head(10)\n",
    "                                   .rename('Gain').reset_index().rename(columns={'index': 'Feature'}))\n",
    "                    print(\"Top 10 importâncias (XGB, gain):\")\n",
    "                    print(importances)\n",
    "            elif isinstance(model, lgb.LGBMClassifier):\n",
    "                feats = model.feature_name_\n",
    "                gains = model.booster_.feature_importance(importance_type='gain')\n",
    "                importances = (pd.DataFrame({'Feature': feats, 'Gain': gains})\n",
    "                               .sort_values('Gain', ascending=False).head(10))\n",
    "                print(\"Top 10 importâncias (LGBM, gain):\")\n",
    "                print(importances)\n",
    "            elif hasattr(model, 'feature_importances_'):\n",
    "                importances = pd.DataFrame({\n",
    "                    'Feature': X_train.columns,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values('Importance', ascending=False).head(10)\n",
    "                print(\"Top 10 importâncias:\")\n",
    "                print(importances)\n",
    "            elif isinstance(model, LogisticRegression):\n",
    "                # <-- SUGESTÃO IMPLEMENTADA (Comentário)\n",
    "                # A comparação da magnitude destes coeficientes é válida porque as features numéricas foram escalonadas.\n",
    "                coefs = pd.Series(model.coef_[0], index=X_train.columns).sort_values(key=np.abs, ascending=False).head(10)\n",
    "                print(\"Top 10 |coef| (Regressão Logística):\")\n",
    "                print(coefs)\n",
    "\n",
    "        # Acumula resultados por alvo\n",
    "        df_resultados_target = (pd.DataFrame(resultados_target).T)\n",
    "        # guarda apenas ROC-AUC numa tabela comparativa “clássica”\n",
    "        resultados_finais = pd.concat([resultados_finais, df_resultados_target['ROC-AUC'].rename(target)], axis=1)\n",
    "\n",
    "        # Checagens adicionais úteis\n",
    "        suspeitas = {'dias_de_atraso', 'max_dias_atraso', 'DataGeracao', 'DataVencimento', 'Data de Inclusão'}\n",
    "        suspeitas_presentes = sorted(list(set(X_train.columns) & suspeitas))\n",
    "        if suspeitas_presentes:\n",
    "            print(f\"[ALERTA] Colunas suspeitas presentes em X: {suspeitas_presentes}\")\n",
    "\n",
    "    return resultados_finais\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 3: EXECUÇÃO\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df_ml = carregar_e_preparar_dados_corrigido()\n",
    "\n",
    "    # Relatório rápido de base rates por label\n",
    "    print(\"\\nBase rates dos alvos (df_ml):\")\n",
    "    print(df_ml[['Vencido_1d_Flag','Vencido_30d_Flag','Vencido_60d_Flag','Vencido_90d_Flag']].mean().round(4))\n",
    "\n",
    "    resultados_finais = treinar_e_avaliar(df_ml)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*88)\n",
    "    print(\"   RESUMO COMPARATIVO FINAL - ROC-AUC\")\n",
    "    print(\"=\"*88)\n",
    "    print(resultados_finais.round(4))\n",
    "\n",
    "    melhor_modelo_geral = resultados_finais.mean(axis=1).idxmax()\n",
    "    print(\"\\n\" + \"-\"*88)\n",
    "    print(f\"Considerando a média de ROC-AUC em todos os alvos, o melhor modelo parece ser: '{melhor_modelo_geral}'\")\n",
    "    print(\"-\"*88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f36036ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ETAPA 1: Carregando e preparando os dados...\n",
      "================================================================================\n",
      "Dataset para ML criado com 6838 contratos (CCBs).\n",
      "Período dos dados: de 2024-09-18 a 2025-08-05\n",
      "\n",
      "================================================================================\n",
      " TREINANDO MODELOS PARA O ALVO: Vencido_1d_Flag\n",
      "================================================================================\n",
      "\n",
      "--- Modelo: Regressão Logística ---\n",
      "  - Processando Fold 1/5...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 244\u001b[0m\n\u001b[0;32m    241\u001b[0m targets_a_prever \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVencido_1d_Flag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVencido_30d_Flag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVencido_60d_Flag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVencido_90d_Flag\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Executa a nova função de treinamento com validação temporal\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m resultados_finais \u001b[38;5;241m=\u001b[39m \u001b[43mtreinar_e_avaliar_modelos_temporal_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_a_prever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  RESUMO COMPARATIVO FINAL (VALIDAÇÃO TEMPORAL CRUZADA)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 208\u001b[0m, in \u001b[0;36mtreinar_e_avaliar_modelos_temporal_cv\u001b[1;34m(df_ml, targets, n_splits)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Treinamento do modelo\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Cálculo das métricas para o fold\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    661\u001b[0m         )\n\u001b[1;32m--> 662\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1276\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1272\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > 1 does not have any effect when\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1273\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1274\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs))\n\u001b[0;32m   1275\u001b[0m         )\n\u001b[1;32m-> 1276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1187\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1185\u001b[0m     classes_ \u001b[38;5;241m=\u001b[39m enc\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(classes_) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1189\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1191\u001b[0m         )\n\u001b[0;32m   1193\u001b[0m     class_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(class_weight, classes\u001b[38;5;241m=\u001b[39mclasses_, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(1)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script de Treinamento e Avaliação de Modelos de Machine Learning\n",
    "VERSÃO CORRIGIDA - COM VALIDAÇÃO TEMPORAL E SEM DATA LEAKAGE\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelos e Ferramentas\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 1: CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
    "# ALTERAÇÃO: Removida a criação da feature '_MuitosContratos' para evitar data leakage.\n",
    "# ALTERAÇÃO: Garante que o dataframe final esteja ordenado por data.\n",
    "# =============================================================================\n",
    "def carregar_e_preparar_dados():\n",
    "    \"\"\"\n",
    "    Carrega, limpa e prepara os dados, usando a \"Data de Inclusão\" para\n",
    "    estabelecer a ordem cronológica correta dos contratos.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ETAPA 1: Carregando e preparando os dados...\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ! PATHS ----------------------------------------------------------------------\n",
    "    path_starcard = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\StarCard.xlsx'\n",
    "    path_originadores = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\Originadores.xlsx'\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "    df_starcard = pd.read_excel(path_starcard)\n",
    "    cols_originadores = ['CCB', 'Prazo', 'Valor Parcela', 'Produto', 'Convênio', 'Data de Inclusão']\n",
    "    df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "\n",
    "    if not df_originadores['CCB'].is_unique:\n",
    "        df_originadores = df_originadores.drop_duplicates(subset='CCB', keep='first')\n",
    "\n",
    "    df_merged = pd.merge(df_starcard, df_originadores, on='CCB', how='left', suffixes=('', '_orig'))\n",
    "    df_merged = df_merged.rename(columns={\n",
    "        'Data Referencia': 'DataGeracao', 'Data Vencimento': 'DataVencimento',\n",
    "        'ID Cliente': 'SacadoID'\n",
    "    })\n",
    "\n",
    "    cols_monetarias = ['Valor Parcela']\n",
    "    for col in cols_monetarias:\n",
    "        if df_merged[col].dtype == 'object':\n",
    "            df_merged[col] = df_merged[col].astype(str).str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()\n",
    "            df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "    cols_data = ['DataGeracao', 'DataVencimento', 'Data de Nascimento', 'Data de Inclusão']\n",
    "    for col in cols_data:\n",
    "        df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')\n",
    "\n",
    "    df_base = df_merged.copy()\n",
    "    del df_starcard, df_originadores, df_merged\n",
    "\n",
    "    df_base['dias_de_atraso'] = (df_base['DataGeracao'] - df_base['DataVencimento']).dt.days\n",
    "    df_base['Produto'] = df_base['Produto'].fillna('')\n",
    "    df_base['Convênio'] = df_base['Convênio'].fillna('')\n",
    "    \n",
    "    condicoes_produto = [df_base['Produto'].str.contains('Empréstimo', case=False, na=False), df_base['Produto'].str.contains('Cartão RMC', case=False, na=False), df_base['Produto'].str.contains('Cartão Benefício', case=False, na=False)]\n",
    "    opcoes_produto = ['Empréstimo', 'Cartão RMC', 'Cartão Benefício']\n",
    "    df_base['_TipoProduto'] = np.select(condicoes_produto, opcoes_produto, default='Outros')\n",
    "\n",
    "    condicoes_empregado = [df_base['Produto'].str.contains('Efetivo|Efetivio', case=False, na=False, regex=True), df_base['Produto'].str.contains('Temporário', case=False, na=False), df_base['Produto'].str.contains('CONTRATADO', case=False, na=False), df_base['Produto'].str.contains('Comissionado', case=False, na=False)]\n",
    "    opcoes_empregado = ['Efetivo', 'Temporário', 'Contratado', 'Comissionado']\n",
    "    df_base['_TipoEmpregado'] = np.select(condicoes_empregado, opcoes_empregado, default='Outros')\n",
    "\n",
    "    condicoes_convenio = [df_base['Convênio'].str.contains(r'GOV\\.|AGN -', case=False, na=False, regex=True), df_base['Convênio'].str.contains(r'PREF\\.|PRERF', case=False, na=False, regex=True)]\n",
    "    opcoes_convenio = ['Estadual', 'Municipal']\n",
    "    df_base['_EsferaConvenio'] = np.select(condicoes_convenio, opcoes_convenio, default='Outros')\n",
    "\n",
    "    if 'Data de Nascimento' in df_base.columns:\n",
    "        df_base['_IdadeCliente'] = ((df_base['DataGeracao'] - df_base['Data de Nascimento']).dt.days / 365.25)\n",
    "        bins = [0, 37, 45, 53, 120]\n",
    "        labels = ['Até 37 anos', '38 a 45 anos', '46 a 53 anos', '54 anos ou mais']\n",
    "        df_base['_IdadesBins'] = pd.cut(df_base['_IdadeCliente'], bins=bins, labels=labels, right=True)\n",
    "    \n",
    "    # REMOVIDO DAQUI: A feature '_MuitosContratos' será criada dentro do loop de validação cruzada.\n",
    "\n",
    "    atraso_por_ccb = df_base.groupby('CCB')['dias_de_atraso'].max().reset_index()\n",
    "    atraso_por_ccb.rename(columns={'dias_de_atraso': 'max_dias_atraso'}, inplace=True)\n",
    "    atraso_por_ccb['Vencido_1d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 1).astype(int)\n",
    "    atraso_por_ccb['Vencido_30d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 30).astype(int)\n",
    "    atraso_por_ccb['Vencido_60d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 60).astype(int)\n",
    "    atraso_por_ccb['Vencido_90d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= 90).astype(int)\n",
    "\n",
    "    # A feature 'SacadoID' é mantida por enquanto para ser usada na criação da feature '_MuitosContratos'\n",
    "    features_para_modelo = ['CCB', 'SacadoID', 'Convênio', 'CAPAG', 'Prazo', 'Valor Parcela', '_TipoProduto', '_TipoEmpregado', '_EsferaConvenio', '_IdadesBins', 'Data de Inclusão']\n",
    "    features_existentes = [f for f in features_para_modelo if f in df_base.columns]\n",
    "    df_features = df_base[features_existentes].drop_duplicates(subset='CCB', keep='first')\n",
    "\n",
    "    df_ml = pd.merge(df_features, atraso_por_ccb, on='CCB')\n",
    "    \n",
    "    df_ml = df_ml.rename(columns={\n",
    "        'Prazo': 'Total_Parcelas', 'Valor Parcela': 'Valor_Parcela', '_EsferaConvenio': 'Esfera_Convenio',\n",
    "        '_IdadesBins': 'Faixa_Idade', '_TipoProduto': 'Tipo_Produto', '_TipoEmpregado': 'Tipo_Empregado',\n",
    "        'Data de Inclusão': 'DataInclusao'\n",
    "    })\n",
    "\n",
    "    # IMPORTANTE: Ordenar os dados por data para a validação temporal funcionar corretamente\n",
    "    df_ml = df_ml.sort_values('DataInclusao').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Dataset para ML criado com {len(df_ml)} contratos (CCBs).\")\n",
    "    print(f\"Período dos dados: de {df_ml['DataInclusao'].min().date()} a {df_ml['DataInclusao'].max().date()}\")\n",
    "    return df_ml\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 2: FUNÇÕES DE DIAGNÓSTICO E TREINAMENTO\n",
    "# =============================================================================\n",
    "\n",
    "def treinar_e_avaliar_modelos_temporal_cv(df_ml, targets, n_splits=5):\n",
    "    \"\"\"\n",
    "    Executa um pipeline de treinamento usando Validação Cruzada Temporal (TimeSeriesSplit)\n",
    "    para garantir uma avaliação robusta e sem vazamento de dados do futuro.\n",
    "    A feature '_MuitosContratos' é criada dentro de cada fold para evitar data leakage.\n",
    "    \"\"\"\n",
    "    resultados_finais = {}\n",
    "\n",
    "    for target in targets:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\" TREINANDO MODELOS PARA O ALVO: {target}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        y = df_ml[target]\n",
    "        \n",
    "        if y.nunique() < 2:\n",
    "            print(f\"AVISO: O dataset inteiro para o alvo '{target}' tem apenas uma classe. Pulando.\")\n",
    "            continue\n",
    "        \n",
    "        # Prepara o X inicial, mantendo colunas necessárias para feature engineering\n",
    "        cols_to_drop_initial = targets + ['max_dias_atraso', 'DataInclusao']\n",
    "        X = df_ml.drop(columns=[c for c in cols_to_drop_initial if c in df_ml.columns])\n",
    "\n",
    "        # Define os modelos a serem treinados\n",
    "        # Os hiperparâmetros foram mantidos da versão original, podem ser otimizados\n",
    "        models = {\n",
    "            \"Regressão Logística\": Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(random_state=42, class_weight='balanced', C=0.1, solver='liblinear'))]),\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1, max_depth=5, n_estimators=150, min_samples_leaf=10),\n",
    "            \"XGBoost\": xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', n_jobs=-1, max_depth=4, learning_rate=0.05, n_estimators=200, subsample=0.8, colsample_bytree=0.8),\n",
    "            \"LightGBM\": lgb.LGBMClassifier(random_state=42, n_jobs=-1, max_depth=4, learning_rate=0.05, n_estimators=200, subsample=0.8, colsample_bytree=0.8)\n",
    "        }\n",
    "        \n",
    "        resultados_target = {}\n",
    "\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\n--- Modelo: {name} ---\")\n",
    "            \n",
    "            # Listas para armazenar as métricas de cada fold\n",
    "            roc_auc_scores = []\n",
    "            auprc_inadimplentes_scores = []\n",
    "            auprc_adimplentes_scores = []\n",
    "\n",
    "            # Configura a validação cruzada temporal\n",
    "            tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "            for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "                print(f\"  - Processando Fold {fold+1}/{n_splits}...\")\n",
    "                \n",
    "                # Divisão de treino e teste para este fold\n",
    "                X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "                y_train, y_test = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n",
    "\n",
    "                # --- CORREÇÃO DE DATA LEAKAGE NA FEATURE ENGINEERING ---\n",
    "                # 1. Aprender a regra SOMENTE com os dados de treino\n",
    "                sacado_contratos_treino = X_train.groupby('SacadoID')['CCB'].nunique()\n",
    "                sacado_alto_treino = sacado_contratos_treino[sacado_contratos_treino >= 3].index\n",
    "                # 2. Aplicar a regra aprendida no treino e no teste\n",
    "                X_train['Muitos_Contratos'] = X_train['SacadoID'].isin(sacado_alto_treino).astype(int)\n",
    "                X_test['Muitos_Contratos'] = X_test['SacadoID'].isin(sacado_alto_treino).astype(int)\n",
    "\n",
    "                # Remover colunas de ID que não são features\n",
    "                X_train = X_train.drop(columns=['CCB', 'SacadoID'])\n",
    "                X_test = X_test.drop(columns=['CCB', 'SacadoID'])\n",
    "\n",
    "                # One-hot encoding e alinhamento de colunas\n",
    "                categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "                X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "                X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
    "                X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "                # Tratamento de desbalanceamento para XGBoost/LightGBM\n",
    "                if 'scale_pos_weight' in model.get_params() if not isinstance(model, Pipeline) else 'model__scale_pos_weight' in model.get_params():\n",
    "                    try:\n",
    "                        scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "                        model.set_params(**{'model__scale_pos_weight' if isinstance(model, Pipeline) else 'scale_pos_weight': scale_pos_weight})\n",
    "                    except ZeroDivisionError:\n",
    "                        print(\"    AVISO: Nenhuma amostra da classe positiva no treino. Pulando fold.\")\n",
    "                        continue\n",
    "                \n",
    "                # Treinamento do modelo\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "                # Cálculo das métricas para o fold\n",
    "                roc_auc_scores.append(roc_auc_score(y_test, y_pred_proba))\n",
    "                \n",
    "                # AUPRC para inadimplentes (classe positiva, geralmente o foco)\n",
    "                precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "                auprc_inadimplentes_scores.append(auc(recall, precision))\n",
    "\n",
    "                # AUPRC para adimplentes (classe negativa)\n",
    "                precision, recall, _ = precision_recall_curve(y_test, 1 - y_pred_proba, pos_label=0)\n",
    "                auprc_adimplentes_scores.append(auc(recall, precision))\n",
    "\n",
    "            # Média e desvio padrão das métricas após todos os folds\n",
    "            resultados_target[name] = {\n",
    "                'ROC-AUC Média': np.mean(roc_auc_scores),\n",
    "                'ROC-AUC Desv.': np.std(roc_auc_scores),\n",
    "                'AUPRC_inadimplentes': np.mean(auprc_inadimplentes_scores),\n",
    "                'AUPRC_adimplentes': np.mean(auprc_adimplentes_scores)\n",
    "            }\n",
    "            print(f\"  - Resultado Final (Média CV): ROC-AUC={np.mean(roc_auc_scores):.4f}, AUPRC_inadimplentes={np.mean(auprc_inadimplentes_scores):.4f}\")\n",
    "\n",
    "        resultados_finais[target] = pd.DataFrame.from_dict(resultados_target, orient='index')\n",
    "        \n",
    "    return resultados_finais\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 3: EXECUÇÃO PRINCIPAL E EXIBIÇÃO DO RESUMO FINAL\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df_ml = carregar_e_preparar_dados()\n",
    "    targets_a_prever = ['Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
    "    \n",
    "    # Executa a nova função de treinamento com validação temporal\n",
    "    resultados_finais = treinar_e_avaliar_modelos_temporal_cv(df_ml, targets_a_prever, n_splits=5)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"  RESUMO COMPARATIVO FINAL (VALIDAÇÃO TEMPORAL CRUZADA)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if not resultados_finais:\n",
    "        print(\"Nenhum alvo pôde ser avaliado.\")\n",
    "    else:\n",
    "        for target, df_resultado in resultados_finais.items():\n",
    "            print(f\"\\n--- Resultados para o Alvo: {target} ---\")\n",
    "            print(df_resultado.round(4))\n",
    "            \n",
    "            if not df_resultado.empty:\n",
    "                # Sugestão: Selecionar o melhor modelo com base no AUPRC da classe de interesse (inadimplentes)\n",
    "                melhor_modelo = df_resultado['AUPRC_inadimplentes'].idxmax()\n",
    "                melhor_score = df_resultado['AUPRC_inadimplentes'].max()\n",
    "                \n",
    "                print(\"\\n\" + \"-\"*80)\n",
    "                print(f\"Considerando a performance na identificação de INADIMPLENTES (maior AUPRC),\")\n",
    "                print(f\"o melhor modelo parece ser: '{melhor_modelo}' com AUPRC médio de {melhor_score:.4f}\")\n",
    "                print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ef16fcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Após treinar o seu modelo XGBoost final para um alvo\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Supondo que 'model' seja o seu objeto XGBoost treinado\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances_\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 10 Features Mais Importantes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(importances\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Após treinar o seu modelo XGBoost final para um alvo\n",
    "# Supondo que 'model' seja o seu objeto XGBoost treinado\n",
    "importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Features Mais Importantes:\")\n",
    "print(importances.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2877896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ETAPA 1: Carregando e preparando os dados com Snapshot em t₀...\n",
      "================================================================================\n",
      "Dataset para ML criado com snapshot t₀ correto.\n",
      "\n",
      "================================================================================\n",
      "ETAPA 2: Divisão Temporal dos Dados\n",
      "================================================================================\n",
      "Divisão temporal realizada na data: 2025-06-06\n",
      "Dados de treino: 4807 amostras (de 2024-09-23 até 2025-06-06)\n",
      "Dados de teste: 2031 amostras (de 2025-06-09 até 2025-08-05)\n",
      "\n",
      "================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_1d_Flag (Validação Temporal)\n",
      "================================================================================\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC Score: 0.6588\n",
      "PR-AUC Score: 0.5191\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC Score: 0.5792\n",
      "PR-AUC Score: 0.7110\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE    0.281647\n",
      "0                     Total_Parcelas    0.117335\n",
      "40          Esfera_Convenio_Estadual    0.089289\n",
      "41         Esfera_Convenio_Municipal    0.073208\n",
      "8                Convênio_GOV. GOIAS    0.069239\n",
      "1                      Valor_Parcela    0.061993\n",
      "5                            CAPAG_C    0.039859\n",
      "39         Tipo_Empregado_Temporário    0.029400\n",
      "36       Tipo_Empregado_Comissionado    0.026060\n",
      "12          Convênio_PREF. ARAÇATUBA    0.025097\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC Score: 0.5280\n",
      "PR-AUC Score: 0.3845\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE    0.363657\n",
      "42          Faixa_Idade_38 a 45 anos    0.099888\n",
      "10            Convênio_PREF. ALTINHO    0.081715\n",
      "45           Faixa_Idade_Até 37 anos    0.077317\n",
      "40          Esfera_Convenio_Estadual    0.076541\n",
      "36       Tipo_Empregado_Comissionado    0.044453\n",
      "33     Tipo_Produto_Cartão Benefício    0.043173\n",
      "35           Tipo_Produto_Empréstimo    0.043089\n",
      "12          Convênio_PREF. ARAÇATUBA    0.038746\n",
      "5                            CAPAG_C    0.022060\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 4775, number of negative: 32\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 333\n",
      "[LightGBM] [Info] Number of data points in the train set: 4807, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "ROC-AUC Score: 0.6036\n",
      "PR-AUC Score: 0.4270\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela        1319\n",
      "0                     Total_Parcelas         287\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE         143\n",
      "36       Tipo_Empregado_Comissionado         136\n",
      "44       Faixa_Idade_54 anos ou mais         108\n",
      "45           Faixa_Idade_Até 37 anos         100\n",
      "43          Faixa_Idade_46 a 53 anos          77\n",
      "2                   Muitos_Contratos          60\n",
      "37            Tipo_Empregado_Efetivo          60\n",
      "40          Esfera_Convenio_Estadual          59\n",
      "\n",
      "================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_30d_Flag (Validação Temporal)\n",
      "================================================================================\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC Score: 0.4673\n",
      "PR-AUC Score: 0.0197\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC Score: 0.5809\n",
      "PR-AUC Score: 0.4266\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE    0.149801\n",
      "0                     Total_Parcelas    0.131202\n",
      "41         Esfera_Convenio_Municipal    0.098945\n",
      "40          Esfera_Convenio_Estadual    0.096483\n",
      "1                      Valor_Parcela    0.080824\n",
      "8                Convênio_GOV. GOIAS    0.079146\n",
      "12          Convênio_PREF. ARAÇATUBA    0.043400\n",
      "39         Tipo_Empregado_Temporário    0.036265\n",
      "3                            CAPAG_A    0.033074\n",
      "36       Tipo_Empregado_Comissionado    0.026731\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC Score: 0.4382\n",
      "PR-AUC Score: 0.0177\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE    0.302897\n",
      "40          Esfera_Convenio_Estadual    0.133078\n",
      "12          Convênio_PREF. ARAÇATUBA    0.089134\n",
      "36       Tipo_Empregado_Comissionado    0.064371\n",
      "17               Convênio_PREF. IATI    0.031640\n",
      "6                         CAPAG_N.D.    0.030035\n",
      "10            Convênio_PREF. ALTINHO    0.029737\n",
      "37            Tipo_Empregado_Efetivo    0.028495\n",
      "29           Convênio_PREF. SOROCABA    0.027846\n",
      "22         Convênio_PREF. PIRACICABA    0.026757\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 4671, number of negative: 136\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 333\n",
      "[LightGBM] [Info] Number of data points in the train set: 4807, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "ROC-AUC Score: 0.5374\n",
      "PR-AUC Score: 0.0253\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela        1253\n",
      "0                     Total_Parcelas         329\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE         119\n",
      "2                   Muitos_Contratos         103\n",
      "44       Faixa_Idade_54 anos ou mais          91\n",
      "43          Faixa_Idade_46 a 53 anos          83\n",
      "29           Convênio_PREF. SOROCABA          81\n",
      "42          Faixa_Idade_38 a 45 anos          70\n",
      "37            Tipo_Empregado_Efetivo          68\n",
      "13              Convênio_PREF. BAURU          66\n",
      "\n",
      "================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_60d_Flag (Validação Temporal)\n",
      "================================================================================\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC Score: nan\n",
      "PR-AUC Score: 0.5000\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC Score: nan\n",
      "PR-AUC Score: 0.5000\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.467703\n",
      "36       Tipo_Empregado_Comissionado    0.098324\n",
      "0                     Total_Parcelas    0.064469\n",
      "37            Tipo_Empregado_Efetivo    0.031834\n",
      "27              Convênio_PREF. SALTO    0.027210\n",
      "12          Convênio_PREF. ARAÇATUBA    0.026961\n",
      "39         Tipo_Empregado_Temporário    0.024664\n",
      "3                            CAPAG_A    0.024201\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE    0.023928\n",
      "35           Tipo_Produto_Empréstimo    0.019202\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC Score: nan\n",
      "PR-AUC Score: 0.5000\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "36       Tipo_Empregado_Comissionado    0.305553\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE    0.153986\n",
      "27              Convênio_PREF. SALTO    0.111965\n",
      "12          Convênio_PREF. ARAÇATUBA    0.051543\n",
      "40          Esfera_Convenio_Estadual    0.050527\n",
      "35           Tipo_Produto_Empréstimo    0.039660\n",
      "14   Convênio_PREF. CAMPOS DO JORDÃO    0.034753\n",
      "37            Tipo_Empregado_Efetivo    0.028983\n",
      "4                            CAPAG_B    0.022407\n",
      "15              Convênio_PREF. COTIA    0.021504\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 3620, number of negative: 1187\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 333\n",
      "[LightGBM] [Info] Number of data points in the train set: 4807, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "ROC-AUC Score: nan\n",
      "PR-AUC Score: 0.5000\n",
      "Top 10 Features mais importantes:\n",
      "                          Feature  Importance\n",
      "1                   Valor_Parcela        1488\n",
      "0                  Total_Parcelas         369\n",
      "45        Faixa_Idade_Até 37 anos          91\n",
      "44    Faixa_Idade_54 anos ou mais          69\n",
      "33  Tipo_Produto_Cartão Benefício          67\n",
      "42       Faixa_Idade_38 a 45 anos          65\n",
      "2                Muitos_Contratos          61\n",
      "12       Convênio_PREF. ARAÇATUBA          60\n",
      "35        Tipo_Produto_Empréstimo          59\n",
      "43       Faixa_Idade_46 a 53 anos          54\n",
      "\n",
      "================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_90d_Flag (Validação Temporal)\n",
      "================================================================================\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC Score: nan\n",
      "PR-AUC Score: 0.5000\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC Score: nan\n",
      "PR-AUC Score: 0.5000\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "1                      Valor_Parcela    0.596325\n",
      "0                     Total_Parcelas    0.076489\n",
      "36       Tipo_Empregado_Comissionado    0.047960\n",
      "37            Tipo_Empregado_Efetivo    0.037836\n",
      "39         Tipo_Empregado_Temporário    0.023236\n",
      "35           Tipo_Produto_Empréstimo    0.022683\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE    0.017157\n",
      "2                   Muitos_Contratos    0.015283\n",
      "33     Tipo_Produto_Cartão Benefício    0.012590\n",
      "34           Tipo_Produto_Cartão RMC    0.012240\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC Score: nan\n",
      "PR-AUC Score: 0.5000\n",
      "Top 10 Features mais importantes:\n",
      "                             Feature  Importance\n",
      "39         Tipo_Empregado_Temporário    0.254277\n",
      "36       Tipo_Empregado_Comissionado    0.192377\n",
      "40          Esfera_Convenio_Estadual    0.079555\n",
      "18  Convênio_PREF. JUAZEIRO DO NORTE    0.075816\n",
      "35           Tipo_Produto_Empréstimo    0.036852\n",
      "5                            CAPAG_C    0.026397\n",
      "27              Convênio_PREF. SALTO    0.023001\n",
      "17               Convênio_PREF. IATI    0.022922\n",
      "28        Convênio_PREF. SANTA LUZIA    0.021132\n",
      "3                            CAPAG_A    0.020325\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 2293, number of negative: 2514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 333\n",
      "[LightGBM] [Info] Number of data points in the train set: 4807, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "ROC-AUC Score: nan\n",
      "PR-AUC Score: 0.5000\n",
      "Top 10 Features mais importantes:\n",
      "                          Feature  Importance\n",
      "1                   Valor_Parcela        1480\n",
      "0                  Total_Parcelas         357\n",
      "2                Muitos_Contratos         108\n",
      "45        Faixa_Idade_Até 37 anos          98\n",
      "42       Faixa_Idade_38 a 45 anos          73\n",
      "33  Tipo_Produto_Cartão Benefício          69\n",
      "5                         CAPAG_C          66\n",
      "44    Faixa_Idade_54 anos ou mais          64\n",
      "35        Tipo_Produto_Empréstimo          58\n",
      "43       Faixa_Idade_46 a 53 anos          52\n",
      "\n",
      "================================================================================\n",
      "   RESUMO COMPARATIVO FINAL - MÉTRICAS DE AVALIAÇÃO (Validação Temporal)\n",
      "================================================================================\n",
      "                               Vencido_1d_Flag  Vencido_30d_Flag  \\\n",
      "LightGBM (PR-AUC)                       0.4270            0.0253   \n",
      "LightGBM (ROC-AUC)                      0.6036            0.5374   \n",
      "Random Forest (PR-AUC)                  0.7110            0.4266   \n",
      "Random Forest (ROC-AUC)                 0.5792            0.5809   \n",
      "Regressão Logística (PR-AUC)            0.5191            0.0197   \n",
      "Regressão Logística (ROC-AUC)           0.6588            0.4673   \n",
      "XGBoost (PR-AUC)                        0.3845            0.0177   \n",
      "XGBoost (ROC-AUC)                       0.5280            0.4382   \n",
      "\n",
      "                               Vencido_60d_Flag  Vencido_90d_Flag  \n",
      "LightGBM (PR-AUC)                           0.5               0.5  \n",
      "LightGBM (ROC-AUC)                          NaN               NaN  \n",
      "Random Forest (PR-AUC)                      0.5               0.5  \n",
      "Random Forest (ROC-AUC)                     NaN               NaN  \n",
      "Regressão Logística (PR-AUC)                0.5               0.5  \n",
      "Regressão Logística (ROC-AUC)               NaN               NaN  \n",
      "XGBoost (PR-AUC)                            0.5               0.5  \n",
      "XGBoost (ROC-AUC)                           NaN               NaN  \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script Completo e Metodologicamente Sólido para Modelagem de Risco de Crédito\n",
    "\n",
    "Este script implementa um fluxo de trabalho de Machine Learning robusto, incorporando\n",
    "as seguintes melhores práticas:\n",
    "\n",
    "1.  **Snapshot t₀:** As features de cada contrato são extraídas de sua data de origem (t₀),\n",
    "    garantindo que o modelo não tenha acesso a informações futuras.\n",
    "\n",
    "2.  **Pipeline de Pré-processamento:** Utiliza o Pipeline e o ColumnTransformer do Scikit-learn para\n",
    "    encapsular todas as etapas de transformação de dados (imputação, encoding, escalonamento).\n",
    "    Isso previne o vazamento de dados (data leakage) e torna o modelo pronto para produção.\n",
    "\n",
    "3.  **Validação Temporal:** A divisão dos dados em treino e teste é feita com base no tempo\n",
    "    (holdout temporal). O modelo é treinado com contratos mais antigos e avaliado em\n",
    "    contratos mais recentes, simulando um cenário real de previsão.\n",
    "\n",
    "4.  **Avaliação Completa:** Calcula tanto a ROC-AUC quanto a PR-AUC (Precision-Recall),\n",
    "    que é especialmente útil para classes desbalanceadas.\n",
    "\n",
    "5.  **Modularidade:** Itera sobre múltiplos horizontes de inadimplência (1d, 30d, 60d, 90d)\n",
    "    e treina um portfólio de modelos de classificação para cada um.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Modelos e Ferramentas de Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Métricas de Avaliação\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "# =============================================================================\n",
    "# ETAPA 1: CARREGAMENTO E PREPARAÇÃO DOS DADOS COM SNAPSHOT t₀\n",
    "# =============================================================================\n",
    "def carregar_dados_com_snapshot_t0():\n",
    "    \"\"\"\n",
    "    Carrega, limpa e transforma os dados, garantindo que as features de cada contrato\n",
    "    sejam extraídas de um snapshot na sua data de origem (t₀).\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ETAPA 1: Carregando e preparando os dados com Snapshot em t₀...\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    #! PATHS ----------------------------------------------------------------------\n",
    "    # ATENÇÃO: REDIFINIR AQUI OS PATHS PARA A SUA MÁQUINA\n",
    "    path_starcard = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\StarCard.xlsx'\n",
    "    path_originadores = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\Originadores.xlsx'\n",
    "    #------------------------------------------------------------------------------\n",
    "\n",
    "    # Carregamento e limpeza inicial\n",
    "    df_starcard = pd.read_excel(path_starcard)\n",
    "    cols_originadores = ['CCB', 'Prazo', 'Valor Parcela', 'Produto', 'Convênio']\n",
    "    df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "    if not df_originadores['CCB'].is_unique:\n",
    "        df_originadores = df_originadores.drop_duplicates(subset='CCB', keep='first')\n",
    "    df_merged = pd.merge(df_starcard, df_originadores, on='CCB', how='left', suffixes=('', '_orig'))\n",
    "    df_merged = df_merged.rename(columns={'Data Referencia': 'DataGeracao', 'Data Vencimento': 'DataVencimento', 'ID Cliente': 'SacadoID', 'Data Aquisicao': 'DataAquisicao'})\n",
    "    \n",
    "    cols_monetarias = ['Valor Parcela']\n",
    "    for col in cols_monetarias:\n",
    "        if df_merged[col].dtype == 'object':\n",
    "            df_merged[col] = df_merged[col].astype(str).str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()\n",
    "            df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "            \n",
    "    cols_data = ['DataGeracao', 'DataVencimento', 'Data de Nascimento', 'DataAquisicao']\n",
    "    for col in cols_data:\n",
    "        df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')\n",
    "    df_base = df_merged.copy()\n",
    "\n",
    "    # 1. Definir t₀ (data de origem) para cada CCB\n",
    "    df_base['t0'] = df_base.groupby('CCB')['DataAquisicao'].transform('min')\n",
    "    \n",
    "    # 2. Capturar o estado final do contrato para criar o alvo\n",
    "    df_base['dias_de_atraso'] = (df_base['DataGeracao'] - df_base['DataVencimento']).dt.days\n",
    "    estado_final = df_base.groupby('CCB')['dias_de_atraso'].max().reset_index()\n",
    "    estado_final = estado_final.rename(columns={'dias_de_atraso': 'max_dias_atraso'})\n",
    "    \n",
    "    # 3. Filtrar para manter apenas a linha de features de t₀\n",
    "    df_snapshot = df_base.loc[df_base.groupby('CCB')['DataAquisicao'].idxmin()].copy()\n",
    "\n",
    "    # 4. Engenharia de Features usando o Snapshot de t₀\n",
    "    df_snapshot['Produto'] = df_snapshot['Produto'].fillna('')\n",
    "    df_snapshot['Convênio'] = df_snapshot['Convênio'].fillna('')\n",
    "    condicoes_produto = [df_snapshot['Produto'].str.contains('Empréstimo', case=False, na=False), df_snapshot['Produto'].str.contains('Cartão RMC', case=False, na=False), df_snapshot['Produto'].str.contains('Cartão Benefício', case=False, na=False)]\n",
    "    opcoes_produto = ['Empréstimo', 'Cartão RMC', 'Cartão Benefício']\n",
    "    df_snapshot['_TipoProduto'] = np.select(condicoes_produto, opcoes_produto, default='Outros')\n",
    "    condicoes_empregado = [df_snapshot['Produto'].str.contains('Efetivo|Efetivio', case=False, na=False, regex=True), df_snapshot['Produto'].str.contains('Temporário', case=False, na=False), df_snapshot['Produto'].str.contains('CONTRATADO', case=False, na=False), df_snapshot['Produto'].str.contains('Comissionado', case=False, na=False)]\n",
    "    opcoes_empregado = ['Efetivo', 'Temporário', 'Contratado', 'Comissionado']\n",
    "    df_snapshot['_TipoEmpregado'] = np.select(condicoes_empregado, opcoes_empregado, default='Outros')\n",
    "    condicoes_convenio = [df_snapshot['Convênio'].str.contains(r'GOV\\.|AGN -', case=False, na=False, regex=True), df_snapshot['Convênio'].str.contains(r'PREF\\.|PRERF', case=False, na=False, regex=True)]\n",
    "    opcoes_convenio = ['Estadual', 'Municipal']\n",
    "    df_snapshot['_EsferaConvenio'] = np.select(condicoes_convenio, opcoes_convenio, default='Outros')\n",
    "    \n",
    "    if 'Data de Nascimento' in df_snapshot.columns:\n",
    "        df_snapshot['_IdadeCliente'] = ((df_snapshot['t0'] - df_snapshot['Data de Nascimento']).dt.days / 365.25)\n",
    "        bins = [0, 37, 45, 53, 120]\n",
    "        labels = ['Até 37 anos', '38 a 45 anos', '46 a 53 anos', '54 anos ou mais']\n",
    "        df_snapshot['_IdadesBins'] = pd.cut(df_snapshot['_IdadeCliente'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    sacado_contratos = df_base.groupby('SacadoID')['CCB'].nunique()\n",
    "    sacado_contratos_alto = sacado_contratos[sacado_contratos >= 3].index\n",
    "    df_snapshot['_MuitosContratos'] = df_snapshot['SacadoID'].isin(sacado_contratos_alto).astype(int)\n",
    "\n",
    "    # 5. Juntar as features de t₀ com os alvos do estado final\n",
    "    df_ml = pd.merge(df_snapshot, estado_final, on='CCB', how='left')\n",
    "\n",
    "    # Criar todos os alvos\n",
    "    df_ml['Vencido_1d_Flag'] = (df_ml['max_dias_atraso'] >= 1).astype(int)\n",
    "    df_ml['Vencido_30d_Flag'] = (df_ml['max_dias_atraso'] >= 30).astype(int)\n",
    "    df_ml['Vencido_60d_Flag'] = (df_ml['max_dias_atraso'] >= 60).astype(int)\n",
    "    df_ml['Vencido_90d_Flag'] = (df_ml['max_dias_atraso'] >= 90).astype(int)\n",
    "\n",
    "    df_ml = df_ml.rename(columns={\n",
    "        'Prazo': 'Total_Parcelas', 'Valor Parcela': 'Valor_Parcela', '_EsferaConvenio': 'Esfera_Convenio',\n",
    "        '_IdadesBins': 'Faixa_Idade', '_MuitosContratos': 'Muitos_Contratos',\n",
    "        '_TipoProduto': 'Tipo_Produto', '_TipoEmpregado': 'Tipo_Empregado'\n",
    "    })\n",
    "    \n",
    "    print(\"Dataset para ML criado com snapshot t₀ correto.\")\n",
    "    return df_ml\n",
    "\n",
    "# =============================================================================\n",
    "# Bloco Principal de Execução\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df_ml = carregar_dados_com_snapshot_t0()\n",
    "\n",
    "    # --- Configurações da Modelagem ---\n",
    "    targets = ['Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
    "    features_to_use = [\n",
    "        'Total_Parcelas', 'Valor_Parcela', 'Muitos_Contratos', 'CAPAG',\n",
    "        'Convênio', 'Tipo_Produto', 'Tipo_Empregado', 'Esfera_Convenio', 'Faixa_Idade'\n",
    "    ]\n",
    "    \n",
    "    # Garantir que apenas colunas existentes sejam usadas\n",
    "    features_to_use = [f for f in features_to_use if f in df_ml.columns]\n",
    "    \n",
    "    resultados_finais = pd.DataFrame()\n",
    "\n",
    "    # --- Divisão Temporal (Temporal Holdout) ---\n",
    "    df_ml = df_ml.sort_values('t0').dropna(subset=['t0'])\n",
    "    cutoff_date = df_ml['t0'].quantile(0.7, interpolation='nearest')\n",
    "    train_df = df_ml[df_ml['t0'] <= cutoff_date]\n",
    "    test_df = df_ml[df_ml['t0'] > cutoff_date]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ETAPA 2: Divisão Temporal dos Dados\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Divisão temporal realizada na data: {cutoff_date.date()}\")\n",
    "    print(f\"Dados de treino: {len(train_df)} amostras (de {train_df['t0'].min().date()} até {train_df['t0'].max().date()})\")\n",
    "    print(f\"Dados de teste: {len(test_df)} amostras (de {test_df['t0'].min().date()} até {test_df['t0'].max().date()})\")\n",
    "\n",
    "    # --- Construção do Pipeline de Pré-processamento ---\n",
    "    numerical_features = train_df[features_to_use].select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = train_df[features_to_use].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "    # --- Loop de Treinamento e Avaliação ---\n",
    "    for target in targets:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"   TREINANDO MODELOS PARA O ALVO: {target} (Validação Temporal)\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        X_train = train_df[features_to_use]\n",
    "        y_train = train_df[target]\n",
    "        X_test = test_df[features_to_use]\n",
    "        y_test = test_df[target]\n",
    "        \n",
    "        # Define os modelos\n",
    "        models = {\n",
    "            \"Regressão Logística\": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000, n_jobs=-1),\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "            \"XGBoost\": xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', n_jobs=-1),\n",
    "            \"LightGBM\": lgb.LGBMClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        }\n",
    "\n",
    "        target_results = {}\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\n--- Treinando {name} ---\")\n",
    "            \n",
    "            pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                       ('classifier', model)])\n",
    "            \n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            \n",
    "            target_results[f\"{name} (ROC-AUC)\"] = roc_auc\n",
    "            target_results[f\"{name} (PR-AUC)\"] = pr_auc\n",
    "            \n",
    "            print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "            print(f\"PR-AUC Score: {pr_auc:.4f}\")\n",
    "\n",
    "            # Extração e exibição da importância das features\n",
    "            if name in [\"Random Forest\", \"XGBoost\", \"LightGBM\"]:\n",
    "                try:\n",
    "                    # Nomes das features após o one-hot encoding\n",
    "                    ohe_feature_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "                    final_feature_names = numerical_features + list(ohe_feature_names)\n",
    "                    \n",
    "                    importances_values = pipeline.named_steps['classifier'].feature_importances_\n",
    "                    \n",
    "                    importances_df = pd.DataFrame({\n",
    "                        'Feature': final_feature_names,\n",
    "                        'Importance': importances_values\n",
    "                    }).sort_values('Importance', ascending=False).head(10)\n",
    "                    \n",
    "                    print(\"Top 10 Features mais importantes:\")\n",
    "                    print(importances_df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Não foi possível extrair a importância das features: {e}\")\n",
    "\n",
    "        # Armazenar resultados\n",
    "        df_target_results = pd.DataFrame.from_dict(target_results, orient='index', columns=[target])\n",
    "        if resultados_finais.empty:\n",
    "            resultados_finais = df_target_results\n",
    "        else:\n",
    "            resultados_finais = resultados_finais.join(df_target_results, how='outer')\n",
    "\n",
    "    # =============================================================================\n",
    "    # ETAPA FINAL: EXIBIÇÃO DO RESUMO COMPARATIVO\n",
    "    # =============================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"   RESUMO COMPARATIVO FINAL - MÉTRICAS DE AVALIAÇÃO (Validação Temporal)\")\n",
    "    print(\"=\"*80)\n",
    "    print(resultados_finais.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
