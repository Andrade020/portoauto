{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d89fae",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<span style=\"color:#C1D3FE;font-size: 32px; font-weight: bold;\">Notebook de Treinamento de Machine Learning: \"Originadora e StartCard\" de 05/08</span>\n",
    "<br> <span style=\"color:#FFD1DC;\"> Feito por Lucas Andrade entre 21 e 22 de Agosto de 2025 </span>\n",
    "<br> <span style=\"color:#FFF5BA;\"> a ser revisado por Felipe Bastos\n",
    "\n",
    "<br>\n",
    "<span style=\"color:#C1D3FE;\">Lucas Rafael de Andrade Desenvolvimento de Software Ltda (59.088.726/0001-70)</span>\n",
    "\n",
    "<span style=\"color:#C1D3FE;\">Solicitado por Porto Real Asset</span>\n",
    "\n",
    "\n",
    "Observação: esse notebook traz como features para o modelo as seguintes séries: \n",
    "Esfera do convênio,\n",
    "Faixa população,\n",
    "CAPAG,\n",
    "Muitos contratos,\n",
    "Tipo de produto,\n",
    "Tipo de empregado,\n",
    "Faixa de Idade,\n",
    "Total de parcelas,\n",
    "Valor da parcela\n",
    "\n",
    "Falta incluir: \n",
    "Dados econômicos (como PIB e População), e # prox parcela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f65004",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c50bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "VERSãO: FALTANDO COLOCAR DADOS COMO POPULAçÂO E PIB PER CAPITA\n",
    "\"\"\"\n",
    "#* baza >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "#* modeloj <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "#* Metriko >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "#* Antaŭprilaborado <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#! CUIDADO! Isso pode ser útil )))))))))))))))))))))))))))))))\n",
    "warnings.filterwarnings('ignore')\n",
    "#! )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fcabc4",
   "metadata": {},
   "source": [
    "### Função de Carregamento dos dados e preparação \n",
    "retorna um df com  as features, já"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "933aada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "#  FUNÇÂO:\n",
    "#  CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
    "# =============================================================================\n",
    "def carregar_e_preparar_dados_corrigido():\n",
    "    \"\"\"\n",
    "    por enquanto lê só  StarCard.xlsx e Originadores.xlsx\n",
    "     Uso 'Data de Inclusão' para ordenar o seguinte\n",
    "        - duplicacoes de ccb\n",
    "        - _MuitosContratos c/ cum Count (para evitrar leak)\n",
    "        - Idade calculada na Data de Inclusão (fallback em DataGeracao se der m)\n",
    "    Crio labels 'Vencido_{1,30,60,90}d' \n",
    "    \"\"\"\n",
    "    print(\"=\"*88)\n",
    "    print(\"ETAPA 1: Carregando e preparando os dados (VERSÃO FINAL)...\")\n",
    "    print(\"=\"*88)\n",
    "\n",
    "    #! PATHS ----------------------------------------------------------------------\n",
    "    #! COLOQUE CORRETAMENTe na maquina \n",
    "    path_starcard = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\StarCard.xlsx'\n",
    "    path_originadores = r'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\originadores\\data\\Originadores.xlsx'\n",
    "    #!------------------------------------------------------------------------------\n",
    "\n",
    "    #******************   Leitura       *************************************************\n",
    "    df_starcard = pd.read_excel(path_starcard)\n",
    "    cols_originadores = ['CCB', 'Data de Inclusão', 'Prazo', 'Valor Parcela', 'Produto', 'Convênio', 'CAPAG']\n",
    "    # CAPAG pode não existir; vamos ler com try simples\n",
    "    try:\n",
    "        df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "    except ValueError:\n",
    "        # <deprec> debug do AC\n",
    "\n",
    "        print(\"[ALERTA] Coluna 'CAPAG' não encontrada em Originadores.xlsx. Esta feature será desconsiderada no modelo.\")\n",
    "        cols_originadores = [c for c in cols_originadores if c != 'CAPAG']\n",
    "        df_originadores = pd.read_excel(path_originadores, usecols=cols_originadores)\n",
    "\n",
    "    #* Normalizo garantindo que vai pegar por inlcusao na ordem\n",
    "    if 'Data de Inclusão' in df_originadores.columns:\n",
    "        df_originadores['Data de Inclusão'] = pd.to_datetime(df_originadores['Data de Inclusão'], errors='coerce')\n",
    "        df_originadores = (\n",
    "            df_originadores\n",
    "            .sort_values(['CCB', 'Data de Inclusão'])\n",
    "            .drop_duplicates(subset='CCB', keep='first')\n",
    "        )\n",
    "    \"\"\"faco isso para que ele pegue de forma deterinística a mesma versao da ccb\"\"\"\n",
    "\n",
    "    #* Merge: \n",
    "    #* note que o startcard repete os ccbs em varias linhas e originadores tem apenas uma lina por ccb \n",
    "    df_merged = pd.merge(df_starcard, df_originadores, on='CCB', how='left', suffixes=('', '_orig'))\n",
    "\n",
    "   \n",
    "    df_merged = df_merged.rename(columns={  # Renomeios #*(para ser compatível com fct_consig- outros dados)\n",
    "        'Data Referencia': 'DataGeracao',\n",
    "        'Data Vencimento': 'DataVencimento',\n",
    "        'ID Cliente': 'SacadoID'\n",
    "    }) \n",
    "    #?----------------------------------------------------------------\n",
    "    for col in ['DataGeracao', 'DataVencimento', 'Data de Nascimento']:\n",
    "        if col in df_merged.columns:\n",
    "            df_merged[col] = pd.to_datetime(df_merged[col], errors='coerce')     # Tipos de data\n",
    "    #?----------------------------------------------------------------\n",
    "    # Conversão  #? sim, é necessário #----------------------------------------------------------------\n",
    "    if 'Valor Parcela' in df_merged.columns and df_merged['Valor Parcela'].dtype == 'object':\n",
    "        s = df_merged['Valor Parcela'].astype(str)\n",
    "        s = s.str.replace('R$', '', regex=False).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip()\n",
    "        df_merged['Valor Parcela'] = pd.to_numeric(s, errors='coerce')\n",
    "    #?----------------------------------------------------------------\n",
    "    df_base = df_merged.copy() # agora vamos usar esse df\n",
    "    # cleanup da memoria\n",
    "    del df_starcard, df_originadores, df_merged\n",
    "    #?----------------------------------------------------------------\n",
    "    # Limpezas básicas\n",
    "    if 'Produto' in df_base.columns:\n",
    "        df_base['Produto'] = df_base['Produto'].fillna('')\n",
    "    if 'Convênio' in df_base.columns:\n",
    "        df_base['Convênio'] = df_base['Convênio'].fillna('')\n",
    "    #?----------------------------------------------------------------\n",
    "    # feat dias_de_atraso\n",
    "    if 'DataGeracao' in df_base.columns and 'DataVencimento' in df_base.columns:\n",
    "        df_base['dias_de_atraso'] = (df_base['DataGeracao'] - df_base['DataVencimento']).dt.days\n",
    "    #?----------------------------------------------------------------\n",
    "    # buckets de produto/empregado/convênio\n",
    "    condicoes_produto = [\n",
    "        df_base['Produto'].str.contains('Empréstimo', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Cartão RMC', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Cartão Benefício', case=False, na=False)\n",
    "    ]\n",
    "    opcoes_produto = ['Empréstimo', 'Cartão RMC', 'Cartão Benefício']\n",
    "    df_base['_TipoProduto'] = np.select(condicoes_produto, opcoes_produto, default='Outros')\n",
    "    \"\"\"Agrupar em buckets transforma informação\n",
    "    não estruturada em features úteis e reduz a complexidade \n",
    "    para os modelos\"\"\"\n",
    "\n",
    "    #?----------------------------------------------------------------\n",
    "    condicoes_empregado = [\n",
    "        df_base['Produto'].str.contains('Efetivo|Efetivio', case=False, na=False, regex=True),\n",
    "        df_base['Produto'].str.contains('Temporário', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('CONTRATADO', case=False, na=False),\n",
    "        df_base['Produto'].str.contains('Comissionado', case=False, na=False)\n",
    "    ]\n",
    "    opcoes_empregado = ['Efetivo', 'Temporário', 'Contratado', 'Comissionado']\n",
    "    df_base['_TipoEmpregado'] = np.select(condicoes_empregado, opcoes_empregado, default='Outros')\n",
    "    #?----------------------------------------------------------------\n",
    "    # Rgx do convênio\n",
    "    condicoes_convenio = [\n",
    "        df_base['Convênio'].str.contains(r'GOV\\.|AGN -', case=False, na=False, regex=True),\n",
    "        df_base['Convênio'].str.contains(r'PREF\\.|PRERF', case=False, na=False, regex=True)\n",
    "    ] #* note que eu ajustei para o typo que observei empiricamente em pref\n",
    "    opcoes_convenio = ['Estadual', 'Municipal']\n",
    "    df_base['_EsferaConvenio'] = np.select(condicoes_convenio, opcoes_convenio, default='Outros')\n",
    "\n",
    "    # ----- Data de Inclusão -----\n",
    "    \"\"\"\n",
    "    explicação do que eu fiz abaixo: \n",
    "    tentei evitar vazamento de dados do futuro. \n",
    "    A feature _MuitosContratos reflete o histórico\n",
    "    do cliente até este momento, e nao o total de contratos\n",
    "    q ele viria a ter. \n",
    "    Da mesma forma, \n",
    "    a idade é a que ele tinha quando assinou o contrato,\n",
    "     que eh a informação que estaria disponivel \n",
    "     para uma analise de credito na época.\"\"\"\n",
    "    if 'Data de Inclusão' not in df_base.columns:\n",
    "        raise ValueError(\"Coluna 'Data de Inclusão' não encontrada após o merge. Verifique Originadores.xlsx.\")\n",
    "    #?----------------------------------------------------------------\n",
    "    # ordeno por inclusão para _MuitosContratos\n",
    "    df_base = df_base.sort_values(['SacadoID', 'Data de Inclusão', 'CCB'])\n",
    "    df_base['_NumContratosAnteriores'] = df_base.groupby('SacadoID').cumcount()\n",
    "    df_base['_MuitosContratos'] = (df_base['_NumContratosAnteriores'] >= 2).astype(int)\n",
    "    #?----------------------------------------------------------------\n",
    "    # Idade na Data de Inclusão \n",
    "    # (fallback em DataGeracao, caso desse errado)\n",
    "    if 'Data de Nascimento' in df_base.columns:\n",
    "        base_idade = df_base['Data de Inclusão'].fillna(df_base.get('DataGeracao'))\n",
    "        df_base['_IdadeCliente'] = (base_idade - df_base['Data de Nascimento']).dt.days / 365.25\n",
    "        bins = [0, 37, 45, 53, 120]\n",
    "        labels = ['Até 37 anos', '38 a 45 anos', '46 a 53 anos', '54 anos ou mais']\n",
    "        df_base['_IdadesBins'] = pd.cut(df_base['_IdadeCliente'], bins=bins, labels=labels, right=True)\n",
    "    #? ---------- Labels por CCB ----------\n",
    "    #? Se tivesse múltiplas linhas por CCB (parcelas/linhas), agregaria o maior atraso\n",
    "    #? <deprec>\n",
    "    #if 'dias_de_atraso' not in df_base.columns:\n",
    "    #    raise ValueError(\"'dias_de_atraso' não foi criado. Verifique 'DataGeracao' e 'DataVencimento'.\")\n",
    "\n",
    "    \"\"\"explicação de abaixo: \n",
    "    o que eu faço é deixar a variável que eu quero prever como unequívoca \n",
    "    para ter como objetivo e ser explicada, para ter a mesma dimensionalidade entr\n",
    "    o contrato e o n de linhas \"\"\"\n",
    "    atraso_por_ccb = (\n",
    "        df_base.groupby('CCB', as_index=False)['dias_de_atraso'].max()\n",
    "        .rename(columns={'dias_de_atraso': 'max_dias_atraso'})\n",
    "    )\n",
    "    for k in [1, 30, 60, 90]:\n",
    "        atraso_por_ccb[f'Vencido_{k}d_Flag'] = (atraso_por_ccb['max_dias_atraso'] >= k).astype(int)\n",
    "\n",
    "    # snapshot pela ordem da nclusao\n",
    "    df_base['DataInclRef'] = df_base['Data de Inclusão'].fillna(df_base.get('DataGeracao'))\n",
    "    snapshots = df_base.sort_values(['CCB', 'DataInclRef', 'DataVencimento'])\n",
    "    primeiro_snap = snapshots.groupby('CCB', as_index=False).first()\n",
    "    #! ########################################################################################\n",
    "    #! #####################     IMPORTANTE     ###############################################\n",
    "    features_para_modelo = [\n",
    "        'CCB',  'CAPAG', 'Prazo', 'Valor Parcela', #'Convênio',   ## comente convênio se quisr remver\n",
    "        '_TipoProduto', '_TipoEmpregado', '_EsferaConvenio', '_IdadesBins', '_MuitosContratos'\n",
    "    ]\n",
    "    #! #########################################################################################\n",
    "    ausentes = sorted(list(set(features_para_modelo) - set(primeiro_snap.columns)))\n",
    "    if ausentes: # dbg AC\n",
    "        print(f\"[AVISO] Features ausentes e removidas (não encontradas no snapshot): {ausentes}\")\n",
    "\n",
    "    features_existentes = [f for f in features_para_modelo if f in primeiro_snap.columns]\n",
    "    df_features = primeiro_snap[features_existentes]\n",
    "\n",
    "    # df_ml final #? esse vai ser o df usado no modelo de ML, mesmo\n",
    "    df_ml = pd.merge(df_features, atraso_por_ccb, on='CCB', how='inner').rename(columns={\n",
    "        'Prazo': 'Total_Parcelas',\n",
    "        'Valor Parcela': 'Valor_Parcela',\n",
    "        '_EsferaConvenio': 'Esfera_Convenio',\n",
    "        '_IdadesBins': 'Faixa_Idade',\n",
    "        '_MuitosContratos': 'Muitos_Contratos',\n",
    "        '_TipoProduto': 'Tipo_Produto',\n",
    "        '_TipoEmpregado': 'Tipo_Empregado'\n",
    "    })\n",
    "\n",
    "    #? verificações básicas\n",
    "    #?assert df_ml['CCB'].is_unique, \"CCB não está único no df_ml! Revise o snapshot por CCB.\"\n",
    "    #?assert df_ml[['Vencido_1d_Flag','Vencido_30d_Flag','Vencido_60d_Flag','Vencido_90d_Flag']].notna().all().all(), \\\n",
    "    #?    \"Algum label Vencido_* está com NaN.\"\n",
    "    \n",
    "    print(f\"\\n <DBG> Dataset para ML criado com {df_ml.shape[0]} linhas (CCBs) e {df_ml.shape[1]} colunas.\")\n",
    "    return df_ml\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37aeea",
   "metadata": {},
   "source": [
    "### Função De Treino e Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cbfbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# FUNÇÃO: \n",
    "#   TREINAMENTO E AVALIAÇÃO\n",
    "# =============================================================================\n",
    "def treinar_e_avaliar(df_ml):\n",
    "    targets = ['Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
    "    resultados_finais = pd.DataFrame()\n",
    "\n",
    "    for target in targets:\n",
    "        print(\"\\n\" + \"=\"*88)\n",
    "        print(f\"   TREINANDO MODELOS PARA O ALVO: {target}\")\n",
    "        print(\"=\"*88)\n",
    "        #?----------------------------------------------------------------    \n",
    "        # Def X e y  #?(OBS: Removo colunas desncessárias para o train)\n",
    "        X = df_ml.drop(columns=targets + ['CCB', 'max_dias_atraso'])\n",
    "        y = df_ml[target]\n",
    "        #?-----------------  tipos: -----------------------------------------------\n",
    "        numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "        categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        #?-------------------  split: ---------------------------------------------        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.30, random_state=42, stratify=y # OBS:  Split estratificado\n",
    "        )\n",
    "        \"\"\" note que é importante tentar fazer o split o mais rápido possível,\n",
    "        para trabalhar apenas com os padrões que ele pegar no conj de teste, para \n",
    "        garantir que nao tenha nenhuma contaminação \"\"\"\n",
    "\n",
    "        #?---------- torno Dummy (após o split para nao contaminar) ------------------------------------------------------\n",
    "        X_train = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "        X_test  = pd.get_dummies(X_test,  columns=categorical_features, drop_first=True)\n",
    "        X_test  = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "        #?------------------- <debug> ---------------------------------------------\n",
    "        #print(\"#cols treino:\", X_train.shape[1], \"| #cols teste:\", X_test.shape[1])\n",
    "        #assert list(X_train.columns) == list(X_test.columns), \"Treino e teste desalinhados!\"\n",
    "        #?------------------ Imputação + Escalonamento  ----------------------------------------------\n",
    "        # só nas nas numéricas originais (interseção)\n",
    "        #* pelo que eu pesquisei o scalling não é necessário, mas vou deixar para se quiser \n",
    "        #* usar outros modelos, além de que para a reg logistica é útil \n",
    "        num_cols = [c for c in numerical_features if c in X_train.columns]\n",
    "        #? if len(num_cols) > 0: # idente abaixo para <bebug>\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        X_train[num_cols] = imputer.fit_transform(X_train[num_cols])\n",
    "        X_test[num_cols]  = imputer.transform(X_test[num_cols])\n",
    "        #?-----------------------\n",
    "        scaler = StandardScaler()\n",
    "        X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "        X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
    "\n",
    "        #?else:\n",
    "        #?    print(\"[INFO] Nenhuma coluna numérica foi identificada para imputação ou escalonamento.\")\n",
    "\n",
    "        # Log base rates # - coloco isso para estudar o balanceio\n",
    "        print(\"Base rate no treino:\", float(y_train.mean()).__round__(4), \"| no teste:\", float(y_test.mean()).__round__(4))\n",
    "        #?-----------------------------\n",
    "        # scale_pos_weight com guarda\n",
    "\n",
    "        \"\"\"\n",
    "        note que temos um debalanceio muito grande nesse tipo de porblema, fazendo \n",
    "        com que o treinamento fique viesado para um lado. \n",
    "        Isso aqui faz comm que ele de mais peso à classe minoritária\n",
    "        #? obs: o paralelo aqui é o de fraudes em cartão de crédito\n",
    "        \"\"\"\n",
    "        pos = int((y_train == 1).sum())\n",
    "        neg = int((y_train == 0).sum())\n",
    "        if pos == 0:\n",
    "            print(f\"[AVISO] Classe positiva ausente no treino para {target}. Ajustando scale_pos_weight=1.0.\")\n",
    "            scale_pos_weight = 1.0\n",
    "        else:\n",
    "            scale_pos_weight = neg / pos\n",
    "        #?---------------- ------------------------------------------------\n",
    "        #?---------------- MODELOS -----------------------------------------------\n",
    "        #! ####################################################################################################\n",
    "        models = {\n",
    "            \"Regressão Logística\": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
    "            \"Random Forest\":       RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "            \"SVM (Kernel RBF)\":    SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced'),\n",
    "            \"XGBoost\":             xgb.XGBClassifier(random_state=42, eval_metric='logloss',\n",
    "                                                      use_label_encoder=False, scale_pos_weight=scale_pos_weight,\n",
    "                                                      n_jobs=-1),\n",
    "            \"LightGBM\":            lgb.LGBMClassifier(random_state=42, scale_pos_weight=scale_pos_weight,\n",
    "                                                       n_jobs=-1)\n",
    "        }\n",
    "        #! ######################################################################################################\n",
    "\n",
    "        resultados_target = {}\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\n--- Treinando {name} ---\")\n",
    "            model.fit(X_train, y_train)\n",
    "            #?---------------- probabilidades -----------------------------------------------\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            #?----------------metricas -----------------------------------------------\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            ap  = average_precision_score(y_test, y_pred_proba)\n",
    "            resultados_target[name] = {'ROC-AUC': auc, 'PR-AUC(AP)': ap}\n",
    "            print(f\"ROC-AUC: {auc:.4f} | PR-AUC(AP): {ap:.4f}\")\n",
    "            #?---------------- IMPORTANCIAS -----------------------------------------------\n",
    "            \"\"\"note que o objetivo é explicar, entao isso é muito importante \n",
    "            o motivo de usar isso está nas referÊncias\"\"\"\n",
    "            if isinstance(model, xgb.XGBClassifier):\n",
    "                booster = model.get_booster()\n",
    "                imp = booster.get_score(importance_type='gain')\n",
    "                if len(imp) > 0:\n",
    "                    importances = (pd.Series(imp).sort_values(ascending=False).head(10)\n",
    "                                   .rename('Gain').reset_index().rename(columns={'index': 'Feature'}))\n",
    "                    print(\"Top 10 importâncias (XGB, gain):\")\n",
    "                    print(importances)\n",
    "            elif isinstance(model, lgb.LGBMClassifier):\n",
    "                feats = model.feature_name_\n",
    "                gains = model.booster_.feature_importance(importance_type='gain')\n",
    "                importances = (pd.DataFrame({'Feature': feats, 'Gain': gains})\n",
    "                               .sort_values('Gain', ascending=False).head(10))\n",
    "                print(\"Top 10 importâncias (LGBM, gain):\")\n",
    "                print(importances)\n",
    "            elif hasattr(model, 'feature_importances_'):\n",
    "                importances = pd.DataFrame({\n",
    "                    'Feature': X_train.columns,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values('Importance', ascending=False).head(10)\n",
    "                print(\"Top 10 importâncias:\")\n",
    "                print(importances)\n",
    "            elif isinstance(model, LogisticRegression):\n",
    "                # A comparação da magnitude destes coeficientes é válida porque \n",
    "                # as features numéricas foram escalonadas.\n",
    "                coefs = pd.Series(model.coef_[0], index=X_train.columns).sort_values(key=np.abs, ascending=False).head(10)\n",
    "                print(\"Top 10 |coef| (Regressão Logística):\")\n",
    "                print(coefs)\n",
    "\n",
    "        #? Acumula resultados por alvo\n",
    "        df_resultados_target = (pd.DataFrame(resultados_target).T)\n",
    "        #? guarda  ROC-AUC numa tabela comparativa \n",
    "\n",
    "        \n",
    "        resultados_finais = pd.concat([resultados_finais, df_resultados_target['ROC-AUC'].rename(target)], axis=1)\n",
    "\n",
    "        #? Checagens adicionais úteis\n",
    "        #?suspeitas = {'dias_de_atraso', 'max_dias_atraso', 'DataGeracao', 'DataVencimento', 'Data de Inclusão'}\n",
    "        #?suspeitas_presentes = sorted(list(set(X_train.columns) & suspeitas))\n",
    "        #?if suspeitas_presentes:\n",
    "        #?    print(f\"[ALERTA] Colunas suspeitas presentes em X: {suspeitas_presentes}\")\n",
    "\n",
    "    return resultados_finais\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39df0d7",
   "metadata": {},
   "source": [
    "### Execução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f7793",
   "metadata": {},
   "source": [
    "#### Ler dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd31cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "ETAPA 1: Carregando e preparando os dados (VERSÃO FINAL)...\n",
      "========================================================================================\n",
      "\n",
      " <DBG> Dataset para ML criado com 6838 linhas (CCBs) e 14 colunas.\n",
      "\n",
      "Base rates dos alvos (df_ml):\n",
      "Vencido_1d_Flag     0.8157\n",
      "Vencido_30d_Flag    0.6897\n",
      "Vencido_60d_Flag    0.5294\n",
      "Vencido_90d_Flag    0.3353\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#! demorado (até 4m30s)\n",
    "df_ml = carregar_e_preparar_dados_corrigido()\n",
    "\n",
    "print(\"\\nBase rates dos alvos (df_ml):\") # ( relatório rápido de base rates por label)\n",
    "print(df_ml[['Vencido_1d_Flag','Vencido_30d_Flag','Vencido_60d_Flag','Vencido_90d_Flag']].mean().round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d231755",
   "metadata": {},
   "source": [
    "#### Treinar Modelos e Avaliar\n",
    "\n",
    "<span style=\"color:#FFD1DC;\">Contém Markdowns com TL;DR </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de124251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TREINANDO MODELOS... AGUARDE (+-1 MIN)\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_1d_Flag\n",
      "========================================================================================\n",
      "Base rate no treino: 0.8157 | no teste: 0.8158\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.9112 | PR-AUC(AP): 0.9677\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Contratado   -4.139504\n",
      "Tipo_Empregado_Efetivo       3.322750\n",
      "Esfera_Convenio_Municipal   -2.938538\n",
      "Tipo_Empregado_Temporário    2.891798\n",
      "CAPAG_B                     -1.461829\n",
      "CAPAG_N.D.                  -1.403280\n",
      "Tipo_Produto_Empréstimo     -1.209099\n",
      "Tipo_Empregado_Outros        0.695386\n",
      "CAPAG_C                     -0.161676\n",
      "Tipo_Produto_Cartão RMC     -0.140456\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.9375 | PR-AUC(AP): 0.9807\n",
      "Top 10 importâncias:\n",
      "                      Feature  Importance\n",
      "1               Valor_Parcela    0.220520\n",
      "0              Total_Parcelas    0.207176\n",
      "8   Tipo_Empregado_Contratado    0.161193\n",
      "11  Tipo_Empregado_Temporário    0.124871\n",
      "12  Esfera_Convenio_Municipal    0.059075\n",
      "9      Tipo_Empregado_Efetivo    0.052638\n",
      "7     Tipo_Produto_Empréstimo    0.032088\n",
      "4                     CAPAG_C    0.027902\n",
      "5                  CAPAG_N.D.    0.022745\n",
      "2            Muitos_Contratos    0.021535\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.9116 | PR-AUC(AP): 0.9741\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.9337 | PR-AUC(AP): 0.9813\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                     Feature       Gain\n",
      "0  Tipo_Empregado_Contratado  26.427397\n",
      "1  Esfera_Convenio_Municipal  10.578958\n",
      "2     Tipo_Empregado_Efetivo   4.171108\n",
      "3             Total_Parcelas   2.856307\n",
      "4  Tipo_Empregado_Temporário   2.731068\n",
      "5                    CAPAG_B   1.649809\n",
      "6                 CAPAG_N.D.   0.978978\n",
      "7      Tipo_Empregado_Outros   0.961150\n",
      "8    Tipo_Produto_Cartão RMC   0.856992\n",
      "9    Tipo_Produto_Empréstimo   0.685501\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3904, number of negative: 882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.815712 -> initscore=1.487565\n",
      "[LightGBM] [Info] Start training from score 1.487565\n",
      "ROC-AUC: 0.9400 | PR-AUC(AP): 0.9827\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                      Feature         Gain\n",
      "0              Total_Parcelas  2650.982469\n",
      "8   Tipo_Empregado_Contratado  2614.302729\n",
      "1               Valor_Parcela  1491.733980\n",
      "12  Esfera_Convenio_Municipal  1227.765614\n",
      "9      Tipo_Empregado_Efetivo   448.439438\n",
      "11  Tipo_Empregado_Temporário   251.030250\n",
      "7     Tipo_Produto_Empréstimo   212.549737\n",
      "2            Muitos_Contratos   179.326429\n",
      "3                     CAPAG_B   107.588587\n",
      "13   Faixa_Idade_38_a_45_anos   107.413959\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_30d_Flag\n",
      "========================================================================================\n",
      "Base rate no treino: 0.6897 | no teste: 0.6896\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.8480 | PR-AUC(AP): 0.9034\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Contratado   -3.722323\n",
      "Tipo_Empregado_Efetivo       3.404100\n",
      "Tipo_Empregado_Temporário    2.463495\n",
      "Esfera_Convenio_Municipal   -2.053657\n",
      "CAPAG_B                     -1.998968\n",
      "CAPAG_N.D.                  -1.261466\n",
      "Tipo_Produto_Empréstimo     -1.100754\n",
      "Tipo_Empregado_Outros        1.007112\n",
      "CAPAG_C                     -0.971152\n",
      "Tipo_Produto_Cartão RMC      0.218468\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8822 | PR-AUC(AP): 0.9222\n",
      "Top 10 importâncias:\n",
      "                      Feature  Importance\n",
      "1               Valor_Parcela    0.386320\n",
      "0              Total_Parcelas    0.200179\n",
      "11  Tipo_Empregado_Temporário    0.080499\n",
      "9      Tipo_Empregado_Efetivo    0.079006\n",
      "8   Tipo_Empregado_Contratado    0.072072\n",
      "7     Tipo_Produto_Empréstimo    0.029841\n",
      "12  Esfera_Convenio_Municipal    0.026712\n",
      "2            Muitos_Contratos    0.022458\n",
      "4                     CAPAG_C    0.020375\n",
      "6     Tipo_Produto_Cartão RMC    0.015966\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.8336 | PR-AUC(AP): 0.8779\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8901 | PR-AUC(AP): 0.9314\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                     Feature       Gain\n",
      "0  Tipo_Empregado_Contratado  56.264435\n",
      "1     Tipo_Empregado_Efetivo  11.153292\n",
      "2             Total_Parcelas   3.792136\n",
      "3      Tipo_Empregado_Outros   3.681315\n",
      "4  Tipo_Empregado_Temporário   3.389155\n",
      "5                    CAPAG_B   2.179682\n",
      "6    Tipo_Produto_Empréstimo   2.053640\n",
      "7                    CAPAG_C   1.495817\n",
      "8  Esfera_Convenio_Municipal   1.475026\n",
      "9                 CAPAG_N.D.   1.128388\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3301, number of negative: 1485\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.689720 -> initscore=0.798811\n",
      "[LightGBM] [Info] Start training from score 0.798811\n",
      "ROC-AUC: 0.8953 | PR-AUC(AP): 0.9366\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                        Feature         Gain\n",
      "0                Total_Parcelas  3473.228851\n",
      "1                 Valor_Parcela  2755.153510\n",
      "8     Tipo_Empregado_Contratado  2738.051868\n",
      "9        Tipo_Empregado_Efetivo  1895.791638\n",
      "11    Tipo_Empregado_Temporário   658.906985\n",
      "7       Tipo_Produto_Empréstimo   477.440917\n",
      "2              Muitos_Contratos   280.825905\n",
      "3                       CAPAG_B   171.863881\n",
      "4                       CAPAG_C   167.595454\n",
      "15  Faixa_Idade_54_anos_ou_mais   163.971594\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_60d_Flag\n",
      "========================================================================================\n",
      "Base rate no treino: 0.5295 | no teste: 0.5292\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.8513 | PR-AUC(AP): 0.8406\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Efetivo         5.018614\n",
      "Tipo_Empregado_Temporário      3.913306\n",
      "Tipo_Empregado_Outros          3.111446\n",
      "Esfera_Convenio_Municipal     -2.510135\n",
      "Tipo_Empregado_Contratado     -2.139856\n",
      "CAPAG_B                       -2.024931\n",
      "CAPAG_C                       -1.734823\n",
      "Tipo_Produto_Empréstimo       -1.139490\n",
      "CAPAG_N.D.                    -0.824950\n",
      "Faixa_Idade_54 anos ou mais    0.176373\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.8663 | PR-AUC(AP): 0.8430\n",
      "Top 10 importâncias:\n",
      "                        Feature  Importance\n",
      "1                 Valor_Parcela    0.424765\n",
      "0                Total_Parcelas    0.133766\n",
      "11    Tipo_Empregado_Temporário    0.101622\n",
      "9        Tipo_Empregado_Efetivo    0.084350\n",
      "8     Tipo_Empregado_Contratado    0.048428\n",
      "4                       CAPAG_C    0.037996\n",
      "12    Esfera_Convenio_Municipal    0.035005\n",
      "7       Tipo_Produto_Empréstimo    0.033121\n",
      "2              Muitos_Contratos    0.023892\n",
      "15  Faixa_Idade_54 anos ou mais    0.013461\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.8541 | PR-AUC(AP): 0.8352\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8790 | PR-AUC(AP): 0.8734\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                     Feature       Gain\n",
      "0  Tipo_Empregado_Contratado  59.031689\n",
      "1  Tipo_Empregado_Temporário  19.572149\n",
      "2      Tipo_Empregado_Outros   8.412154\n",
      "3  Esfera_Convenio_Municipal   5.605096\n",
      "4                    CAPAG_C   5.586591\n",
      "5     Tipo_Empregado_Efetivo   4.591215\n",
      "6             Total_Parcelas   4.249494\n",
      "7                    CAPAG_B   4.030591\n",
      "8                 CAPAG_N.D.   3.201544\n",
      "9    Tipo_Produto_Empréstimo   3.185456\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2534, number of negative: 2252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.529461 -> initscore=0.117980\n",
      "[LightGBM] [Info] Start training from score 0.117980\n",
      "ROC-AUC: 0.8856 | PR-AUC(AP): 0.8776\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                      Feature         Gain\n",
      "0              Total_Parcelas  4119.191002\n",
      "1               Valor_Parcela  3493.711760\n",
      "8   Tipo_Empregado_Contratado  3018.976545\n",
      "11  Tipo_Empregado_Temporário  2517.103756\n",
      "4                     CAPAG_C  1163.450849\n",
      "12  Esfera_Convenio_Municipal   897.775650\n",
      "9      Tipo_Empregado_Efetivo   745.325781\n",
      "7     Tipo_Produto_Empréstimo   736.070876\n",
      "2            Muitos_Contratos   481.759044\n",
      "10      Tipo_Empregado_Outros   331.185243\n",
      "\n",
      "========================================================================================\n",
      "   TREINANDO MODELOS PARA O ALVO: Vencido_90d_Flag\n",
      "========================================================================================\n",
      "Base rate no treino: 0.3354 | no teste: 0.3353\n",
      "\n",
      "--- Treinando Regressão Logística ---\n",
      "ROC-AUC: 0.7809 | PR-AUC(AP): 0.6245\n",
      "Top 10 |coef| (Regressão Logística):\n",
      "Tipo_Empregado_Efetivo       4.382952\n",
      "Tipo_Empregado_Temporário    3.018381\n",
      "Tipo_Empregado_Outros        2.928855\n",
      "Tipo_Empregado_Contratado   -2.319493\n",
      "Esfera_Convenio_Municipal   -2.244051\n",
      "CAPAG_B                     -0.817866\n",
      "Tipo_Produto_Empréstimo     -0.683874\n",
      "Tipo_Produto_Cartão RMC      0.528923\n",
      "CAPAG_N.D.                  -0.399760\n",
      "CAPAG_C                     -0.155562\n",
      "dtype: float64\n",
      "\n",
      "--- Treinando Random Forest ---\n",
      "ROC-AUC: 0.7975 | PR-AUC(AP): 0.6651\n",
      "Top 10 importâncias:\n",
      "                      Feature  Importance\n",
      "1               Valor_Parcela    0.512880\n",
      "0              Total_Parcelas    0.120615\n",
      "9      Tipo_Empregado_Efetivo    0.065673\n",
      "11  Tipo_Empregado_Temporário    0.061301\n",
      "12  Esfera_Convenio_Municipal    0.042776\n",
      "7     Tipo_Produto_Empréstimo    0.038719\n",
      "8   Tipo_Empregado_Contratado    0.035169\n",
      "2            Muitos_Contratos    0.033954\n",
      "4                     CAPAG_C    0.017279\n",
      "6     Tipo_Produto_Cartão RMC    0.014196\n",
      "\n",
      "--- Treinando SVM (Kernel RBF) ---\n",
      "ROC-AUC: 0.7841 | PR-AUC(AP): 0.6013\n",
      "\n",
      "--- Treinando XGBoost ---\n",
      "ROC-AUC: 0.8290 | PR-AUC(AP): 0.7052\n",
      "Top 10 importâncias (XGB, gain):\n",
      "                     Feature       Gain\n",
      "0  Tipo_Empregado_Contratado  53.870216\n",
      "1  Esfera_Convenio_Municipal  12.179648\n",
      "2  Tipo_Empregado_Temporário  10.360579\n",
      "3     Tipo_Empregado_Efetivo   8.830858\n",
      "4      Tipo_Empregado_Outros   6.107745\n",
      "5             Total_Parcelas   4.938339\n",
      "6    Tipo_Produto_Empréstimo   3.915785\n",
      "7                    CAPAG_C   3.176491\n",
      "8           Muitos_Contratos   2.799209\n",
      "9                    CAPAG_B   1.950188\n",
      "\n",
      "--- Treinando LightGBM ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1605, number of negative: 3181\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 4786, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335353 -> initscore=-0.684072\n",
      "[LightGBM] [Info] Start training from score -0.684072\n",
      "ROC-AUC: 0.8371 | PR-AUC(AP): 0.7202\n",
      "Top 10 importâncias (LGBM, gain):\n",
      "                      Feature         Gain\n",
      "1               Valor_Parcela  4678.520853\n",
      "0              Total_Parcelas  4557.654179\n",
      "8   Tipo_Empregado_Contratado  2940.261268\n",
      "12  Esfera_Convenio_Municipal  2520.615667\n",
      "9      Tipo_Empregado_Efetivo  1455.677869\n",
      "2            Muitos_Contratos  1396.630777\n",
      "11  Tipo_Empregado_Temporário  1368.635075\n",
      "7     Tipo_Produto_Empréstimo   920.595465\n",
      "4                     CAPAG_C   431.865465\n",
      "10      Tipo_Empregado_Outros   387.612271\n"
     ]
    }
   ],
   "source": [
    "print (\" TREINANDO MODELOS... AGUARDE (+-1 MIN)\")\n",
    "resultados_finais = treinar_e_avaliar(df_ml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb6131",
   "metadata": {},
   "source": [
    "O Fator mais importante:  (`Tipo_Empregado`) \n",
    "\n",
    "Este foi, de longe, o fator mais impactante em quase todos os modelos.\n",
    "* **Menor Risco:** Clientes com vínculo `Contratado` consistentemente representam um risco muito menor.\n",
    "* **Maior Risco:** Clientes com vínculos `Efetivo` e `Temporário` estão associados a um risco significativamente maior.\n",
    "\n",
    "Valor e Prazo da Parcela\n",
    "\n",
    "As características do contrato em si parecem ser relevantes, especialmente para modelos como Random Forest e LightGBM.\n",
    "* `Valor_Parcela` e `Total_Parcelas` apareceram consistentemente no topo. Quanto maior a dívida, maior o risco. A importância do `Valor_Parcela` cresce drasticamente ao prever inadimplências mais longas (90 dias).\n",
    "\n",
    "Contexto do Contrato :\n",
    "\n",
    "\n",
    "Fatores que descrevem o ambiente do contrato também têm sua importância explicativa\n",
    "* **`Esfera_Convenio_Municipal`:** Ser de um convênio municipal se mostrou um fator de proteção, reduzindo o risco.\n",
    "* **`Tipo_Produto_Empréstimo`:** Contratos de Empréstimo são, em geral, mais seguros que os de Cartão.\n",
    "* **`CAPAG`:** A classificação de capacidade de pagamento também apareceu como um preditor relevante em diversos cenários."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b32319",
   "metadata": {},
   "source": [
    "(Pré) Conclusão: \n",
    "1.   O **LightGBM** parece ser o modelo mais preciso e robusto para todas as faixas de previsão de inadimplência.\n",
    "2.  A principal variável para entender o risco é o **vínculo empregatício** do cliente.\n",
    "3.  A melhor previsão combina o **perfil do cliente** (vínculo) com os **dados do contrato** (valor, prazo, produto) e o **contexto** (esfera do convênio)- logo é multifatores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74233caa",
   "metadata": {},
   "source": [
    "#### Comparativo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4f32eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================\n",
      "   RESUMO COMPARATIVO FINAL - ROC-AUC\n",
      "========================================================================================\n",
      "                     Vencido_1d_Flag  Vencido_30d_Flag  Vencido_60d_Flag  \\\n",
      "Regressão Logística           0.9112            0.8480            0.8513   \n",
      "Random Forest                 0.9375            0.8822            0.8663   \n",
      "SVM (Kernel RBF)              0.9116            0.8336            0.8541   \n",
      "XGBoost                       0.9337            0.8901            0.8790   \n",
      "LightGBM                      0.9400            0.8953            0.8856   \n",
      "\n",
      "                     Vencido_90d_Flag  \n",
      "Regressão Logística            0.7809  \n",
      "Random Forest                  0.7975  \n",
      "SVM (Kernel RBF)               0.7841  \n",
      "XGBoost                        0.8290  \n",
      "LightGBM                       0.8371  \n",
      "\n",
      "----------------------------------------------------------------------------------------\n",
      "Considerando a média de ROC-AUC em todos os alvos, o melhor modelo parece ser: 'LightGBM'\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*88)\n",
    "print(\"   RESUMO COMPARATIVO FINAL - ROC-AUC\")\n",
    "print(\"=\"*88)\n",
    "print(resultados_finais.round(4))\n",
    "\n",
    "melhor_modelo_geral = resultados_finais.mean(axis=1).idxmax()\n",
    "print(\"\\n\" + \"-\"*88)\n",
    "print(f\"Considerando a média de ROC-AUC em todos os alvos, o melhor modelo parece ser: '{melhor_modelo_geral}'\")\n",
    "print(\"-\"*88)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8f9ad",
   "metadata": {},
   "source": [
    "### Stats Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17567be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Nomes das colunas limpos para o statsmodels:\n",
      "['CCB', 'CAPAG', 'Total_Parcelas', 'Valor_Parcela', 'Tipo_Produto', 'Tipo_Empregado', 'Esfera_Convenio', 'Faixa_Idade', 'Muitos_Contratos', 'max_dias_atraso', 'Vencido_1d_Flag', 'Vencido_30d_Flag', 'Vencido_60d_Flag', 'Vencido_90d_Flag']\n",
      "================================================================================\n",
      "\n",
      "### 1. Regressão Linear (OLS) para 'max_dias_atraso' ###\n",
      "\n",
      "Fórmula utilizada:\n",
      "max_dias_atraso ~ C(CAPAG) + Total_Parcelas + Valor_Parcela + C(Tipo_Produto) + C(Tipo_Empregado) + C(Esfera_Convenio) + C(Faixa_Idade) + Muitos_Contratos\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        max_dias_atraso   R-squared:                       0.364\n",
      "Model:                            OLS   Adj. R-squared:                  0.363\n",
      "Method:                 Least Squares   F-statistic:                     244.5\n",
      "Date:                Fri, 22 Aug 2025   Prob (F-statistic):               0.00\n",
      "Time:                        17:51:33   Log-Likelihood:                -36319.\n",
      "No. Observations:                6838   AIC:                         7.267e+04\n",
      "Df Residuals:                    6821   BIC:                         7.279e+04\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================================\n",
      "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Intercept                            29.0519      3.363      8.638      0.000      22.459      35.645\n",
      "C(CAPAG)[T.B]                       -33.3464      5.027     -6.633      0.000     -43.202     -23.491\n",
      "C(CAPAG)[T.C]                       -13.7962      2.307     -5.980      0.000     -18.319      -9.274\n",
      "C(CAPAG)[T.N.D.]                    -28.5068      3.261     -8.742      0.000     -34.899     -22.115\n",
      "C(Tipo_Produto)[T.Cartão RMC]         5.3271      1.949      2.734      0.006       1.507       9.147\n",
      "C(Tipo_Produto)[T.Empréstimo]       -21.7563      1.562    -13.924      0.000     -24.819     -18.693\n",
      "C(Tipo_Empregado)[T.Contratado]     -39.1317      2.829    -13.833      0.000     -44.677     -33.586\n",
      "C(Tipo_Empregado)[T.Efetivo]         85.0834      2.361     36.030      0.000      80.454      89.713\n",
      "C(Tipo_Empregado)[T.Outros]          44.8056      6.776      6.613      0.000      31.523      58.088\n",
      "C(Tipo_Empregado)[T.Temporário]      61.5118      2.108     29.186      0.000      57.380      65.643\n",
      "C(Esfera_Convenio)[T.Municipal]     -39.7841      2.359    -16.865      0.000     -44.408     -35.160\n",
      "C(Faixa_Idade)[T.38 a 45 anos]        0.3451      1.551      0.222      0.824      -2.696       3.386\n",
      "C(Faixa_Idade)[T.46 a 53 anos]        0.2704      1.713      0.158      0.875      -3.088       3.629\n",
      "C(Faixa_Idade)[T.54 anos ou mais]    -0.2443      1.834     -0.133      0.894      -3.840       3.351\n",
      "Total_Parcelas                        0.0325      0.028      1.147      0.251      -0.023       0.088\n",
      "Valor_Parcela                         0.0108      0.002      4.827      0.000       0.006       0.015\n",
      "Muitos_Contratos                      7.0570      1.212      5.823      0.000       4.681       9.433\n",
      "==============================================================================\n",
      "Omnibus:                      665.904   Durbin-Watson:                   0.936\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1202.175\n",
      "Skew:                           0.671   Prob(JB):                    8.93e-262\n",
      "Kurtosis:                       4.555   Cond. No.                     4.37e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.37e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)  #! !!!!! \n",
    "\n",
    "# TRATAR DADOS \n",
    "df_sm = df_ml.copy()\n",
    "df_sm.columns = df_sm.columns.str.replace(' ', '_', regex=False).str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "#(ele nao parece aceitar espaco, ç, etc)\n",
    "df_sm.dropna(inplace=True) # para garantir, nao deve fazer dfrença\n",
    "print(\"=\"*80)\n",
    "print(\"Nomes das colunas limpos para o statsmodels:\")\n",
    "print(df_sm.columns.tolist())\n",
    "print(\"=\"*80)\n",
    "\n",
    "# REGRESSÃO LINEAR (OLS)\n",
    "# OBJETIVO: Entender quais fatores influenciam a QUANTIDADE de dias em atraso.\n",
    "# como é reg linear, nao adianta tentar chegar a fatos binários, e sim a quantidades\n",
    "\n",
    "print(\"\\n### 1. Regressão Linear (OLS) para 'max_dias_atraso' ###\\n\")\n",
    "target_ols = 'max_dias_atraso'\n",
    "categorical_features = df_sm.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "numeric_features = df_sm.select_dtypes(include=np.number).columns.tolist() # identifico features\n",
    "\n",
    "#? ---------- removo colunas inúteis, como o próprio alvo, ou códigos --------------------------------------------------------------------------------\n",
    "predictors = [col for col in df_sm.columns if col not in ['CCB', 'max_dias_atraso'] + [c for c in df_sm.columns if 'Vencido' in c]]\n",
    "formula_parts = []\n",
    "for col in predictors:\n",
    "    if col in categorical_features:\n",
    "        formula_parts.append(f\"C({col})\")\n",
    "    else:\n",
    "        formula_parts.append(col)\n",
    "        \n",
    "formula_ols = f\"{target_ols} ~ \" + \" + \".join(formula_parts)\n",
    "\n",
    "print(f\"Fórmula utilizada:\\n{formula_ols}\\n\")\n",
    "\n",
    "# TREINAMENTO\n",
    "model_ols = smf.ols(formula=formula_ols, data=df_sm).fit()\n",
    "\n",
    "#SUMÁRIO\n",
    "print(model_ols.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd1f4c5",
   "metadata": {},
   "source": [
    "#### Regressão Logística \n",
    "Abaixo modelo nos diz que a inadimplência severa é menos sobre o histórico de crédito (`Muitos_Contratos`) e mais sobre o **contexto do cliente e do produto**. O risco é uma combinação de quem o cliente é (idade), onde ele trabalha (esfera do convênio) e o tipo de produto que ele contratou.\n",
    "\n",
    "Tipo Empregado foi removido por não convergir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692e21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "### REFAZENDO A REGRESSÃO LOGÍSTICA SEM A VARIÁVEL 'Tipo_Empregado' ###\n",
      "================================================================================\n",
      "\n",
      "<DEBUG> Variáveis preditoras utilizadas nesta nova análise:\n",
      "['CAPAG', 'Total_Parcelas', 'Valor_Parcela', 'Tipo_Produto', 'Esfera_Convenio', 'Faixa_Idade', 'Muitos_Contratos']\n",
      "\n",
      " [INFO] fórmula utilizada:\n",
      "Vencido_90d_Flag ~ C(CAPAG) + Total_Parcelas + Valor_Parcela + C(Tipo_Produto) + C(Esfera_Convenio) + C(Faixa_Idade) + Muitos_Contratos\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.611409\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       Vencido_90d_Flag   No. Observations:                 6838\n",
      "Model:                          Logit   Df Residuals:                     6825\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Fri, 22 Aug 2025   Pseudo R-squ.:                 0.04151\n",
      "Time:                        17:56:44   Log-Likelihood:                -4180.8\n",
      "converged:                       True   LL-Null:                       -4361.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.811e-70\n",
      "=====================================================================================================\n",
      "                                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Intercept                            -0.2247      0.130     -1.732      0.083      -0.479       0.030\n",
      "C(CAPAG)[T.B]                        -0.8929      0.253     -3.525      0.000      -1.389      -0.396\n",
      "C(CAPAG)[T.C]                        -0.4046      0.103     -3.913      0.000      -0.607      -0.202\n",
      "C(CAPAG)[T.N.D.]                     -0.7640      0.161     -4.748      0.000      -1.079      -0.449\n",
      "C(Tipo_Produto)[T.Cartão RMC]         0.4366      0.085      5.122      0.000       0.270       0.604\n",
      "C(Tipo_Produto)[T.Empréstimo]        -0.7115      0.068    -10.492      0.000      -0.844      -0.579\n",
      "C(Esfera_Convenio)[T.Municipal]      -0.9238      0.101     -9.143      0.000      -1.122      -0.726\n",
      "C(Faixa_Idade)[T.38 a 45 anos]        0.0500      0.069      0.722      0.470      -0.086       0.186\n",
      "C(Faixa_Idade)[T.46 a 53 anos]        0.1246      0.075      1.650      0.099      -0.023       0.273\n",
      "C(Faixa_Idade)[T.54 anos ou mais]     0.3163      0.079      4.002      0.000       0.161       0.471\n",
      "Total_Parcelas                        0.0043      0.001      3.552      0.000       0.002       0.007\n",
      "Valor_Parcela                         0.0003      0.000      3.264      0.001       0.000       0.001\n",
      "Muitos_Contratos                      0.0092      0.053      0.172      0.863      -0.095       0.114\n",
      "=====================================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "--- Coeficientes do Modelo (Razão de Chances / Odds Ratio) ---\n",
      "                                   Odds Ratio         P>|z|  OR CI Inferior  \\\n",
      "Intercept                            0.798754  8.327740e-02        0.619414   \n",
      "C(CAPAG)[T.B]                        0.409478  4.238291e-04        0.249236   \n",
      "C(CAPAG)[T.C]                        0.667262  9.108934e-05        0.544870   \n",
      "C(CAPAG)[T.N.D.]                     0.465784  2.055385e-06        0.339789   \n",
      "C(Tipo_Produto)[T.Cartão RMC]        1.547486  3.027920e-07        1.309365   \n",
      "C(Tipo_Produto)[T.Empréstimo]        0.490902  9.375125e-26        0.429806   \n",
      "C(Esfera_Convenio)[T.Municipal]      0.397026  6.067416e-20        0.325701   \n",
      "C(Faixa_Idade)[T.38 a 45 anos]       1.051286  4.704270e-01        0.917780   \n",
      "C(Faixa_Idade)[T.46 a 53 anos]       1.132691  9.886480e-02        0.976899   \n",
      "C(Faixa_Idade)[T.54 anos ou mais]    1.372015  6.287487e-05        1.175124   \n",
      "Total_Parcelas                       1.004265  3.825181e-04        1.001909   \n",
      "Valor_Parcela                        1.000335  1.098250e-03        1.000134   \n",
      "Muitos_Contratos                     1.009228  8.631277e-01        0.909152   \n",
      "\n",
      "                                   OR CI Superior  \n",
      "Intercept                                1.030020  \n",
      "C(CAPAG)[T.B]                            0.672745  \n",
      "C(CAPAG)[T.C]                            0.817146  \n",
      "C(CAPAG)[T.N.D.]                         0.638499  \n",
      "C(Tipo_Produto)[T.Cartão RMC]            1.828911  \n",
      "C(Tipo_Produto)[T.Empréstimo]            0.560683  \n",
      "C(Esfera_Convenio)[T.Municipal]          0.483969  \n",
      "C(Faixa_Idade)[T.38 a 45 anos]           1.204213  \n",
      "C(Faixa_Idade)[T.46 a 53 anos]           1.313327  \n",
      "C(Faixa_Idade)[T.54 anos ou mais]        1.601895  \n",
      "Total_Parcelas                           1.006626  \n",
      "Valor_Parcela                            1.000535  \n",
      "Muitos_Contratos                         1.120318  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# REGRESSÃO LOGÍSTICA (LOGIT) ---\n",
    "# OBJETIVO: Entender quais fatores influenciam a PROBABILIDADE de um contrato\n",
    "#           ter um atraso severo (>= 90 dias).\n",
    "\"\"\"\n",
    "# obs: estou removendo a variável 'Tipo_Empregado' que causou a falha de convergência\n",
    "# devido ao problema de separação perfeita, no caso de 90 dias\n",
    "\"\"\"\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"### REFAZENDO A REGRESSÃO LOGÍSTICA SEM A VARIÁVEL 'Tipo_Empregado' ###\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Obter preditores e remover 'Tipo_Empregado'\n",
    "preditores_originais = [col for col in df_sm.columns if col not in ['CCB', 'max_dias_atraso'] + [c for c in df_sm.columns if 'Vencido' in c]]\n",
    "preditores_corrigidos = [p for p in preditores_originais if p != 'Tipo_Empregado'] #! se for diferente de 90, pode trocar isso\n",
    "\n",
    "print(\"\\n<DEBUG> Variáveis preditoras utilizadas nesta nova análise:\")\n",
    "print(preditores_corrigidos)\n",
    "\n",
    "#! ########################################################\n",
    "target_logit = 'Vencido_90d_Flag'\n",
    "\n",
    "#! OBSERVAÇÂO: Você pode trocar 90d por 1d, 30d, etc.\n",
    "#! estou deixando assim apenas para nao ficar muito massivo\n",
    "#! ########################################################\n",
    "\n",
    "formula_parts_corrigida = []\n",
    "for col in preditores_corrigidos:\n",
    "    if col in df_sm.select_dtypes(include=['object', 'category', 'bool']).columns:\n",
    "        formula_parts_corrigida.append(f\"C({col})\")\n",
    "    else:\n",
    "        formula_parts_corrigida.append(col)\n",
    "        \n",
    "formula_logit_corrigida = f\"{target_logit} ~ \" + \" + \".join(formula_parts_corrigida)\n",
    "\n",
    "print(f\"\\n [INFO] fórmula utilizada:\\n{formula_logit_corrigida}\\n\")\n",
    "\n",
    "model_logit_corrigido = smf.logit(formula=formula_logit_corrigida, data=df_sm).fit()\n",
    "\n",
    "\n",
    "# SUMÁRIO\n",
    "print(model_logit_corrigido.summary())\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"--- Coeficientes do Modelo (Razão de Chances / Odds Ratio) ---\")\n",
    "\n",
    "odds_ratios_corrigido = pd.DataFrame({\n",
    "    \"Odds Ratio\": np.exp(model_logit_corrigido.params),\n",
    "    \"P>|z|\": model_logit_corrigido.pvalues\n",
    "})\n",
    "conf_int_corrigido = np.exp(model_logit_corrigido.conf_int())\n",
    "conf_int_corrigido.columns = ['OR CI Inferior', 'OR CI Superior']\n",
    "odds_ratios_corrigido = odds_ratios_corrigido.join(conf_int_corrigido)\n",
    "\n",
    "print(odds_ratios_corrigido)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000b851c",
   "metadata": {},
   "source": [
    "## Referências\n",
    "Abaixo estão os links que eu visitei para consultar dúvidas: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e24463",
   "metadata": {},
   "source": [
    "machine learning - How to deal with possible data leakage in time series data? - Data Science Stack Exchange\n",
    "https://datascience.stackexchange.com/questions/45575/how-to-deal-with-possible-data-leakage-in-time-series-data\n",
    "Python Pandas: Keeping only dataframe rows containing first occurrence of an item - Stack Overflow\n",
    "https://stackoverflow.com/questions/24136620/python-pandas-keeping-only-dataframe-rows-containing-first-occurrence-of-an-ite/24137060\n",
    "python - Add column with number of days between dates in DataFrame pandas - Stack Overflow\n",
    "https://stackoverflow.com/questions/22132525/add-column-with-number-of-days-between-dates-in-dataframe-pandas\n",
    "Python Pandas max value in a group as a new column - Stack Overflow\n",
    "https://stackoverflow.com/questions/35640364/python-pandas-max-value-in-a-group-as-a-new-column\n",
    "python - Assign conditions from a list np.select and create a new column (pandas) - Stack Overflow\n",
    "https://stackoverflow.com/questions/69824116/assign-conditions-from-a-list-np-select-and-create-a-new-column-pandas\n",
    "python - Pandas get the age from a date (example: date of birth) - Stack Overflow\n",
    "https://stackoverflow.com/questions/26788854/pandas-get-the-age-from-a-date-example-date-of-birth\n",
    "Why do we use stratify in train_test_split | by aymuosmukherjee | Medium\n",
    "https://medium.com/@aymuosmukherjee/why-do-we-use-stratify-in-train-test-split-e3eb296a5494\n",
    "python - How can I align pandas get_dummies across training / validation / testing? - Stack Overflow\n",
    "https://stackoverflow.com/questions/56738267/how-can-i-align-pandas-get-dummies-across-training-validation-testing\n",
    "Feature Engineering in a Pipeline - Weijian Zhang\n",
    "https://weijianzhg.com/blog/2021/feature-engineering/\n",
    "Column Transformer with Mixed Types — scikit-learn 1.7.1 documentation\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "How Does the class_weight Parameter in Scikit-Learn Work? - GeeksforGeeks\n",
    "https://www.geeksforgeeks.org/machine-learning/how-does-the-classweight-parameter-in-scikit-learn-work/\n",
    "unbalanced classes - What is the proper usage of scale_pos_weight in xgboost for imbalanced datasets? - Cross Validated\n",
    "https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n",
    "roc_auc_score — scikit-learn 1.7.1 documentation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "F1 Score vs ROC AUC vs Accuracy vs PR AUC - Neptune.ai\n",
    "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc\n",
    "python - XGBoostClassifier: model.get_booster().get_score(importance_type=\"gain\") not return entire feature importance - Stack Overflow\n",
    "https://stackoverflow.com/questions/74067871/xgboostclassifier-model-get-booster-get-scoreimportance-type-gain-not-ret\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
