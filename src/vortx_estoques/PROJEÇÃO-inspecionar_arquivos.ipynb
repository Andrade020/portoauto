{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a7bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecionando: carteira_52203615000119_20250901.json ---\n",
      "Formato: JSON\n",
      "Tipo: Lista de objetos\n",
      "Chaves do primeiro objeto da lista: ['carteiras', 'ativos', 'passivos']\n",
      "-----------------------------------------------------------\n",
      "\n",
      "--- Inspecionando: 130170-Demonstrativo_Caixa.xlsx ---\n",
      "Formato: Excel com 1 aba(s): ['52203615000119-15540']\n",
      "\n",
      "... Lendo aba: '52203615000119-15540' ...\n",
      "Colunas detectadas: ['Fundo', 'Carteira', 'Tipo Carteira', 'Posição', 'Emissão', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7']\n",
      "Prévia das 60 primeiras linhas:\n",
      "                     Fundo                            Carteira Tipo Carteira  \\\n",
      "0   FIDC FCT CONSIGNADO II                               15540          FIDC   \n",
      "1                      NaN                                 NaN           NaN   \n",
      "2                   Título                           Histórico     Título CP   \n",
      "3                      NaN           SALDO FINAL EM 07/07/2025           NaN   \n",
      "4                C/C VORTX              Certificadora - 584755  #CERTDIGITAL   \n",
      "5                C/C VORTX                Valor a indentificar         VALID   \n",
      "6                C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "7                C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "8                C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "9                C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "10               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "11               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "12               C/C VORTX                        AQUISICAO DC    DC C AQUIS   \n",
      "13               C/C VORTX               Crédito a Identificar         VALID   \n",
      "14               C/C VORTX  Venda Cota CRT 1442 FC FIRF BEYOND    BEYOND FCT   \n",
      "15               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "16               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "17               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "18               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "19               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "20               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "21               C/C VORTX                        AQUISICAO DC    DC C AQUIS   \n",
      "22               C/C VORTX  Venda Cota CRT 1442 FC FIRF BEYOND    BEYOND FCT   \n",
      "23               C/C VORTX                Valor a indentificar         VALID   \n",
      "24               C/C VORTX                Valor a indentificar         VALID   \n",
      "25               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "26               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "27               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "28               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "29               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "30               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "31               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "32               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "33               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "34               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "35               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "36               C/C VORTX                        AQUISICAO DC    DC C AQUIS   \n",
      "37               C/C VORTX  Venda Cota CRT 1442 FC FIRF BEYOND    BEYOND FCT   \n",
      "38               C/C VORTX  Venda Cota CRT 1442 FC FIRF BEYOND    BEYOND FCT   \n",
      "39               C/C VORTX                Valor a indentificar         VALID   \n",
      "40               C/C VORTX                Valor a indentificar         VALID   \n",
      "41               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "42               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "43               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "44               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "45               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "46               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "47               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "48               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "49               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "50               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "51               C/C VORTX                          Tarifa TED    #TARIFBANC   \n",
      "52               C/C VORTX                        AQUISICAO DC    DC C AQUIS   \n",
      "53               C/C VORTX               Crédito a Identificar         VALID   \n",
      "54               C/C VORTX  Venda Cota CRT 1442 FC FIRF BEYOND    BEYOND FCT   \n",
      "55               C/C VORTX  Venda Cota CRT 1442 FC FIRF BEYOND    BEYOND FCT   \n",
      "56               C/C VORTX                Valor a indentificar         VALID   \n",
      "57               C/C VORTX                Valor a indentificar         VALID   \n",
      "58               C/C VORTX                Valor a indentificar         VALID   \n",
      "59               C/C VORTX                Valor a indentificar         VALID   \n",
      "\n",
      "                    Posição     Emissão     Unnamed: 5     Unnamed: 6  \\\n",
      "0   08/07/2025 a 07/08/2025  11/09/2025            NaN            NaN   \n",
      "1                       NaN         NaN            NaN            NaN   \n",
      "2                      Data        Tipo      Entrada/D        Saída/C   \n",
      "3                       NaN         NaN            NaN            NaN   \n",
      "4                08/07/2025         Fut        R$ 0,00    R$ 1.413,62   \n",
      "5                08/07/2025         Fut  R$ 101.052,20        R$ 0,00   \n",
      "6                08/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "7                08/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "8                08/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "9                08/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "10               08/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "11               08/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "12               08/07/2025         Dig        R$ 0,00  R$ 244.667,00   \n",
      "13               08/07/2025         Dig   R$ 53.597,83        R$ 0,00   \n",
      "14               08/07/2025         Aut   R$ 82.407,72        R$ 0,00   \n",
      "15               09/07/2025         Fut        R$ 0,00       R$ 17,90   \n",
      "16               09/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "17               09/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "18               09/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "19               09/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "20               09/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "21               09/07/2025         Dig        R$ 0,00  R$ 286.301,81   \n",
      "22               09/07/2025         Aut  R$ 283.748,56        R$ 0,00   \n",
      "23               10/07/2025         Fut   R$ 55.921,40        R$ 0,00   \n",
      "24               10/07/2025         Fut    R$ 1.068,46        R$ 0,00   \n",
      "25               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "26               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "27               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "28               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "29               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "30               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "31               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "32               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "33               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "34               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "35               10/07/2025         Fut        R$ 0,00        R$ 9,70   \n",
      "36               10/07/2025         Dig        R$ 0,00  R$ 495.234,27   \n",
      "37               10/07/2025         Aut   R$ 35.559,34        R$ 0,00   \n",
      "38               10/07/2025         Aut  R$ 402.791,77        R$ 0,00   \n",
      "39               11/07/2025         Fut   R$ 18.391,21        R$ 0,00   \n",
      "40               11/07/2025         Fut   R$ 13.852,82        R$ 0,00   \n",
      "41               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "42               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "43               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "44               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "45               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "46               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "47               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "48               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "49               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "50               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "51               11/07/2025         Dig        R$ 0,00        R$ 9,70   \n",
      "52               11/07/2025         Dig        R$ 0,00  R$ 772.639,52   \n",
      "53               11/07/2025         Dig   R$ 42.531,01        R$ 0,00   \n",
      "54               11/07/2025         Aut  R$ 307.135,95        R$ 0,00   \n",
      "55               11/07/2025         Aut  R$ 395.730,01        R$ 0,00   \n",
      "56               14/07/2025         Fut   R$ 48.423,66        R$ 0,00   \n",
      "57               14/07/2025         Fut    R$ 6.306,90        R$ 0,00   \n",
      "58               14/07/2025         Fut  R$ 273.848,84        R$ 0,00   \n",
      "59               14/07/2025         Fut    R$ 1.037,31        R$ 0,00   \n",
      "\n",
      "        Unnamed: 7  \n",
      "0              NaN  \n",
      "1              NaN  \n",
      "2            Saldo  \n",
      "3     R$ 12.700,72  \n",
      "4     R$ 11.287,10  \n",
      "5    R$ 112.339,30  \n",
      "6    R$ 112.329,60  \n",
      "7    R$ 112.319,90  \n",
      "8    R$ 112.310,20  \n",
      "9    R$ 112.300,50  \n",
      "10   R$ 112.290,80  \n",
      "11   R$ 112.281,10  \n",
      "12  R$ -132.385,90  \n",
      "13   R$ -78.788,07  \n",
      "14     R$ 3.619,65  \n",
      "15     R$ 3.601,75  \n",
      "16     R$ 3.592,05  \n",
      "17     R$ 3.582,35  \n",
      "18     R$ 3.572,65  \n",
      "19     R$ 3.562,95  \n",
      "20     R$ 3.553,25  \n",
      "21  R$ -282.748,56  \n",
      "22       R$ 999,99  \n",
      "23    R$ 56.921,40  \n",
      "24    R$ 57.989,86  \n",
      "25    R$ 57.980,16  \n",
      "26    R$ 57.970,46  \n",
      "27    R$ 57.960,76  \n",
      "28    R$ 57.951,06  \n",
      "29    R$ 57.941,36  \n",
      "30    R$ 57.931,66  \n",
      "31    R$ 57.921,96  \n",
      "32    R$ 57.912,26  \n",
      "33    R$ 57.902,56  \n",
      "34    R$ 57.892,86  \n",
      "35    R$ 57.883,16  \n",
      "36  R$ -437.351,11  \n",
      "37  R$ -401.791,77  \n",
      "38     R$ 1.000,00  \n",
      "39    R$ 19.391,21  \n",
      "40    R$ 33.244,03  \n",
      "41    R$ 33.234,33  \n",
      "42    R$ 33.224,63  \n",
      "43    R$ 33.214,93  \n",
      "44    R$ 33.205,23  \n",
      "45    R$ 33.195,53  \n",
      "46    R$ 33.185,83  \n",
      "47    R$ 33.176,13  \n",
      "48    R$ 33.166,43  \n",
      "49    R$ 33.156,73  \n",
      "50    R$ 33.147,03  \n",
      "51    R$ 33.137,33  \n",
      "52  R$ -739.502,19  \n",
      "53  R$ -696.971,18  \n",
      "54  R$ -389.835,23  \n",
      "55     R$ 5.894,77  \n",
      "56    R$ 54.318,44  \n",
      "57    R$ 60.625,34  \n",
      "58   R$ 334.474,18  \n",
      "59   R$ 335.511,49  \n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Inspecionando: 130166-Carteira.xlsx ---\n",
      "Formato: Excel com 16 aba(s): ['InfoGerais', 'Pagar', 'Receber', 'Disponibilidade', 'CotasAplicadas', 'Imoveis', 'Compromissada', 'RendaFixa', 'RendaVariavel', 'AluguelAções', 'OpçõesAções', 'Futuros', 'OpçõesFuturos', 'Swap', 'OpçõesFlexíveis', 'OpçõesDerivativos']\n",
      "\n",
      "... Lendo aba: 'InfoGerais' ...\n",
      "Colunas detectadas: ['carteira', 'cnpjFundo', 'nome', 'dataAtual', 'administracao', 'pl', 'quantidadeCotas', 'valorCota', 'variacaoCota']\n",
      "Prévia das 60 primeiras linhas:\n",
      "   carteira           cnpjFundo             nome   dataAtual  \\\n",
      "0     15543  52.203.615/0001-19  FIDC FCT II SR2  07/08/2025   \n",
      "1     15540  52.203.615/0001-19      FIDC FCT II  07/08/2025   \n",
      "\n",
      "                                       administracao            pl  \\\n",
      "0  VORTX DISTRIBUIDORA DE TITULOS E VALORES MOBIL...  1.106135e+08   \n",
      "1  VORTX DISTRIBUIDORA DE TITULOS E VALORES MOBIL...  5.288521e+07   \n",
      "\n",
      "   quantidadeCotas    valorCota  variacaoCota  \n",
      "0     1.000000e+05  1106.135164      0.066868  \n",
      "1     1.484642e+06    35.621530     -0.251922  \n",
      "\n",
      "... Lendo aba: 'Pagar' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'despesa', 'detalhes', 'valor']\n",
      "Prévia das 60 primeiras linhas:\n",
      "   carteira              nome       despesa                         detalhes  \\\n",
      "0     15540  FIDC FCT II       AUDIT DEZ25                         Auditoria   \n",
      "1     15540  FIDC FCT II       AUDIT LASTRO                        Auditoria   \n",
      "2     15540  FIDC FCT II       PEND GESTÃO   Outras Despesas Administrativas   \n",
      "3     15540  FIDC FCT II       PROV ADM                   Taxa Administração   \n",
      "4     15540  FIDC FCT II       PROV GESTÃO   Outras Despesas Administrativas   \n",
      "5     15540  FIDC FCT II       TX ESCRT FIX  Outras Despesas Administrativas   \n",
      "6     15540  FIDC FCT II       VALID                                  Outros   \n",
      "\n",
      "        valor  \n",
      "0    -4352.85  \n",
      "1   -11628.13  \n",
      "2      -49.69  \n",
      "3    -5791.77  \n",
      "4   -19305.92  \n",
      "5     -496.45  \n",
      "6 -3456282.36  \n",
      "\n",
      "... Lendo aba: 'Receber' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'valReceb', 'detalhes', 'valor']\n",
      "Prévia das 60 primeiras linhas:\n",
      "   carteira   nome      valReceb                                detalhes  \\\n",
      "0     15540  15540  CETIP 08/25                               Taxa CETIP   \n",
      "1     15540  15540  DC C AQUIS                        Direito Creditório   \n",
      "2     15540  15540  DIF CVM25                                   Taxa CVM   \n",
      "3     15540  15540  FDC SR 15542  Cotas - Fundos (Ingressos / Retiradas)   \n",
      "4     15540  15540  PDD C RISCO                                   Outros   \n",
      "5     15540  15540  VAL A RECEB                                   Outros   \n",
      "\n",
      "          valor  \n",
      "0  1.412550e+03  \n",
      "1  2.071667e+08  \n",
      "2  1.194573e+04  \n",
      "3 -1.106135e+08  \n",
      "4 -4.128389e+07  \n",
      "5  9.890820e+05  \n",
      "\n",
      "... Lendo aba: 'Disponibilidade' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'instituicao', 'saldo']\n",
      "Prévia das 60 primeiras linhas:\n",
      "   carteira         nome   instituicao  saldo\n",
      "0     15540  FIDC FCT II  VORTX          1000\n",
      "\n",
      "... Lendo aba: 'CotasAplicadas' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'titulo', 'tipoFundo', 'fundo', 'cnpj', 'quantidade', 'valorCota', 'valorBruto', 'tributos', 'valorLiquido', 'isin']\n",
      "Prévia das 60 primeiras linhas:\n",
      "   carteira              nome        titulo tipoFundo  \\\n",
      "0     15540  FIDC FCT II       BEYOND FCT    Fundo RF   \n",
      "\n",
      "                             fundo                cnpj    quantidade  \\\n",
      "0  BEYOND SOBERANO FC FI RF REF DI  50.628.101/0001-80  87624.568572   \n",
      "\n",
      "   valorCota  valorBruto  tributos  valorLiquido          isin  \n",
      "0   1.260138   110419.04         0     110419.04  BR0GIACTF005  \n",
      "\n",
      "... Lendo aba: 'Imoveis' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'imovel', 'detalhes', 'quantidade', 'custoAquisicao', 'mercadoAtual']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, nome, imovel, detalhes, quantidade, custoAquisicao, mercadoAtual]\n",
      "Index: []\n",
      "\n",
      "... Lendo aba: 'Compromissada' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'nomeMercado', 'tipo', 'codigoCustodia', 'emissor', 'dataCompra', 'dataRetornoCompromissada', 'dataEmissaoLastro', 'dataVencimentoLastro', 'taxa', 'indexador', 'quantidade', 'valorCompra', 'valorRetornoPre', 'mercadoAtual']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, nome, nomeMercado, tipo, codigoCustodia, emissor, dataCompra, dataRetornoCompromissada, dataEmissaoLastro, dataVencimentoLastro, taxa, indexador, quantidade, valorCompra, valorRetornoPre, mercadoAtual]\n",
      "Index: []\n",
      "\n",
      "... Lendo aba: 'RendaFixa' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'nomeMercado', 'tipo', 'codigoCustodia', 'emissor', 'dataCompra', 'dataEmissao', 'dataVencimento', 'taxa', 'indexador', 'quantidadeLivre', 'quantidadeBloqueio', 'valorCompra', 'custoAtual', 'mercadoAtual', 'ateVencimento', 'isin', 'puMercado', 'puCusto']\n",
      "Prévia das 60 primeiras linhas:\n",
      "   carteira             nome nomeMercado    tipo codigoCustodia emissor  \\\n",
      "0     15543  FIDC FCT II SR2       CETIP  Outros   09H00003977-  ******   \n",
      "\n",
      "   dataCompra dataEmissao dataVencimento taxa indexador  quantidadeLivre  \\\n",
      "0  16/12/2024  16/12/2024     18/12/2028  3,0       DI1           100000   \n",
      "\n",
      "   quantidadeBloqueio  valorCompra    custoAtual  mercadoAtual ateVencimento  \\\n",
      "0                   0    100000000  1.106135e+08  1.106135e+08           Não   \n",
      "\n",
      "           isin  puMercado   puCusto  \n",
      "0  BR0000000000   1106.135  1106.135  \n",
      "\n",
      "... Lendo aba: 'RendaVariavel' ...\n",
      "Colunas detectadas: ['cnpjFundo', 'carteira', 'nome', 'titulo', 'emissor', 'quantidadeLivre', 'quantidadeBloqueio', 'puCusto', 'curvaAtual', 'puMercado', 'mercadoAtual']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [cnpjFundo, carteira, nome, titulo, emissor, quantidadeLivre, quantidadeBloqueio, puCusto, curvaAtual, puMercado, mercadoAtual]\n",
      "Index: []\n",
      "\n",
      "... Lendo aba: 'AluguelAções' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'acaoObjeto', 'situacao', 'emissor', 'vencimento', 'quantidade', 'puCusto', 'curvaAtual', 'puMercado', 'mercadoAtual']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, nome, acaoObjeto, situacao, emissor, vencimento, quantidade, puCusto, curvaAtual, puMercado, mercadoAtual]\n",
      "Index: []\n",
      "\n",
      "... Lendo aba: 'OpçõesAções' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'tipo', 'callPut', 'titulo', 'dataVencimento', 'precoExercicio', 'quantidade', 'custoAtual', 'puMercado', 'mercadoAtual']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, nome, tipo, callPut, titulo, dataVencimento, precoExercicio, quantidade, custoAtual, puMercado, mercadoAtual]\n",
      "Index: []\n",
      "\n",
      "... Lendo aba: 'Futuros' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'mercado', 'mercadoria', 'sigla', 'serie', 'vencimento', 'quantidade', 'nocional', 'mercadoAjuste']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, nome, mercado, mercadoria, sigla, serie, vencimento, quantidade, nocional, mercadoAjuste]\n",
      "Index: []\n",
      "\n",
      "... Lendo aba: 'OpçõesFuturos' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'mercado', 'mercadoria', 'sigla', 'serie', 'vencimento', 'quantidade', 'nocional', 'mercadoAjuste']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, nome, mercado, mercadoria, sigla, serie, vencimento, quantidade, nocional, mercadoAjuste]\n",
      "Index: []\n",
      "\n",
      "... Lendo aba: 'Swap' ...\n",
      "Colunas detectadas: ['carteira', 'contrato', 'emissor', 'contraparte', 'codIsin', 'dtCompra', 'dtEmissao', 'dtVenc', 'indexAtivo', 'porcentIndexAtivo', 'tipoIdexAtivo', 'indexPassivo', 'porcentIndexPassivo', 'tipoIndexPassivo', 'txAtiva', 'txPassiva', 'quantidade', 'valorCompra', 'curvaAtiva', 'curvaPassiva', 'MtMAtivo', 'MtMPassivo', 'Net']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, contrato, emissor, contraparte, codIsin, dtCompra, dtEmissao, dtVenc, indexAtivo, porcentIndexAtivo, tipoIdexAtivo, indexPassivo, porcentIndexPassivo, tipoIndexPassivo, txAtiva, txPassiva, quantidade, valorCompra, curvaAtiva, curvaPassiva, MtMAtivo, MtMPassivo, Net]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n",
      "\n",
      "... Lendo aba: 'OpçõesFlexíveis' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'tipo', 'callPut', 'dataOperacao', 'dataExercicio', 'ativo', 'garantia', 'premio', 'puMercado', 'quantidade', 'valorFinanceiro', 'tributos', 'precoExercicio', 'classeOperacao', 'hedge', 'tipoHedge']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, nome, tipo, callPut, dataOperacao, dataExercicio, ativo, garantia, premio, puMercado, quantidade, valorFinanceiro, tributos, precoExercicio, classeOperacao, hedge, tipoHedge]\n",
      "Index: []\n",
      "\n",
      "... Lendo aba: 'OpçõesDerivativos' ...\n",
      "Colunas detectadas: ['carteira', 'nome', 'isin', 'mercado', 'sigla', 'serie', 'callPut', 'quantidade', 'vencimento', 'premio', 'puMercado', 'valorFinanceiro', 'tributos', 'precoExercicio', 'classeOperacao', 'hedge', 'tipoHedge']\n",
      "Prévia das 60 primeiras linhas:\n",
      "Empty DataFrame\n",
      "Columns: [carteira, nome, isin, mercado, sigla, serie, callPut, quantidade, vencimento, premio, puMercado, valorFinanceiro, tributos, precoExercicio, classeOperacao, hedge, tipoHedge]\n",
      "Index: []\n",
      "------------------------------------------\n",
      "\n",
      "--- Inspecionando: remessas_2025-09-01_completo.json ---\n",
      "Formato: JSON\n",
      "Tipo: Lista de objetos\n",
      "Chaves do primeiro objeto da lista: ['remessaId', 'tipoRemessa', 'qtdTitulos', 'codigoStatus', 'status', 'dataInclusao', 'fundo', 'fundoCNPJ', 'cedente', 'cedenteCPFCNPJ', 'certificadora', 'valorNominal', 'valorPresente', 'valorPagamento', 'valorRecompra', 'uniqueId', 'contasPagamento', 'detalhesStatus', 'signatarios', 'erros']\n",
      "-------------------------------------------------------\n",
      "\n",
      "--- Inspecionando: remessas_2025-09-01_detalhes_status.csv ---\n",
      "Formato: CSV\n",
      "Colunas detectadas: ['codigoStatus', 'descricao', 'dataCriacao', 'alterador', 'remessaId']\n",
      "Prévia das 5 primeiras linhas:\n",
      "                        codigoStatus  \\\n",
      "0    STATUS_REMESSA_ARQUIVO_RECEBIDO   \n",
      "1  STATUS_REMESSA_ESTRUTURA_PENDENTE   \n",
      "2   STATUS_REMESSA_ENVIADA_BOLETADOR   \n",
      "3  STATUS_REMESSA_ARQUIVO_PROCESSADO   \n",
      "4   STATUS_REMESSA_DADOS_PROCESSANDO   \n",
      "\n",
      "                                         descricao              dataCriacao  \\\n",
      "0                    Arquivo recebido com sucesso.   2025-09-01T10:35:23.05   \n",
      "1  Estrutura da remessa pendente de processamento.   2025-09-01T10:35:23.11   \n",
      "2                 Remessa enviada para o boletador  2025-09-01T10:35:26.187   \n",
      "3                    Arquivo de remessa processado   2025-09-01T10:36:31.73   \n",
      "4                       Processando dados remessa.    2025-09-01T10:36:31.8   \n",
      "\n",
      "                         alterador  remessaId  \n",
      "0                          SISTEMA   78417127  \n",
      "1                          SISTEMA   78417127  \n",
      "2  SISTEMA VRS.Remessas.Serverless   78417127  \n",
      "3                          SISTEMA   78417127  \n",
      "4                          SISTEMA   78417127  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "--- Inspecionando: remessas_2025-09-01_lista.csv ---\n",
      "Formato: CSV\n",
      "Colunas detectadas: ['remessaId', 'tipoRemessa', 'qtdTitulos', 'codigoStatus', 'status', 'dataInclusao', 'fundo', 'fundoCNPJ', 'cedente', 'cedenteCPFCNPJ', 'certificadora', 'valorNominal', 'valorPresente', 'valorPagamento', 'valorRecompra', 'uniqueId']\n",
      "Prévia das 5 primeiras linhas:\n",
      "   remessaId tipoRemessa  qtdTitulos              codigoStatus  \\\n",
      "0   78417127      COMPRA         372  STATUS_REMESSA_CONCLUIDA   \n",
      "1   39878991      COMPRA         612  STATUS_REMESSA_CONCLUIDA   \n",
      "2   92112125      COMPRA         360  STATUS_REMESSA_CONCLUIDA   \n",
      "3   26485909  LIQUIDAÇÃO         625   PROCESSAMENTO_CONCLUIDO   \n",
      "4   81902257  LIQUIDAÇÃO         934   PROCESSAMENTO_CONCLUIDO   \n",
      "\n",
      "                                              status             dataInclusao  \\\n",
      "0                                Operação concluída.  2025-09-01T10:35:23.037   \n",
      "1                                Operação concluída.   2025-09-01T10:35:24.24   \n",
      "2                                Operação concluída.   2025-09-01T10:35:34.78   \n",
      "3  Processamento concluído com sucesso! (Liquidaç...   2025-09-01T14:06:22.06   \n",
      "4  Processamento concluído com sucesso! (Liquidaç...   2025-09-01T14:06:25.18   \n",
      "\n",
      "                     fundo           fundoCNPJ  \\\n",
      "0  FIDC FCT CONSIGNADO II   52.203.615/0001-19   \n",
      "1  FIDC FCT CONSIGNADO II   52.203.615/0001-19   \n",
      "2  FIDC FCT CONSIGNADO II   52.203.615/0001-19   \n",
      "3  FIDC FCT CONSIGNADO II   52.203.615/0001-19   \n",
      "4  FIDC FCT CONSIGNADO II   52.203.615/0001-19   \n",
      "\n",
      "                                          cedente      cedenteCPFCNPJ  \\\n",
      "0  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  34.337.707/0001-00   \n",
      "1  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  34.337.707/0001-00   \n",
      "2  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  34.337.707/0001-00   \n",
      "3  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  34.337.707/0001-00   \n",
      "4  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  34.337.707/0001-00   \n",
      "\n",
      "   certificadora  valorNominal  valorPresente  valorPagamento  valorRecompra  \\\n",
      "0            NaN      87880.56       36103.74        36103.74              0   \n",
      "1            NaN     241043.28       92421.14        92421.14              0   \n",
      "2            NaN      81488.52       36647.10        36647.10              0   \n",
      "3            NaN          0.00      315172.48            0.00              0   \n",
      "4            NaN          0.00       30779.19            0.00              0   \n",
      "\n",
      "   uniqueId  \n",
      "0  MzQzODkz  \n",
      "1  MzQzODk0  \n",
      "2  MzQzODk4  \n",
      "3  MzQzOTY1  \n",
      "4  MzQzOTY2  \n",
      "---------------------------------------------------\n",
      "\n",
      "--- Inspecionando: atualizacao_acessos.xlsx ---\n",
      "Formato: Excel com 1 aba(s): ['Planilha1']\n",
      "\n",
      "... Lendo aba: 'Planilha1' ...\n",
      "Colunas detectadas: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21']\n",
      "Prévia das 60 primeiras linhas:\n",
      "    Unnamed: 0  Unnamed: 1                       Unnamed: 2  Unnamed: 3  \\\n",
      "0          NaN         NaN                              NaN         NaN   \n",
      "1          NaN         NaN                              NaN         NaN   \n",
      "2          NaN         NaN                              NaN         NaN   \n",
      "3          NaN         NaN                              NaN         NaN   \n",
      "4          NaN         NaN                              NaN         NaN   \n",
      "5          NaN         NaN                              NaN         NaN   \n",
      "6          NaN         NaN                              NaN         NaN   \n",
      "7          NaN         NaN                              NaN         NaN   \n",
      "8          NaN         NaN                              NaN         NaN   \n",
      "9          NaN         NaN                              NaN         NaN   \n",
      "10         NaN         NaN                              NaN         NaN   \n",
      "11         NaN         NaN                              NaN         NaN   \n",
      "12         NaN         NaN                              NaN         NaN   \n",
      "13         NaN         NaN                              NaN         NaN   \n",
      "14         NaN         NaN                              NaN         NaN   \n",
      "15         NaN         NaN                              NaN         NaN   \n",
      "16         NaN         NaN                              NaN         NaN   \n",
      "17         NaN         NaN  tem listagem de cnpj de fundos?         NaN   \n",
      "\n",
      "    Unnamed: 4 Unnamed: 5                              Unnamed: 6  Unnamed: 7  \\\n",
      "0          NaN        NaN                                     NaN         NaN   \n",
      "1          NaN        NaN                                     NaN         NaN   \n",
      "2          NaN          X                               PERMISSÃO         NaN   \n",
      "3          NaN         OK                                     NaN         NaN   \n",
      "4          NaN         OK                                     NaN         NaN   \n",
      "5          NaN         OK                                     NaN         NaN   \n",
      "6          NaN          X                               PERMISSÃO         NaN   \n",
      "7          NaN          X                               PERMISSÃO         NaN   \n",
      "8          NaN          x              SEM PERMISSÃO PARA O FUNDO         NaN   \n",
      "9          NaN          X              SEM PERMISSÃO PARA RECURSO         NaN   \n",
      "10         NaN          X                           Sem Permissão         NaN   \n",
      "11         NaN         OK  FUNCIONOU, MAS DEVERIA TER FUNCIONADO?         NaN   \n",
      "12         NaN        NaN            obs: contém cnpjs dos fundos         NaN   \n",
      "13         NaN        NaN                                     NaN         NaN   \n",
      "14         NaN        NaN                                     NaN         NaN   \n",
      "15         NaN        NaN                                     NaN         NaN   \n",
      "16         NaN        NaN                                     NaN         NaN   \n",
      "17         NaN        NaN                                     NaN         NaN   \n",
      "\n",
      "    Unnamed: 8  Unnamed: 9  ...  Unnamed: 12  Unnamed: 13  Unnamed: 14  \\\n",
      "0          NaN         NaN  ...          NaN          NaN          NaN   \n",
      "1          NaN         NaN  ...          NaN          NaN          NaN   \n",
      "2          NaN         NaN  ...          NaN          NaN            -   \n",
      "3          NaN         NaN  ...          NaN          NaN            X   \n",
      "4          NaN         NaN  ...          NaN          NaN          NaN   \n",
      "5          NaN         NaN  ...          NaN          NaN           OK   \n",
      "6          NaN         NaN  ...          NaN          NaN          NaN   \n",
      "7          NaN         NaN  ...          NaN          NaN          NaN   \n",
      "8          NaN         NaN  ...          NaN          NaN          NaN   \n",
      "9          NaN         NaN  ...          NaN          NaN          NaN   \n",
      "10         NaN         NaN  ...          NaN          NaN          NaN   \n",
      "11         NaN         NaN  ...          NaN          NaN          NaN   \n",
      "12         NaN         NaN  ...          NaN          NaN          NaN   \n",
      "13         NaN         NaN  ...          NaN          NaN          NaN   \n",
      "14         NaN         NaN  ...          NaN          NaN          NaN   \n",
      "15         NaN         NaN  ...          NaN          NaN          NaN   \n",
      "16         NaN         NaN  ...          NaN          NaN          NaN   \n",
      "17         NaN         NaN  ...          NaN          NaN          NaN   \n",
      "\n",
      "    Unnamed: 15 Unnamed: 16 Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
      "0           NaN         NaN         NaN          NaN          NaN   \n",
      "1           NaN         NaN         NaN          NaN          NaN   \n",
      "2           NaN         NaN         NaN          NaN          NaN   \n",
      "3     PERMISSÃO         NaN         NaN          NaN          NaN   \n",
      "4           NaN         NaN         NaN          NaN          NaN   \n",
      "5           NaN         NaN         NaN          NaN          NaN   \n",
      "6           NaN         NaN         NaN          NaN          NaN   \n",
      "7           NaN         NaN         NaN          NaN          NaN   \n",
      "8           NaN         NaN         NaN          NaN          NaN   \n",
      "9           NaN         NaN         NaN          NaN          NaN   \n",
      "10          NaN         NaN         NaN          NaN          NaN   \n",
      "11          NaN         NaN         NaN          NaN          NaN   \n",
      "12          NaN         NaN         NaN          NaN          NaN   \n",
      "13          NaN         NaN         NaN          NaN          NaN   \n",
      "14          NaN         NaN         NaN          NaN          NaN   \n",
      "15          NaN         NaN         NaN          NaN          NaN   \n",
      "16          NaN         NaN         NaN          NaN          NaN   \n",
      "17          NaN         NaN         NaN          NaN          NaN   \n",
      "\n",
      "    Unnamed: 20           Unnamed: 21  \n",
      "0           NaN                   NaN  \n",
      "1           NaN                   NaN  \n",
      "2             -                   NaN  \n",
      "3             -                   NaN  \n",
      "4             X             hANDSHAKE  \n",
      "5             X             hANDSHAKE  \n",
      "6            OK                   NaN  \n",
      "7             -                   NaN  \n",
      "8            OK                   NaN  \n",
      "9             X             hANDSHAKE  \n",
      "10            -                   NaN  \n",
      "11            X  Sem resposta do site  \n",
      "12            X             Handshake  \n",
      "13            -                   NaN  \n",
      "14          NaN                   NaN  \n",
      "15          NaN                   NaN  \n",
      "16          NaN                   NaN  \n",
      "17          NaN                   NaN  \n",
      "\n",
      "[18 rows x 22 columns]\n",
      "----------------------------------------------\n",
      "\n",
      "--- Inspecionando: documentos_52203615000119.json ---\n",
      "Formato: JSON\n",
      "Tipo: Lista de objetos\n",
      "Chaves do primeiro objeto da lista: ['nivel', 'nomeNivel', 'cnpjOuCodCVM', 'tipoDocumento', 'nomeDocumento', 'url']\n",
      "----------------------------------------------------\n",
      "\n",
      "--- Inspecionando: 78417127.xml ---\n",
      "Formato: XML\n",
      "Elemento raiz (root): <Remessa>\n",
      "Primeiros 5 elementos filhos:\n",
      "  - <Identificacao>\n",
      "  - <DataGeracao>\n",
      "  - <Fundo>\n",
      "  - <CNPJCustodiante>\n",
      "  - <Instrucoes>\n",
      "----------------------------------\n",
      "\n",
      "--- Inspecionando: movimentacao_cotistas_52203615000119_2025-08-20_completo.json ---\n",
      "Formato: JSON\n",
      "Tipo: Lista de objetos\n",
      "Chaves do primeiro objeto da lista: ['cnpjFundo', 'movimentacaoCotista', 'total']\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "--- Inspecionando: extrato_52203615000119_2025-08-01_a_2025-08-31_completo.json ---\n",
      "Formato: JSON\n",
      "Tipo: Dicionário (Objeto JSON)\n",
      "Chaves do JSON (nível raiz): ['cnpjFundo', 'dataInicial', 'dataFinal', 'saldoInicial', 'saldoFinal', 'dadosBancariosFundo', 'lancamentos']\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "--- Fim da inspeção ---\n"
     ]
    }
   ],
   "source": [
    "# inspecionando todos os arquivos: \n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "# Lista de caminhos dos arquivos que você forneceu\n",
    "# Use 'r' antes das aspas para garantir que o caminho seja lido corretamente pelo Python\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\Leo\\Downloads\\carteira_52203615000119_20250901.json\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\130170-Demonstrativo_Caixa.xlsx\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\130166-Carteira.xlsx\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\remessas_2025-09-01_completo.json\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\remessas_2025-09-01_detalhes_status.csv\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\remessas_2025-09-01_lista.csv\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\atualizacao_acessos.xlsx\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\documentos_52203615000119.json\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\78417127.xml\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\movimentacao_cotistas_52203615000119_2025-08-20_completo.json\",\n",
    "    r\"C:\\Users\\Leo\\Downloads\\extrato_52203615000119_2025-08-01_a_2025-08-31_completo.json\"\n",
    "]\n",
    "\n",
    "def inspect_file(path):\n",
    "    \"\"\"\n",
    "    Função para inspecionar um arquivo, identificando seu tipo e mostrando\n",
    "    uma prévia do seu conteúdo.\n",
    "    \"\"\"\n",
    "    # Pega apenas o nome do arquivo para exibição\n",
    "    filename = os.path.basename(path)\n",
    "    print(f\"--- Inspecionando: {filename} ---\")\n",
    "    \n",
    "    # Verifica se o arquivo realmente existe no caminho especificado\n",
    "    if not os.path.exists(path):\n",
    "        print(\"!!! ERRO: Arquivo não encontrado. Verifique o caminho. !!!\\n\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Lógica para arquivos .csv\n",
    "        if path.endswith('.csv'):\n",
    "            df = pd.read_csv(path, encoding='utf-8', sep=None, engine='python', nrows=5)\n",
    "            print(\"Formato: CSV\")\n",
    "            print(\"Colunas detectadas:\", df.columns.tolist())\n",
    "            print(\"Prévia das 5 primeiras linhas:\")\n",
    "            print(df.head(5))\n",
    "\n",
    "        # Lógica para arquivos .xlsx\n",
    "        elif path.endswith('.xlsx'):\n",
    "            xls = pd.ExcelFile(path)\n",
    "            print(f\"Formato: Excel com {len(xls.sheet_names)} aba(s): {xls.sheet_names}\")\n",
    "            # Mostra o início de cada aba (planilha)\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                print(f\"\\n... Lendo aba: '{sheet_name}' ...\")\n",
    "                df = pd.read_excel(path, sheet_name=sheet_name, nrows=60)\n",
    "                print(\"Colunas detectadas:\", df.columns.tolist())\n",
    "                print(\"Prévia das 60 primeiras linhas:\")\n",
    "                print(df.head(60))\n",
    "\n",
    "        # Lógica para arquivos .json\n",
    "        elif path.endswith('.json'):\n",
    "            print(\"Formato: JSON\")\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, dict):\n",
    "                    print(\"Tipo: Dicionário (Objeto JSON)\")\n",
    "                    print(\"Chaves do JSON (nível raiz):\", list(data.keys()))\n",
    "                elif isinstance(data, list) and data:\n",
    "                    print(\"Tipo: Lista de objetos\")\n",
    "                    if isinstance(data[0], dict):\n",
    "                        print(\"Chaves do primeiro objeto da lista:\", list(data[0].keys()))\n",
    "                else:\n",
    "                    print(\"Conteúdo do JSON não é um dicionário ou lista de objetos.\")\n",
    "\n",
    "        # Lógica para arquivos .xml\n",
    "        elif path.endswith('.xml'):\n",
    "            print(\"Formato: XML\")\n",
    "            tree = ET.parse(path)\n",
    "            root = tree.getroot()\n",
    "            print(f\"Elemento raiz (root): <{root.tag}>\")\n",
    "            print(\"Primeiros 5 elementos filhos:\")\n",
    "            for i, child in enumerate(root):\n",
    "                if i >= 5:\n",
    "                    break\n",
    "                print(f\"  - <{child.tag}>\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Formato de arquivo não suportado para inspeção automática: {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! ERRO ao processar o arquivo: {e} !!!\")\n",
    "    \n",
    "    # Linha para separar a inspeção de cada arquivo\n",
    "    print(\"-\" * (len(filename) + 22) + \"\\n\")\n",
    "\n",
    "\n",
    "# Roda a função de inspeção para cada arquivo da lista\n",
    "for file_path in file_paths:\n",
    "    inspect_file(file_path)\n",
    "\n",
    "print(\"--- Fim da inspeção ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5baf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Projeção de Fluxo de Caixa ---\n",
      "                      Prazo        Data   Saldo Projetado\n",
      "0                       D+0  01/09/2025       R$ 5,292.37\n",
      "1                       D+1  02/09/2025   R$ 1,183,417.67\n",
      "2                       D+5  06/09/2025   R$ 1,183,417.67\n",
      "3                      D+10  11/09/2025   R$ 1,183,417.67\n",
      "4                      D+21  22/09/2025   R$ 1,183,417.67\n",
      "5                      D+63  03/11/2025  R$ -3,254,323.10\n",
      "6    1ª Amort. (16/01/2026)  16/01/2026  R$ -6,367,646.81\n",
      "7  Últ. Amort. (11/01/2029)  11/01/2029  R$ -3,259,933.78\n",
      "\n",
      "--- Avisos Importantes ---\n",
      "1. Pagamento de Despesas: As datas foram inferidas. É necessário confirmar as datas reais de vencimento.\n",
      "2. Pagamento de Estoque (Direitos Creditórios): O valor total de R$ 214M a receber NÃO foi incluído na projeção por falta de datas de vencimento no arquivo JSON.\n",
      "3. Resgate de Fundos: Assumiu-se um prazo de resgate de D+1 para os fundos de cotas.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    \"\"\"Carrega os dados da carteira a partir de um arquivo JSON.\"\"\"\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        # O JSON é uma lista com um único objeto principal\n",
    "        dados = json.load(f)[0]\n",
    "    return dados\n",
    "\n",
    "def extrair_fluxos_de_caixa(dados):\n",
    "    \"\"\"Extrai e organiza todos os eventos de fluxo de caixa do JSON.\"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # 1. Disponibilidades (Entradas)\n",
    "    # Conta Corrente (D+0)\n",
    "    disponibilidade = next((ativo['Disponibilidade'] for ativo in dados['ativos'] if 'Disponibilidade' in ativo and ativo['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        saldo_cc = disponibilidade['ativos'][0]['saldo']\n",
    "        fluxos.append({'data': data_base, 'descricao': 'Conta Corrente (Saldo Inicial)', 'valor': saldo_cc, 'tipo': 'Disponibilidade'})\n",
    "\n",
    "    # Fundos Investidos (Cotas - Assumindo resgate em D+1)\n",
    "    cotas = next((ativo['Cotas'] for ativo in dados['ativos'] if 'Cotas' in ativo and ativo['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base + timedelta(days=1), 'descricao': f\"Resgate Fundo '{cota['titulo']}'\", 'valor': cota['valorBruto'], 'tipo': 'Disponibilidade'})\n",
    "            \n",
    "    # Títulos de Renda Fixa\n",
    "    renda_fixa = next((ativo['RendaFixa'] for ativo in dados['ativos'] if 'RendaFixa' in ativo and ativo['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            data_vencimento = datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d')\n",
    "            fluxos.append({'data': data_vencimento, 'descricao': f\"Venc. RF '{titulo['codigoCustodia']}'\", 'valor': titulo['mercadoAtual'], 'tipo': 'Disponibilidade'})\n",
    "    \n",
    "    # ATENÇÃO: Pagamentos do Estoque (Direitos Creditórios) - SEM DATA NO JSON\n",
    "    # Esta seção precisaria ser implementada quando a data de vencimento dos direitos creditórios for conhecida.\n",
    "    # Ex: fluxos.append({'data': data_venc_dc, 'descricao': 'Recebimento Estoque', 'valor': valor_dc, 'tipo': 'Disponibilidade'})\n",
    "\n",
    "\n",
    "    # 2. Necessidades (Saídas)\n",
    "    # Despesas (Provisões)\n",
    "    passivos = dados.get('passivos', [])\n",
    "    if passivos:\n",
    "        for despesa in passivos[0].get('ativos', []):\n",
    "            # Lógica simples para tentar inferir a data. Isso deve ser validado.\n",
    "            # Se não encontrar data, assume pagamento para o mês seguinte.\n",
    "            data_pagamento = data_base + timedelta(days=30)\n",
    "            if 'DEZ25' in despesa['despesa']:\n",
    "                data_pagamento = datetime(2025, 12, 15) # Exemplo\n",
    "            \n",
    "            fluxos.append({'data': data_pagamento, 'descricao': f\"Despesa: {despesa['despesa']}\", 'valor': despesa['valor'], 'tipo': 'Necessidade'})\n",
    "\n",
    "    # Amortização de Cotas (Série Sênior)\n",
    "    carteira_senior = next((c for c in dados['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1 # Valor negativo para saída\n",
    "        \n",
    "        # Gera 36 pagamentos mensais a partir de Jan/2026\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            # Regra: Se fim de semana, vai para o próximo dia útil\n",
    "            while data_amortizacao.weekday() >= 5: # 5=Sábado, 6=Domingo\n",
    "                data_amortizacao += timedelta(days=1)\n",
    "            \n",
    "            fluxos.append({'data': data_amortizacao, 'descricao': f\"Amortização Cota Sênior ({i+1}/36)\", 'valor': valor_amortizacao, 'tipo': 'Necessidade'})\n",
    "            \n",
    "            # Próximo mês\n",
    "            ano = data_amortizacao.year\n",
    "            mes = data_amortizacao.month + 1\n",
    "            if mes > 12:\n",
    "                mes = 1\n",
    "                ano += 1\n",
    "            data_amortizacao = data_amortizacao.replace(year=ano, month=mes)\n",
    "\n",
    "    return fluxos\n",
    "\n",
    "def criar_tabela_projecao(fluxos, data_base):\n",
    "    \"\"\"Cria a tabela final de projeção de fluxo de caixa.\"\"\"\n",
    "    if not fluxos:\n",
    "        print(\"Nenhum fluxo de caixa foi extraído.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(fluxos)\n",
    "    df_fluxo_diario = df.groupby('data')['valor'].sum().reset_index()\n",
    "    \n",
    "    # Cria um range de datas do início ao fim para garantir que todos os dias sejam considerados\n",
    "    idx = pd.date_range(start=data_base, end=df_fluxo_diario['data'].max())\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data').reindex(idx, fill_value=0).reset_index().rename(columns={'index':'data'})\n",
    "    \n",
    "    df_fluxo_diario['saldo_projetado'] = df_fluxo_diario['valor'].cumsum()\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data')\n",
    "\n",
    "    # Define os prazos para a tabela final\n",
    "    prazos_dias = {'D+0': 0, 'D+1': 1, 'D+5': 5, 'D+10': 10, 'D+21': 21, 'D+63': 63}\n",
    "    \n",
    "    # Adiciona datas de amortização para visualização\n",
    "    datas_amortizacao = sorted([f['data'] for f in fluxos if 'Amortização' in f['descricao']])\n",
    "    if datas_amortizacao:\n",
    "        prazos_dias[f\"1ª Amort. ({datas_amortizacao[0].strftime('%d/%m/%Y')})\"] = (datas_amortizacao[0] - data_base).days\n",
    "        prazos_dias[f\"Últ. Amort. ({datas_amortizacao[-1].strftime('%d/%m/%Y')})\"] = (datas_amortizacao[-1] - data_base).days\n",
    "\n",
    "    projecao = []\n",
    "    for nome_prazo, dias in prazos_dias.items():\n",
    "        data_projecao = data_base + timedelta(days=dias)\n",
    "        saldo = df_fluxo_diario.asof(data_projecao)['saldo_projetado']\n",
    "        projecao.append({'Prazo': nome_prazo, 'Data': data_projecao.strftime('%d/%m/%Y'), 'Saldo Projetado': f\"R$ {saldo:,.2f}\"})\n",
    "\n",
    "    return pd.DataFrame(projecao)\n",
    "\n",
    "\n",
    "# --- Execução Principal ---\n",
    "caminho_json = \"C:\\\\Users\\\\Leo\\\\Downloads\\\\carteira_52203615000119_20250901.json\"\n",
    "dados_carteira = carregar_dados_carteira(caminho_json)\n",
    "lista_fluxos = extrair_fluxos_de_caixa(dados_carteira)\n",
    "\n",
    "data_referencia = datetime.strptime(dados_carteira['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "tabela_final = criar_tabela_projecao(lista_fluxos, data_referencia)\n",
    "\n",
    "print(\"--- Projeção de Fluxo de Caixa ---\")\n",
    "print(tabela_final.to_string())\n",
    "print(\"\\n--- Avisos Importantes ---\")\n",
    "print(\"1. Pagamento de Despesas: As datas foram inferidas. É necessário confirmar as datas reais de vencimento.\")\n",
    "print(\"2. Pagamento de Estoque (Direitos Creditórios): O valor total de R$ 214M a receber NÃO foi incluído na projeção por falta de datas de vencimento no arquivo JSON.\")\n",
    "print(\"3. Resgate de Fundos: Assumiu-se um prazo de resgate de D+1 para os fundos de cotas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bad141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Projeção de Fluxo de Caixa ---\n",
      "                      Prazo        Data   Saldo Projetado\n",
      "0                       D+0  01/09/2025       R$ 5,292.37\n",
      "1                       D+1  02/09/2025   R$ 1,183,417.67\n",
      "2                       D+5  06/09/2025   R$ 1,183,417.67\n",
      "3                      D+10  11/09/2025   R$ 1,183,417.67\n",
      "4                      D+21  22/09/2025   R$ 1,183,417.67\n",
      "5                      D+63  03/11/2025  R$ -3,254,323.10\n",
      "6    1ª Amort. (16/01/2026)  16/01/2026  R$ -6,367,646.81\n",
      "7  Últ. Amort. (11/01/2029)  11/01/2029  R$ -3,259,933.78\n",
      "\n",
      "--- Avisos Importantes ---\n",
      "1. Pagamento de Despesas: As datas foram inferidas. É necessário confirmar as datas reais de vencimento.\n",
      "2. Pagamento de Estoque (Direitos Creditórios): O valor total de R$ 214M a receber NÃO foi incluído na projeção por falta de datas de vencimento no arquivo JSON.\n",
      "3. Resgate de Fundos: Assumiu-se um prazo de resgate de D+1 para os fundos de cotas.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    \"\"\"Carrega os dados da carteira a partir de um arquivo JSON.\"\"\"\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        # O JSON é uma lista com um único objeto principal\n",
    "        dados = json.load(f)[0]\n",
    "    return dados\n",
    "\n",
    "def extrair_fluxos_de_caixa(dados):\n",
    "    \"\"\"Extrai e organiza todos os eventos de fluxo de caixa do JSON.\"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # 1. Disponibilidades (Entradas)\n",
    "    # Conta Corrente (D+0)\n",
    "    disponibilidade = next((ativo['Disponibilidade'] for ativo in dados['ativos'] if 'Disponibilidade' in ativo and ativo['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        saldo_cc = disponibilidade['ativos'][0]['saldo']\n",
    "        fluxos.append({'data': data_base, 'descricao': 'Conta Corrente (Saldo Inicial)', 'valor': saldo_cc, 'tipo': 'Disponibilidade'})\n",
    "\n",
    "    # Fundos Investidos (Cotas - Assumindo resgate em D+1)\n",
    "    cotas = next((ativo['Cotas'] for ativo in dados['ativos'] if 'Cotas' in ativo and ativo['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base + timedelta(days=1), 'descricao': f\"Resgate Fundo '{cota['titulo']}'\", 'valor': cota['valorBruto'], 'tipo': 'Disponibilidade'})\n",
    "            \n",
    "    # Títulos de Renda Fixa\n",
    "    renda_fixa = next((ativo['RendaFixa'] for ativo in dados['ativos'] if 'RendaFixa' in ativo and ativo['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            data_vencimento = datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d')\n",
    "            fluxos.append({'data': data_vencimento, 'descricao': f\"Venc. RF '{titulo['codigoCustodia']}'\", 'valor': titulo['mercadoAtual'], 'tipo': 'Disponibilidade'})\n",
    "    \n",
    "    # ATENÇÃO: Pagamentos do Estoque (Direitos Creditórios) - SEM DATA NO JSON\n",
    "    # Esta seção precisaria ser implementada quando a data de vencimento dos direitos creditórios for conhecida.\n",
    "    # Ex: fluxos.append({'data': data_venc_dc, 'descricao': 'Recebimento Estoque', 'valor': valor_dc, 'tipo': 'Disponibilidade'})\n",
    "\n",
    "\n",
    "    # 2. Necessidades (Saídas)\n",
    "    # Despesas (Provisões)\n",
    "    passivos = dados.get('passivos', [])\n",
    "    if passivos:\n",
    "        for despesa in passivos[0].get('ativos', []):\n",
    "            # Lógica simples para tentar inferir a data. Isso deve ser validado.\n",
    "            # Se não encontrar data, assume pagamento para o mês seguinte.\n",
    "            data_pagamento = data_base + timedelta(days=30)\n",
    "            if 'DEZ25' in despesa['despesa']:\n",
    "                data_pagamento = datetime(2025, 12, 15) # Exemplo\n",
    "            \n",
    "            fluxos.append({'data': data_pagamento, 'descricao': f\"Despesa: {despesa['despesa']}\", 'valor': despesa['valor'], 'tipo': 'Necessidade'})\n",
    "\n",
    "    # Amortização de Cotas (Série Sênior)\n",
    "    carteira_senior = next((c for c in dados['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1 # Valor negativo para saída\n",
    "        \n",
    "        # Gera 36 pagamentos mensais a partir de Jan/2026\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            # Regra: Se fim de semana, vai para o próximo dia útil\n",
    "            while data_amortizacao.weekday() >= 5: # 5=Sábado, 6=Domingo\n",
    "                data_amortizacao += timedelta(days=1)\n",
    "            \n",
    "            fluxos.append({'data': data_amortizacao, 'descricao': f\"Amortização Cota Sênior ({i+1}/36)\", 'valor': valor_amortizacao, 'tipo': 'Necessidade'})\n",
    "            \n",
    "            # Próximo mês\n",
    "            ano = data_amortizacao.year\n",
    "            mes = data_amortizacao.month + 1\n",
    "            if mes > 12:\n",
    "                mes = 1\n",
    "                ano += 1\n",
    "            data_amortizacao = data_amortizacao.replace(year=ano, month=mes)\n",
    "\n",
    "    return fluxos\n",
    "\n",
    "def criar_tabela_projecao(fluxos, data_base):\n",
    "    \"\"\"Cria a tabela final de projeção de fluxo de caixa.\"\"\"\n",
    "    if not fluxos:\n",
    "        print(\"Nenhum fluxo de caixa foi extraído.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(fluxos)\n",
    "    df_fluxo_diario = df.groupby('data')['valor'].sum().reset_index()\n",
    "    \n",
    "    # Cria um range de datas do início ao fim para garantir que todos os dias sejam considerados\n",
    "    idx = pd.date_range(start=data_base, end=df_fluxo_diario['data'].max())\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data').reindex(idx, fill_value=0).reset_index().rename(columns={'index':'data'})\n",
    "    \n",
    "    df_fluxo_diario['saldo_projetado'] = df_fluxo_diario['valor'].cumsum()\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data')\n",
    "\n",
    "    # Define os prazos para a tabela final\n",
    "    prazos_dias = {'D+0': 0, 'D+1': 1, 'D+5': 5, 'D+10': 10, 'D+21': 21, 'D+63': 63}\n",
    "    \n",
    "    # Adiciona datas de amortização para visualização\n",
    "    datas_amortizacao = sorted([f['data'] for f in fluxos if 'Amortização' in f['descricao']])\n",
    "    if datas_amortizacao:\n",
    "        prazos_dias[f\"1ª Amort. ({datas_amortizacao[0].strftime('%d/%m/%Y')})\"] = (datas_amortizacao[0] - data_base).days\n",
    "        prazos_dias[f\"Últ. Amort. ({datas_amortizacao[-1].strftime('%d/%m/%Y')})\"] = (datas_amortizacao[-1] - data_base).days\n",
    "\n",
    "    projecao = []\n",
    "    for nome_prazo, dias in prazos_dias.items():\n",
    "        data_projecao = data_base + timedelta(days=dias)\n",
    "        saldo = df_fluxo_diario.asof(data_projecao)['saldo_projetado']\n",
    "        projecao.append({'Prazo': nome_prazo, 'Data': data_projecao.strftime('%d/%m/%Y'), 'Saldo Projetado': f\"R$ {saldo:,.2f}\"})\n",
    "\n",
    "    return pd.DataFrame(projecao)\n",
    "\n",
    "\n",
    "# --- Execução Principal ---\n",
    "caminho_json = \"C:\\\\Users\\\\Leo\\\\Downloads\\\\carteira_52203615000119_20250901.json\"\n",
    "dados_carteira = carregar_dados_carteira(caminho_json)\n",
    "lista_fluxos = extrair_fluxos_de_caixa(dados_carteira)\n",
    "\n",
    "data_referencia = datetime.strptime(dados_carteira['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "tabela_final = criar_tabela_projecao(lista_fluxos, data_referencia)\n",
    "\n",
    "print(\"--- Projeção de Fluxo de Caixa ---\")\n",
    "print(tabela_final.to_string())\n",
    "print(\"\\n--- Avisos Importantes ---\")\n",
    "print(\"1. Pagamento de Despesas: As datas foram inferidas. É necessário confirmar as datas reais de vencimento.\")\n",
    "print(\"2. Pagamento de Estoque (Direitos Creditórios): O valor total de R$ 214M a receber NÃO foi incluído na projeção por falta de datas de vencimento no arquivo JSON.\")\n",
    "print(\"3. Resgate de Fundos: Assumiu-se um prazo de resgate de D+1 para os fundos de cotas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19320e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando dados de estoque...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_26824\\779620343.py:37: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_26824\\779620343.py:37: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de estoque consolidados com sucesso.\n",
      "\n",
      "--- INICIANDO ANÁLISE DO ESTOQUE CONSOLIDADO ---\n",
      "\n",
      "[1] Formato do DataFrame: 1644304 linhas e 33 colunas.\n",
      "\n",
      "[2] Colunas encontradas:\n",
      "['CCB', 'SEU NUMERO', 'PARCELA', 'Nome Cliente', 'CPF Cliente', 'FIDC', 'Cedente', 'Data Aquisicao', 'Data Vencimento', 'Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido', 'PDD Total', 'Pagamento Parcial', 'Data Referencia', 'Prazo', 'Convênio Formatado', 'Produto', 'Promotora', 'Tipo do Contrato', 'Originador', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB', 'Taxa Originador Split', 'Taxa Split FIDC', 'Data de Nascimento', 'UF', 'CAPAG', 'Status', 'Faixa Vencido', 'Nota PDD']\n",
      "\n",
      "[3] Tipos de dados (info):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1644304 entries, 0 to 1644303\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count    Dtype         \n",
      "---  ------                   --------------    -----         \n",
      " 0   CCB                      1644304 non-null  int64         \n",
      " 1   SEU NUMERO               1644304 non-null  int64         \n",
      " 2   PARCELA                  1644304 non-null  int64         \n",
      " 3   Nome Cliente             1644304 non-null  object        \n",
      " 4   CPF Cliente              1644304 non-null  object        \n",
      " 5   FIDC                     1644304 non-null  object        \n",
      " 6   Cedente                  1644304 non-null  object        \n",
      " 7   Data Aquisicao           1272462 non-null  datetime64[ns]\n",
      " 8   Data Vencimento          735405 non-null   datetime64[ns]\n",
      " 9   Valor Aquisicao          1644304 non-null  float64       \n",
      " 10  Valor Nominal            1644304 non-null  float64       \n",
      " 11  Valor Presente           1644304 non-null  float64       \n",
      " 12  PDD Vencido              1644304 non-null  float64       \n",
      " 13  PDD Total                1644304 non-null  float64       \n",
      " 14  Pagamento Parcial        1644304 non-null  object        \n",
      " 15  Data Referencia          1644304 non-null  datetime64[ns]\n",
      " 16  Prazo                    1640006 non-null  float64       \n",
      " 17  Convênio Formatado       1640006 non-null  object        \n",
      " 18  Produto                  1640006 non-null  object        \n",
      " 19  Promotora                1640006 non-null  object        \n",
      " 20  Tipo do Contrato         1076259 non-null  object        \n",
      " 21  Originador               1640006 non-null  object        \n",
      " 22  Taxa Operada Originador  1640006 non-null  float64       \n",
      " 23  CET Mensal               1640006 non-null  float64       \n",
      " 24  Taxa CCB                 1640006 non-null  float64       \n",
      " 25  Taxa Originador Split    1640006 non-null  float64       \n",
      " 26  Taxa Split FIDC          1640006 non-null  float64       \n",
      " 27  Data de Nascimento       1076259 non-null  datetime64[ns]\n",
      " 28  UF                       1640006 non-null  object        \n",
      " 29  CAPAG                    1630934 non-null  object        \n",
      " 30  Status                   1644304 non-null  object        \n",
      " 31  Faixa Vencido            74416 non-null    object        \n",
      " 32  Nota PDD                 1644304 non-null  object        \n",
      "dtypes: datetime64[ns](4), float64(11), int64(3), object(15)\n",
      "memory usage: 414.0+ MB\n",
      "\n",
      "[4] Amostra das 5 primeiras linhas:\n",
      "        CCB  SEU NUMERO  PARCELA                  Nome Cliente  \\\n",
      "0  31559331  3155933139       39  CARLOS MAGNO OLIVEIRA ARAUJO   \n",
      "1  31559331  3155933129       29  CARLOS MAGNO OLIVEIRA ARAUJO   \n",
      "2  31569369  3156936967       67   RILDO AMAURI MARTINS LOBATO   \n",
      "3  31563855  3156385523       23   PAULO ROBERTO SILVA PEREIRA   \n",
      "4  31563855  3156385528       28   PAULO ROBERTO SILVA PEREIRA   \n",
      "\n",
      "      CPF Cliente FIDC                                         Cedente  \\\n",
      "0  504.105.391-04  FCT  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A   \n",
      "1  504.105.391-04  FCT  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A   \n",
      "2  775.326.783-34  FCT  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A   \n",
      "3  602.655.033-02  FCT  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A   \n",
      "4  602.655.033-02  FCT  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A   \n",
      "\n",
      "  Data Aquisicao Data Vencimento  Valor Aquisicao  ...  CET Mensal  Taxa CCB  \\\n",
      "0     2024-01-18      2027-04-05           301.90  ...        2.23       2.1   \n",
      "1     2024-01-18      2026-04-07           359.44  ...        2.23       2.1   \n",
      "2     2024-01-18      2029-04-09           220.20  ...        2.20       2.1   \n",
      "3     2024-01-18      2026-04-01            84.93  ...        2.45       2.3   \n",
      "4     2024-01-18      2026-04-06            77.40  ...        2.45       2.3   \n",
      "\n",
      "   Taxa Originador Split  Taxa Split FIDC Data de Nascimento  UF  CAPAG  \\\n",
      "0                    2.7              0.0         1968-11-27  MA      B   \n",
      "1                    2.7              0.0         1968-11-27  MA      B   \n",
      "2                    2.7              0.0         1976-03-13  MA      B   \n",
      "3                    2.7              0.0         1984-09-06  MA      C   \n",
      "4                    2.7              0.0         1984-09-06  MA      C   \n",
      "\n",
      "     Status Faixa Vencido Nota PDD  \n",
      "0  A vencer           NaN        H  \n",
      "1  A vencer           NaN        H  \n",
      "2  A vencer           NaN        H  \n",
      "3  A vencer           NaN        B  \n",
      "4  A vencer           NaN        B  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "\n",
      "[5] Análise das colunas-chave para a projeção:\n",
      "\n",
      "  - Análise da coluna 'Data Vencimento':\n",
      "    - Primeira data de vencimento: 04/02/2024\n",
      "    - Última data de vencimento: 08/11/2033\n",
      "\n",
      "  - Análise estatística da coluna 'Valor Presente':\n",
      "count    1,644,304.00\n",
      "mean           130.84\n",
      "std            158.76\n",
      "min              0.18\n",
      "25%             33.22\n",
      "50%             77.68\n",
      "75%            167.97\n",
      "max          3,843.40\n",
      "Name: Valor Presente, dtype: object\n",
      "\n",
      "--- FIM DA ANÁLISE ---\n"
     ]
    }
   ],
   "source": [
    "# depurar dentro do estoque:\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- Sua função para processar o estoque ---\n",
    "# Colocamos ela aqui para ser usada pelo nosso script de depuração.\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    \"\"\"Lê e consolida os arquivos de estoque de uma pasta.\"\"\"\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv:\n",
    "        print(f\"AVISO: Nenhum arquivo CSV de estoque encontrado em {caminho_pasta}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    float_cols = [\n",
    "        'Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido',\n",
    "        'PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB',\n",
    "        'Taxa Originador Split', 'Taxa Split FIDC'\n",
    "    ]\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            # Sua função original para ler os arquivos de estoque\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns:\n",
    "                        df[col] = df[col].astype(str).str.replace(',', '.').astype(float)\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns:\n",
    "                        df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"Nenhum dado de estoque foi carregado com sucesso.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "# --- Bloco de Inspeção e Depuração ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Executa a sua função para carregar os dados\n",
    "    df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "\n",
    "    # 2. Inicia a análise se os dados foram carregados\n",
    "    if not df_estoque.empty:\n",
    "        print(\"\\n--- INICIANDO ANÁLISE DO ESTOQUE CONSOLIDADO ---\")\n",
    "\n",
    "        # Análise 1: Dimensões do DataFrame\n",
    "        print(f\"\\n[1] Formato do DataFrame: {df_estoque.shape[0]} linhas e {df_estoque.shape[1]} colunas.\")\n",
    "\n",
    "        # Análise 2: Lista de colunas\n",
    "        print(\"\\n[2] Colunas encontradas:\")\n",
    "        print(df_estoque.columns.tolist())\n",
    "\n",
    "        # Análise 3: Tipos de dados (para verificar se as conversões funcionaram)\n",
    "        print(\"\\n[3] Tipos de dados (info):\")\n",
    "        df_estoque.info()\n",
    "\n",
    "        # Análise 4: Amostra dos dados\n",
    "        print(\"\\n[4] Amostra das 5 primeiras linhas:\")\n",
    "        print(df_estoque.head())\n",
    "\n",
    "        # Análise 5: Foco nas colunas-chave para o fluxo de caixa\n",
    "        print(\"\\n[5] Análise das colunas-chave para a projeção:\")\n",
    "        \n",
    "        # Verifica se as colunas essenciais existem\n",
    "        coluna_data = 'Data Vencimento'\n",
    "        coluna_valor = 'Valor Presente' # Vamos usar o Valor Presente como referência inicial\n",
    "\n",
    "        if coluna_data in df_estoque.columns:\n",
    "            print(f\"\\n  - Análise da coluna '{coluna_data}':\")\n",
    "            # Remove valores nulos para análise de datas\n",
    "            datas_validas = df_estoque[coluna_data].dropna()\n",
    "            if not datas_validas.empty:\n",
    "                print(f\"    - Primeira data de vencimento: {datas_validas.min().strftime('%d/%m/%Y')}\")\n",
    "                print(f\"    - Última data de vencimento: {datas_validas.max().strftime('%d/%m/%Y')}\")\n",
    "            else:\n",
    "                print(\"    - Nenhuma data de vencimento válida encontrada.\")\n",
    "        else:\n",
    "            print(f\"\\n  - ATENÇÃO: Coluna '{coluna_data}' não encontrada!\")\n",
    "\n",
    "        if coluna_valor in df_estoque.columns:\n",
    "            print(f\"\\n  - Análise estatística da coluna '{coluna_valor}':\")\n",
    "            print(df_estoque[coluna_valor].describe().apply(\"{:,.2f}\".format))\n",
    "        else:\n",
    "            print(f\"\\n  - ATENÇÃO: Coluna '{coluna_valor}' não encontrada!\")\n",
    "\n",
    "        print(\"\\n--- FIM DA ANÁLISE ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ebb778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando dados de estoque...\n",
      "Dados de estoque consolidados com sucesso.\n",
      "Processando e adicionando fluxos do estoque...\n",
      "2422 dias com recebimentos do estoque foram adicionados à projeção.\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (COM ESTOQUE) ---\n",
      "       Prazo        Data   Saldo Projetado\n",
      "0        D+0  01/09/2025       R$ 5,292.37\n",
      "1        D+1  02/09/2025   R$ 1,183,417.67\n",
      "2       D+30  01/10/2025  R$ -3,254,323.10\n",
      "3       D+90  30/11/2025   R$ 7,420,859.95\n",
      "4      D+180  28/02/2026  R$ 20,420,395.53\n",
      "5      D+365  01/09/2026  R$ 35,699,359.88\n",
      "6  1ª Amort.  16/01/2026  R$ 14,070,295.29\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO DE DADOS ---\n",
    "\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    \"\"\"Carrega os dados da carteira a partir de um arquivo JSON.\"\"\"\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        dados = json.load(f)[0]\n",
    "    return dados\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    \"\"\"Lê e consolida os arquivos de estoque de uma pasta (sua função).\"\"\"\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv:\n",
    "        print(f\"AVISO: Nenhum arquivo CSV de estoque encontrado em {caminho_pasta}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    # ... (O restante da sua função continua aqui, exatamente como antes)\n",
    "    float_cols = [\n",
    "        'Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido',\n",
    "        'PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB',\n",
    "        'Taxa Originador Split', 'Taxa Split FIDC'\n",
    "    ]\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns:\n",
    "                        df[col] = df[col].astype(str).str.replace(',', '.').astype(float)\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns:\n",
    "                        # Adicionando format para ser mais explícito e remover o warning\n",
    "                        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"Nenhum dado de estoque foi carregado com sucesso.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "# --- FUNÇÕES DE PROJEÇÃO ---\n",
    "\n",
    "def extrair_fluxos_de_caixa(dados_carteira, df_estoque):\n",
    "    \"\"\"Extrai e organiza todos os eventos de fluxo de caixa.\"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # 1. Disponibilidades (Entradas) - DA CARTEIRA JSON\n",
    "    # ... (extração da Conta Corrente, Fundos Investidos e Renda Fixa como antes)\n",
    "    disponibilidade = next((ativo['Disponibilidade'] for ativo in dados_carteira['ativos'] if 'Disponibilidade' in ativo and ativo['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        saldo_cc = disponibilidade['ativos'][0]['saldo']\n",
    "        fluxos.append({'data': data_base, 'descricao': 'Conta Corrente (Saldo Inicial)', 'valor': saldo_cc, 'tipo': 'Disponibilidade'})\n",
    "\n",
    "    cotas = next((ativo['Cotas'] for ativo in dados_carteira['ativos'] if 'Cotas' in ativo and ativo['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base + timedelta(days=1), 'descricao': f\"Resgate Fundo '{cota['titulo']}'\", 'valor': cota['valorBruto'], 'tipo': 'Disponibilidade'})\n",
    "            \n",
    "    renda_fixa = next((ativo['RendaFixa'] for ativo in dados_carteira['ativos'] if 'RendaFixa' in ativo and ativo['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            data_vencimento = datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d')\n",
    "            fluxos.append({'data': data_vencimento, 'descricao': f\"Venc. RF '{titulo['codigoCustodia']}'\", 'valor': titulo['mercadoAtual'], 'tipo': 'Disponibilidade'})\n",
    "\n",
    "    # 2. Disponibilidades (Entradas) - DO ESTOQUE\n",
    "    if not df_estoque.empty:\n",
    "        print(\"Processando e adicionando fluxos do estoque...\")\n",
    "        # FILTRAGEM CRÍTICA\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        \n",
    "        # Agrupa por dia para obter o total de recebimentos diários\n",
    "        fluxo_estoque = estoque_valido.groupby('Data Vencimento')['Valor Presente'].sum().reset_index()\n",
    "        \n",
    "        for index, row in fluxo_estoque.iterrows():\n",
    "            fluxos.append({\n",
    "                'data': row['Data Vencimento'],\n",
    "                'descricao': 'Recebimento Estoque',\n",
    "                'valor': row['Valor Presente'],\n",
    "                'tipo': 'Disponibilidade'\n",
    "            })\n",
    "        print(f\"{len(fluxo_estoque)} dias com recebimentos do estoque foram adicionados à projeção.\")\n",
    "\n",
    "    # 3. Necessidades (Saídas) - DA CARTEIRA JSON\n",
    "    # ... (extração das Despesas e Amortização de Cotas como antes)\n",
    "    passivos = dados_carteira.get('passivos', [])\n",
    "    if passivos:\n",
    "        for despesa in passivos[0].get('ativos', []):\n",
    "            data_pagamento = data_base + timedelta(days=30)\n",
    "            if 'DEZ25' in despesa['despesa']:\n",
    "                data_pagamento = datetime(2025, 12, 15)\n",
    "            fluxos.append({'data': data_pagamento, 'descricao': f\"Despesa: {despesa['despesa']}\", 'valor': despesa['valor'], 'tipo': 'Necessidade'})\n",
    "\n",
    "    carteira_senior = next((c for c in dados_carteira['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            while data_amortizacao.weekday() >= 5:\n",
    "                data_amortizacao += timedelta(days=1)\n",
    "            fluxos.append({'data': data_amortizacao, 'descricao': f\"Amortização Cota Sênior ({i+1}/36)\", 'valor': valor_amortizacao, 'tipo': 'Necessidade'})\n",
    "            ano = data_amortizacao.year\n",
    "            mes = data_amortizacao.month + 1\n",
    "            if mes > 12: mes = 1; ano += 1\n",
    "            data_amortizacao = data_amortizacao.replace(year=ano, month=mes)\n",
    "\n",
    "    return fluxos\n",
    "\n",
    "\n",
    "def criar_tabela_projecao(fluxos, data_base):\n",
    "    # ... (Esta função continua a mesma de antes)\n",
    "    if not fluxos:\n",
    "        print(\"Nenhum fluxo de caixa foi extraído.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(fluxos)\n",
    "    df_fluxo_diario = df.groupby('data')['valor'].sum().reset_index()\n",
    "    \n",
    "    # Garantir que a data máxima considera o vencimento mais longo do estoque\n",
    "    data_fim_projecao = df_fluxo_diario['data'].max()\n",
    "    idx = pd.date_range(start=data_base, end=data_fim_projecao)\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data').reindex(idx, fill_value=0).reset_index().rename(columns={'index':'data'})\n",
    "    \n",
    "    df_fluxo_diario['saldo_projetado'] = df_fluxo_diario['valor'].cumsum()\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data')\n",
    "\n",
    "    prazos_dias = {'D+0': 0, 'D+1': 1, 'D+30': 30, 'D+90': 90, 'D+180': 180, 'D+365': 365}\n",
    "    datas_amortizacao = sorted([f['data'] for f in fluxos if 'Amortização' in f['descricao']])\n",
    "    if datas_amortizacao:\n",
    "        prazos_dias[f\"1ª Amort.\"] = (datas_amortizacao[0] - data_base).days\n",
    "    \n",
    "    projecao = []\n",
    "    for nome_prazo, dias in prazos_dias.items():\n",
    "        data_projecao = data_base + timedelta(days=dias)\n",
    "        saldo = df_fluxo_diario.asof(data_projecao)['saldo_projetado'] if data_projecao <= data_fim_projecao else df_fluxo_diario.iloc[-1]['saldo_projetado']\n",
    "        projecao.append({'Prazo': nome_prazo, 'Data': data_projecao.strftime('%d/%m/%Y'), 'Saldo Projetado': f\"R$ {saldo:,.2f}\"})\n",
    "\n",
    "    return pd.DataFrame(projecao)\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "PATH_JSON_CARTEIRA = \"C:\\\\Users\\\\Leo\\\\Downloads\\\\carteira_52203615000119_20250901.json\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "\n",
    "# 1. Carregar todas as fontes de dados\n",
    "dados_carteira = carregar_dados_carteira(PATH_JSON_CARTEIRA)\n",
    "df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "\n",
    "# 2. Extrair e combinar os fluxos de caixa\n",
    "lista_fluxos = extrair_fluxos_de_caixa(dados_carteira, df_estoque)\n",
    "\n",
    "# 3. Gerar a tabela final\n",
    "data_referencia = datetime.strptime(dados_carteira['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "tabela_final = criar_tabela_projecao(lista_fluxos, data_referencia)\n",
    "\n",
    "print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (COM ESTOQUE) ---\")\n",
    "print(tabela_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25dd9c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serão buscadas 12 carteiras, de 2024-09 a 2025-09.\n",
      "Tentando gerar token JWT com o token de acesso que termina em: ...04f559\n",
      ">>> Sucesso! Token JWT temporário gerado.\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-09-01\n",
      "✅ Sucesso! Carteira de 2025-09-01 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250901.json'\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-08-01\n",
      "✅ Sucesso! Carteira de 2025-08-01 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250801.json'\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-07-01\n",
      "✅ Sucesso! Carteira de 2025-07-01 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250701.json'\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-06-01\n",
      "FALHA ao obter dados da carteira para 2025-06-01. Status: 500\n",
      "Não foi possível obter a carteira para 2025-06-01. Continuando...\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-05-01\n",
      "FALHA ao obter dados da carteira para 2025-05-01. Status: 500\n",
      "Não foi possível obter a carteira para 2025-05-01. Continuando...\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-04-01\n",
      "✅ Sucesso! Carteira de 2025-04-01 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250401.json'\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-03-01\n",
      "FALHA ao obter dados da carteira para 2025-03-01. Status: 500\n",
      "Não foi possível obter a carteira para 2025-03-01. Continuando...\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-02-01\n",
      "FALHA ao obter dados da carteira para 2025-02-01. Status: 500\n",
      "Não foi possível obter a carteira para 2025-02-01. Continuando...\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2025-01-01\n",
      "FALHA ao obter dados da carteira para 2025-01-01. Status: 500\n",
      "Não foi possível obter a carteira para 2025-01-01. Continuando...\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2024-12-01\n",
      "FALHA ao obter dados da carteira para 2024-12-01. Status: 500\n",
      "Não foi possível obter a carteira para 2024-12-01. Continuando...\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2024-11-01\n",
      "✅ Sucesso! Carteira de 2024-11-01 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20241101.json'\n",
      "\n",
      "Buscando carteira para 52203615000119 na data 2024-10-01\n",
      "FALHA ao obter dados da carteira para 2024-10-01. Status: 400\n",
      "Não foi possível obter a carteira para 2024-10-01. Continuando...\n",
      "\n",
      "--- Download do histórico concluído ---\n"
     ]
    }
   ],
   "source": [
    "# baixando os json das carteiras: \n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "\n",
    "# --- CONFIGURAÇÕES ---\n",
    "CNPJS_DOS_FUNDOS = [\"52203615000119\"]\n",
    "TOKENS_DE_ACESSO = [\n",
    "    \"96cc2224-0c2f-454f-b785-db8dd204f559\",\n",
    "    \"d1bd877a-8b21-4c29-b005-dd5540d38673\",\n",
    "    \"ad647ac8-188d-4d50-a6ff-6ef2524ac3ca\"\n",
    "]\n",
    "MEU_CPF = \"10142836982\"\n",
    "\n",
    "# Pasta onde os arquivos JSON serão salvos\n",
    "PASTA_SAIDA = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "\n",
    "# --- FIM DAS CONFIGURAÇÕES ---\n",
    "\n",
    "URL_AUTENTICACAO = \"https://apis.vortx.com.br/vxlogin/api/user/AuthUserApi\"\n",
    "URL_BASE_API = \"https://apis.vortx.com.br\"\n",
    "\n",
    "def gerar_token_jwt(token_de_acesso, cpf):\n",
    "    print(f\"Tentando gerar token JWT com o token de acesso que termina em: ...{token_de_acesso[-6:]}\")\n",
    "    payload = {\"token\": token_de_acesso, \"login\": cpf}\n",
    "    try:\n",
    "        response = requests.post(URL_AUTENTICACAO, json=payload, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            jwt_token = response.json().get(\"token\")\n",
    "            if jwt_token:\n",
    "                print(\">>> Sucesso! Token JWT temporário gerado.\")\n",
    "                return jwt_token\n",
    "        print(f\"FALHA na autenticação. Status: {response.status_code}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ERRO DE CONEXÃO ao tentar autenticar: {e}\")\n",
    "        return None\n",
    "\n",
    "def obter_carteira_json(jwt_token, lista_cnpjs, data, pasta_destino):\n",
    "    print(f\"\\nBuscando carteira para {', '.join(lista_cnpjs)} na data {data}\")\n",
    "    url_carteira = f\"{URL_BASE_API}/carteira-liberada/buscarCarteiraJSON\"\n",
    "    headers = {\"Authorization\": f\"Bearer {jwt_token}\"}\n",
    "    params = {\"cnpjFundos[]\": lista_cnpjs, \"dataCarteira\": data}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url_carteira, headers=headers, params=params, timeout=45)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"FALHA ao obter dados da carteira para {data}. Status: {response.status_code}\")\n",
    "            return False\n",
    "\n",
    "        dados_carteira = response.json()\n",
    "        \n",
    "        # Verifica se a resposta não está vazia\n",
    "        if not dados_carteira or not dados_carteira[0].get('carteiras'):\n",
    "            print(f\"AVISO: Dados da carteira para {data} vieram vazios. Pulando.\")\n",
    "            return False\n",
    "\n",
    "        cnpjs_str = \"_\".join(lista_cnpjs)\n",
    "        nome_arquivo = f\"carteira_{cnpjs_str}_{data.replace('-', '')}.json\"\n",
    "        caminho_completo = os.path.join(pasta_destino, nome_arquivo)\n",
    "\n",
    "        with open(caminho_completo, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dados_carteira, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"✅ Sucesso! Carteira de {data} salva em: '{caminho_completo}'\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ERRO DE CONEXÃO ao buscar a carteira de {data}: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Bloco Principal de Execução ---\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(PASTA_SAIDA, exist_ok=True) # Garante que a pasta de destino exista\n",
    "\n",
    "    # Gera a lista de datas (primeiro dia de cada mês, do último ano até hoje)\n",
    "    datas_para_buscar = []\n",
    "    data_fim = date.today()\n",
    "    data_inicio = data_fim - relativedelta(years=1)\n",
    "    \n",
    "    data_corrente = data_fim\n",
    "    while data_corrente >= data_inicio:\n",
    "        # Usamos o primeiro dia do mês para padronizar\n",
    "        datas_para_buscar.append(data_corrente.replace(day=1).strftime(\"%Y-%m-%d\"))\n",
    "        data_corrente -= relativedelta(months=1)\n",
    "    \n",
    "    print(f\"Serão buscadas {len(datas_para_buscar)} carteiras, de {data_inicio.strftime('%Y-%m')} a {data_fim.strftime('%Y-%m')}.\")\n",
    "\n",
    "    jwt_token_gerado = None\n",
    "    # Tenta obter um token JWT válido primeiro\n",
    "    for token_acesso in TOKENS_DE_ACESSO:\n",
    "        jwt_token_gerado = gerar_token_jwt(token_acesso, MEU_CPF)\n",
    "        if jwt_token_gerado:\n",
    "            break\n",
    "    \n",
    "    if not jwt_token_gerado:\n",
    "        print(\"\\n❌ Todas as tentativas de autenticação falharam. Saindo do script.\")\n",
    "        exit()\n",
    "\n",
    "    # Itera sobre as datas e baixa cada carteira\n",
    "    for data_carteira in datas_para_buscar:\n",
    "        sucesso_busca = obter_carteira_json(jwt_token_gerado, CNPJS_DOS_FUNDOS, data_carteira, PASTA_SAIDA)\n",
    "        if not sucesso_busca:\n",
    "            print(f\"Não foi possível obter a carteira para {data_carteira}. Continuando...\")\n",
    "        time.sleep(2) # Pausa de 2 segundos para não sobrecarregar a API\n",
    "\n",
    "    print(\"\\n--- Download do histórico concluído ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee5a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20241101.json\n",
      "\n",
      "Carregando dados de estoque...\n",
      "Dados de estoque consolidados com sucesso.\n",
      "Analisando histórico de despesas...\n",
      "Projetando despesas recorrentes com base na média histórica:\n",
      "categoria\n",
      "AUDIT LASTRO      -8087.224\n",
      "PEND GESTÃO         -49.690\n",
      "PROV ADM         -23292.658\n",
      "PROV GESTÃO      -84061.130\n",
      "TX ESCRT FIX      -2185.912\n",
      "VALID          -3198209.798\n",
      "Name: valor, dtype: float64\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (COM PROJEÇÃO DE DESPESAS HISTÓRICAS) ---\n",
      "   Prazo        Data   Saldo Projetado\n",
      "0    D+0  01/11/2024       R$ 1,000.00\n",
      "1    D+1  02/11/2024  R$ 46,964,837.28\n",
      "2   D+30  01/12/2024  R$ 43,648,950.87\n",
      "3   D+90  30/01/2025  R$ 40,333,064.46\n",
      "4  D+180  30/04/2025  R$ 30,385,405.22\n",
      "5  D+365  01/11/2025  R$ 11,087,341.57\n"
     ]
    }
   ],
   "source": [
    "# tentando projetar para o futuro: \n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS DOS DADOS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (como antes) ---\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        dados = json.load(f)[0]\n",
    "    return dados\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    # ... (função completa que você já tem)\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = df[col].astype(str).str.replace(',', '.').astype(float)\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e: print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- NOVA FUNÇÃO PARA PROJETAR DESPESAS ---\n",
    "def projetar_despesas_futuras(caminho_pasta_historico, data_base):\n",
    "    \"\"\"\n",
    "    Lê o histórico de carteiras, calcula a média de despesas recorrentes\n",
    "    e projeta essas despesas para os próximos 12 meses.\n",
    "    \"\"\"\n",
    "    print(\"Analisando histórico de despesas...\")\n",
    "    arquivos_json = glob.glob(os.path.join(caminho_pasta_historico, \"*.json\"))\n",
    "    historico_despesas = []\n",
    "\n",
    "    for arquivo in arquivos_json:\n",
    "        dados = carregar_dados_carteira(arquivo)\n",
    "        data_arquivo = datetime.strptime(dados['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "        passivos = dados.get('passivos', [])\n",
    "        if passivos and passivos[0].get('ativos'):\n",
    "            for despesa in passivos[0]['ativos']:\n",
    "                historico_despesas.append({\n",
    "                    'data': data_arquivo,\n",
    "                    'categoria': despesa['despesa'],\n",
    "                    'valor': despesa['valor']\n",
    "                })\n",
    "    \n",
    "    if not historico_despesas:\n",
    "        return []\n",
    "\n",
    "    df_despesas = pd.DataFrame(historico_despesas)\n",
    "    \n",
    "    # Identifica despesas recorrentes (ex: que aparecem em mais de 3 meses)\n",
    "    contagem_meses = df_despesas.groupby('categoria')['data'].nunique()\n",
    "    categorias_recorrentes = contagem_meses[contagem_meses > 3].index.tolist()\n",
    "    \n",
    "    # Calcula a média mensal para despesas recorrentes\n",
    "    media_recorrentes = df_despesas[df_despesas['categoria'].isin(categorias_recorrentes)].groupby('categoria')['valor'].mean()\n",
    "    \n",
    "    fluxos_despesas_projetadas = []\n",
    "    print(\"Projetando despesas recorrentes com base na média histórica:\")\n",
    "    print(media_recorrentes)\n",
    "\n",
    "    # Projeta as despesas recorrentes para os próximos 12 meses\n",
    "    for i in range(1, 13):\n",
    "        data_projecao = data_base + relativedelta(months=i)\n",
    "        for categoria, valor_medio in media_recorrentes.items():\n",
    "             fluxos_despesas_projetadas.append({\n",
    "                'data': data_projecao,\n",
    "                'descricao': f\"Projeção Despesa: {categoria}\",\n",
    "                'valor': valor_medio,\n",
    "                'tipo': 'Necessidade'\n",
    "            })\n",
    "            \n",
    "    # Adiciona despesas pontuais (ex: Auditoria) que ainda não ocorreram\n",
    "    despesas_pontuais = df_despesas[~df_despesas['categoria'].isin(categorias_recorrentes)]\n",
    "    if 'AUDIT DEZ25' in despesas_pontuais['categoria'].values:\n",
    "        fluxos_despesas_projetadas.append({\n",
    "            'data': datetime(2025, 12, 15),\n",
    "            'descricao': \"Despesa: AUDIT DEZ25\",\n",
    "            'valor': df_despesas[df_despesas['categoria'] == 'AUDIT DEZ25']['valor'].iloc[0],\n",
    "            'tipo': 'Necessidade'\n",
    "        })\n",
    "\n",
    "    return fluxos_despesas_projetadas\n",
    "\n",
    "# --- FUNÇÃO PRINCIPAL DE FLUXO DE CAIXA (ADAPTADA) ---\n",
    "def extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, fluxos_despesas_projetadas):\n",
    "    \"\"\"Extrai fluxos da carteira mais recente e combina com projeções.\"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # 1. Ativos da carteira mais recente (Renda Fixa, Cotas, Caixa)\n",
    "    # ... (lógica idêntica à anterior)\n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade: fluxos.append({'data': data_base, 'descricao': 'Conta Corrente (Saldo Inicial)', 'valor': disponibilidade['ativos'][0]['saldo'], 'tipo': 'Disponibilidade'})\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']: fluxos.append({'data': data_base + timedelta(days=1), 'descricao': f\"Resgate Fundo '{cota['titulo']}'\", 'valor': cota['valorBruto'], 'tipo': 'Disponibilidade'})\n",
    "    renda_fixa = next((a['RendaFixa'] for a in dados_carteira_recente['ativos'] if 'RendaFixa' in a and a['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']: fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'descricao': f\"Venc. RF '{titulo['codigoCustodia']}'\", 'valor': titulo['mercadoAtual'], 'tipo': 'Disponibilidade'})\n",
    "\n",
    "    # 2. Entradas do Estoque\n",
    "    # ... (lógica idêntica à anterior)\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        fluxo_estoque = estoque_valido.groupby('Data Vencimento')['Valor Presente'].sum().reset_index()\n",
    "        for _, row in fluxo_estoque.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'descricao': 'Recebimento Estoque', 'valor': row['Valor Presente'], 'tipo': 'Disponibilidade'})\n",
    "\n",
    "    # 3. Adiciona as despesas PROJETADAS\n",
    "    fluxos.extend(fluxos_despesas_projetadas)\n",
    "\n",
    "    # 4. Saídas de Amortização (da carteira mais recente)\n",
    "    # ... (lógica idêntica à anterior)\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            while data_amortizacao.weekday() >= 5: data_amortizacao += timedelta(days=1)\n",
    "            fluxos.append({'data': data_amortizacao, 'descricao': f\"Amortização Cota Sênior ({i+1}/36)\", 'valor': valor_amortizacao, 'tipo': 'Necessidade'})\n",
    "            ano, mes = (data_amortizacao.year, data_amortizacao.month + 1)\n",
    "            if mes > 12: mes, ano = (1, ano + 1)\n",
    "            data_amortizacao = data_amortizacao.replace(year=ano, month=mes)\n",
    "\n",
    "    return fluxos\n",
    "\n",
    "def criar_tabela_projecao(fluxos, data_base):\n",
    "    # ... (função idêntica à anterior)\n",
    "    if not fluxos: return pd.DataFrame()\n",
    "    df = pd.DataFrame(fluxos)\n",
    "    df_fluxo_diario = df.groupby('data')['valor'].sum().reset_index()\n",
    "    data_fim_projecao = df_fluxo_diario['data'].max()\n",
    "    idx = pd.date_range(start=data_base, end=data_fim_projecao)\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data').reindex(idx, fill_value=0).reset_index().rename(columns={'index':'data'})\n",
    "    df_fluxo_diario['saldo_projetado'] = df_fluxo_diario['valor'].cumsum()\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data')\n",
    "    prazos_dias = {'D+0': 0, 'D+1': 1, 'D+30': 30, 'D+90': 90, 'D+180': 180, 'D+365': 365}\n",
    "    datas_amortizacao = sorted([f['data'] for f in fluxos if 'Amortização' in f['descricao']])\n",
    "    if datas_amortizacao: prazos_dias[f\"1ª Amort.\"] = (datas_amortizacao[0] - data_base).days\n",
    "    projecao = []\n",
    "    for nome_prazo, dias in prazos_dias.items():\n",
    "        data_projecao = data_base + timedelta(days=dias)\n",
    "        saldo = df_fluxo_diario.asof(data_projecao)['saldo_projetado'] if data_projecao <= data_fim_projecao else np.nan\n",
    "        projecao.append({'Prazo': nome_prazo, 'Data': data_projecao.strftime('%d/%m/%Y'), 'Saldo Projetado': f\"R$ {saldo:,.2f}\"})\n",
    "    return pd.DataFrame(projecao)\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Encontra o arquivo de carteira mais recente\n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(f\"ERRO: Nenhum arquivo de carteira encontrado em {PATH_CARTEIRAS_HISTORICO}\")\n",
    "        exit()\n",
    "    arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "    print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_recente)}\")\n",
    "\n",
    "    # 2. Carregar todas as fontes de dados\n",
    "    dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "    df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    # 3. Projetar despesas com base no histórico\n",
    "    fluxos_despesas = projetar_despesas_futuras(PATH_CARTEIRAS_HISTORICO, data_referencia)\n",
    "    \n",
    "    # 4. Extrair e combinar todos os fluxos de caixa\n",
    "    lista_fluxos_final = extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, fluxos_despesas)\n",
    "    \n",
    "    # 5. Gerar a tabela final\n",
    "    tabela_final = criar_tabela_projecao(lista_fluxos_final, data_referencia)\n",
    "\n",
    "    print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (COM PROJEÇÃO DE DESPESAS HISTÓRICAS) ---\")\n",
    "    print(tabela_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b17eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo: C:\\Users\\Leo\\Downloads\\130170-Demonstrativo_Caixa.xlsx\n",
      "\n",
      "--- Análise de Saídas de Caixa Relevantes ---\n",
      "Procurando por pagamentos (saídas) maiores que R$ 500,000.00\n",
      "\n",
      "[RESULTADO] Encontradas as seguintes saídas de caixa relevantes:\n",
      "          Data                          Historico_1 Historico_2   Saida_Num\n",
      "281 2025-08-05                         AQUISICAO DC  DC C AQUIS  1266597.82\n",
      "205 2025-07-29                         AQUISICAO DC  DC C AQUIS   927801.55\n",
      "192 2025-07-28  Compra Cota CRT 1442 FC FIRF BEYOND  BEYOND FCT   840170.70\n",
      "49  2025-07-11                         AQUISICAO DC  DC C AQUIS   772639.52\n",
      "149 2025-07-23                         AQUISICAO DC  DC C AQUIS   703998.73\n",
      "93  2025-07-16  Compra Cota CRT 1442 FC FIRF BEYOND  BEYOND FCT   629409.33\n",
      "175 2025-07-25                         AQUISICAO DC  DC C AQUIS   626931.70\n",
      "83  2025-07-15                         AQUISICAO DC  DC C AQUIS   625809.90\n",
      "268 2025-08-04  Compra Cota CRT 1442 FC FIRF BEYOND  BEYOND FCT   620077.95\n",
      "266 2025-08-04                         AQUISICAO DC  DC C AQUIS   571896.07\n",
      "191 2025-07-28                         AQUISICAO DC  DC C AQUIS   562844.03\n",
      "163 2025-07-24                         AQUISICAO DC  DC C AQUIS   505367.47\n",
      "67  2025-07-14                         AQUISICAO DC  DC C AQUIS   501685.68\n",
      "\n",
      "[CONCLUSÃO PRELIMINAR]\n",
      ">>> Analise a tabela acima. Se você NÃO vir pagamentos recorrentes na casa de ~R$ 3.2 milhões, a despesa 'VALID' provavelmente é uma provisão contábil.\n",
      "    Se você vir esse padrão, então é uma saída de caixa real.\n"
     ]
    }
   ],
   "source": [
    "# vou verificar o demonstrativo de caixa, para ver essas saídas gigantescas: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURAÇÕES ---\n",
    "# 1. Verifique se o caminho para o seu arquivo está correto.\n",
    "PATH_DEMONSTRATIVO = r\"C:\\Users\\Leo\\Downloads\\130170-Demonstrativo_Caixa.xlsx\"\n",
    "\n",
    "# 2. Definimos um \"valor relevante\" para filtrar apenas grandes pagamentos.\n",
    "#    Estamos procurando por saídas na casa dos 3.2 milhões.\n",
    "LIMITE_VALOR_RELEVANTE = 500000  # Meio milhão de reais\n",
    "\n",
    "# --- FIM DAS CONFIGURAÇÕES ---\n",
    "\n",
    "try:\n",
    "    print(f\"Lendo o arquivo: {PATH_DEMONSTRATIVO}\")\n",
    "    \n",
    "    # Etapa 1: Ler o arquivo Excel, pulando as linhas de cabeçalho inúteis.\n",
    "    # Pelas prévias, os dados reais começam na linha 5 (índice 4).\n",
    "    # Vamos ler sem cabeçalho e nomear as colunas manualmente.\n",
    "    df_caixa = pd.read_excel(PATH_DEMONSTRATIVO, header=None, skiprows=4)\n",
    "\n",
    "    # Etapa 2: Limpar e nomear as colunas com base na estrutura visual.\n",
    "    df_caixa.columns = [\n",
    "        'Titulo', \n",
    "        'Historico_1', \n",
    "        'Historico_2', \n",
    "        'Data', \n",
    "        'Tipo', \n",
    "        'Entrada', \n",
    "        'Saida', \n",
    "        'Saldo'\n",
    "    ]\n",
    "\n",
    "    # Etapa 3: Converter as colunas para os tipos corretos.\n",
    "    # Converte a coluna 'Saida' de texto (ex: 'R$ 1.413,62') para número.\n",
    "    def limpar_valor(valor):\n",
    "        if isinstance(valor, str):\n",
    "            # Remove 'R$ ', espaços, e troca ',' por '.'\n",
    "            valor = valor.replace('R$ ', '').strip().replace('.', '').replace(',', '.')\n",
    "        # Converte para numérico, tratando erros\n",
    "        return pd.to_numeric(valor, errors='coerce')\n",
    "\n",
    "    df_caixa['Saida_Num'] = df_caixa['Saida'].apply(limpar_valor)\n",
    "    \n",
    "    # Converte a coluna 'Data' para o formato de data\n",
    "    df_caixa['Data'] = pd.to_datetime(df_caixa['Data'], errors='coerce', dayfirst=True)\n",
    "\n",
    "    # Remove linhas que não são de transação (ex: linhas totalmente vazias)\n",
    "    df_caixa.dropna(subset=['Data', 'Saida_Num'], how='all', inplace=True)\n",
    "    \n",
    "    # Preenche valores nulos em Saida_Num com 0 para poder filtrar\n",
    "    df_caixa['Saida_Num'] = df_caixa['Saida_Num'].fillna(0)\n",
    "\n",
    "    print(\"\\n--- Análise de Saídas de Caixa Relevantes ---\")\n",
    "    print(f\"Procurando por pagamentos (saídas) maiores que R$ {LIMITE_VALOR_RELEVANTE:,.2f}\")\n",
    "\n",
    "    # Etapa 4: Filtrar para encontrar apenas as grandes saídas de caixa.\n",
    "    grandes_saidas = df_caixa[df_caixa['Saida_Num'] > LIMITE_VALOR_RELEVANTE].copy()\n",
    "\n",
    "    # Etapa 5: Exibir os resultados.\n",
    "    if grandes_saidas.empty:\n",
    "        print(\"\\n[CONCLUSÃO PRELIMINAR]\")\n",
    "        print(\">>> Nenhuma grande saída de caixa (> R$ 500 mil) foi encontrada no período coberto pelo arquivo.\")\n",
    "        print(\"Isso fortalece a hipótese de que 'VALID' é uma provisão contábil e não uma saída de caixa mensal.\")\n",
    "    else:\n",
    "        print(\"\\n[RESULTADO] Encontradas as seguintes saídas de caixa relevantes:\")\n",
    "        # Seleciona e ordena as colunas mais importantes para a nossa análise\n",
    "        resultado = grandes_saidas[['Data', 'Historico_1', 'Historico_2', 'Saida_Num']].sort_values(by='Saida_Num', ascending=False)\n",
    "        print(resultado.to_string())\n",
    "        \n",
    "        print(\"\\n[CONCLUSÃO PRELIMINAR]\")\n",
    "        print(\">>> Analise a tabela acima. Se você NÃO vir pagamentos recorrentes na casa de ~R$ 3.2 milhões, a despesa 'VALID' provavelmente é uma provisão contábil.\")\n",
    "        print(\"    Se você vir esse padrão, então é uma saída de caixa real.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo não encontrado em '{PATH_DEMONSTRATIVO}'. Por favor, verifique o caminho.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado ao processar o arquivo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2517db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20241101.json\n",
      "\n",
      "Carregando dados de estoque...\n",
      "Dados de estoque consolidados com sucesso.\n",
      "Analisando histórico de despesas...\n",
      "\n",
      "Projetando despesas de CAIXA recorrentes (média histórica):\n",
      "categoria\n",
      "AUDIT LASTRO    -8087.224\n",
      "PEND GESTÃO       -49.690\n",
      "PROV ADM       -23292.658\n",
      "PROV GESTÃO    -84061.130\n",
      "TX ESCRT FIX    -2185.912\n",
      "Name: valor, dtype: float64\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (VERSÃO FINAL CORRIGIDA) ---\n",
      "   Prazo        Data   Saldo Projetado\n",
      "0    D+0  01/11/2024       R$ 1,000.00\n",
      "1    D+1  02/11/2024  R$ 46,964,837.28\n",
      "2   D+30  01/12/2024  R$ 46,847,160.67\n",
      "3   D+90  30/01/2025  R$ 46,729,484.05\n",
      "4  D+180  30/04/2025  R$ 46,376,454.21\n",
      "5  D+365  01/11/2025  R$ 49,465,859.14\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS DOS DADOS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (sem alterações) ---\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        dados = json.load(f)[0]\n",
    "    return dados\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = df[col].astype(str).str.replace(',', '.').astype(float)\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e: print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- FUNÇÃO DE PROJEÇÃO DE DESPESAS (COM A CORREÇÃO) ---\n",
    "def projetar_despesas_futuras(caminho_pasta_historico, data_base):\n",
    "    print(\"Analisando histórico de despesas...\")\n",
    "    arquivos_json = glob.glob(os.path.join(caminho_pasta_historico, \"*.json\"))\n",
    "    historico_despesas = []\n",
    "\n",
    "    for arquivo in arquivos_json:\n",
    "        dados = carregar_dados_carteira(arquivo)\n",
    "        data_arquivo = datetime.strptime(dados['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "        passivos = dados.get('passivos', [])\n",
    "        if passivos and passivos[0].get('ativos'):\n",
    "            for despesa in passivos[0]['ativos']:\n",
    "                historico_despesas.append({\n",
    "                    'data': data_arquivo,\n",
    "                    'categoria': despesa['despesa'],\n",
    "                    'valor': despesa['valor']\n",
    "                })\n",
    "    \n",
    "    if not historico_despesas:\n",
    "        return []\n",
    "\n",
    "    df_despesas = pd.DataFrame(historico_despesas)\n",
    "    \n",
    "    contagem_meses = df_despesas.groupby('categoria')['data'].nunique()\n",
    "    categorias_recorrentes = contagem_meses[contagem_meses > 3].index.tolist()\n",
    "    \n",
    "    media_recorrentes = df_despesas[df_despesas['categoria'].isin(categorias_recorrentes)].groupby('categoria')['valor'].mean()\n",
    "    \n",
    "    # ####################################################################\n",
    "    # ## ÚNICA ALTERAÇÃO - AQUI ESTÁ A CORREÇÃO ##\n",
    "    # Remove a provisão 'VALID' do cálculo de despesas caixa mensais\n",
    "    media_recorrentes = media_recorrentes.drop('VALID', errors='ignore') \n",
    "    # ####################################################################\n",
    "    \n",
    "    fluxos_despesas_projetadas = []\n",
    "    print(\"\\nProjetando despesas de CAIXA recorrentes (média histórica):\")\n",
    "    print(media_recorrentes)\n",
    "\n",
    "    # Projeta as despesas recorrentes para os próximos 12 meses\n",
    "    for i in range(1, 13):\n",
    "        data_projecao = data_base + relativedelta(months=i)\n",
    "        for categoria, valor_medio in media_recorrentes.items():\n",
    "             fluxos_despesas_projetadas.append({\n",
    "                'data': data_projecao,\n",
    "                'descricao': f\"Projeção Despesa: {categoria}\",\n",
    "                'valor': valor_medio,\n",
    "                'tipo': 'Necessidade'\n",
    "            })\n",
    "            \n",
    "    # Adiciona despesas pontuais que ainda não ocorreram\n",
    "    # (Esta lógica pode ser melhorada se houver mais despesas pontuais)\n",
    "\n",
    "    return fluxos_despesas_projetadas\n",
    "\n",
    "\n",
    "# --- DEMAIS FUNÇÕES (sem alterações) ---\n",
    "def extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, fluxos_despesas_projetadas):\n",
    "    # ... (função idêntica à anterior)\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade: fluxos.append({'data': data_base, 'descricao': 'Conta Corrente (Saldo Inicial)', 'valor': disponibilidade['ativos'][0]['saldo'], 'tipo': 'Disponibilidade'})\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']: fluxos.append({'data': data_base + timedelta(days=1), 'descricao': f\"Resgate Fundo '{cota['titulo']}'\", 'valor': cota['valorBruto'], 'tipo': 'Disponibilidade'})\n",
    "    renda_fixa = next((a['RendaFixa'] for a in dados_carteira_recente['ativos'] if 'RendaFixa' in a and a['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']: fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'descricao': f\"Venc. RF '{titulo['codigoCustodia']}'\", 'valor': titulo['mercadoAtual'], 'tipo': 'Disponibilidade'})\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        fluxo_estoque = estoque_valido.groupby('Data Vencimento')['Valor Presente'].sum().reset_index()\n",
    "        for _, row in fluxo_estoque.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'descricao': 'Recebimento Estoque', 'valor': row['Valor Presente'], 'tipo': 'Disponibilidade'})\n",
    "    fluxos.extend(fluxos_despesas_projetadas)\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            while data_amortizacao.weekday() >= 5: data_amortizacao += timedelta(days=1)\n",
    "            fluxos.append({'data': data_amortizacao, 'descricao': f\"Amortização Cota Sênior ({i+1}/36)\", 'valor': valor_amortizacao, 'tipo': 'Necessidade'})\n",
    "            ano, mes = (data_amortizacao.year, data_amortizacao.month + 1)\n",
    "            if mes > 12: mes, ano = (1, ano + 1)\n",
    "            data_amortizacao = data_amortizacao.replace(year=ano, month=mes)\n",
    "    return fluxos\n",
    "\n",
    "def criar_tabela_projecao(fluxos, data_base):\n",
    "    # ... (função idêntica à anterior)\n",
    "    if not fluxos: return pd.DataFrame()\n",
    "    df = pd.DataFrame(fluxos)\n",
    "    df_fluxo_diario = df.groupby('data')['valor'].sum().reset_index()\n",
    "    data_fim_projecao = df_fluxo_diario['data'].max() if not df_fluxo_diario.empty else data_base\n",
    "    idx = pd.date_range(start=data_base, end=data_fim_projecao)\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data').reindex(idx, fill_value=0).reset_index().rename(columns={'index':'data'})\n",
    "    df_fluxo_diario['saldo_projetado'] = df_fluxo_diario['valor'].cumsum()\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data')\n",
    "    prazos_dias = {'D+0': 0, 'D+1': 1, 'D+30': 30, 'D+90': 90, 'D+180': 180, 'D+365': 365}\n",
    "    datas_amortizacao = sorted([f['data'] for f in fluxos if 'Amortização' in f['descricao']])\n",
    "    if datas_amortizacao: prazos_dias[f\"1ª Amort.\"] = (datas_amortizacao[0] - data_base).days\n",
    "    projecao = []\n",
    "    for nome_prazo, dias in prazos_dias.items():\n",
    "        data_projecao = data_base + timedelta(days=dias)\n",
    "        saldo = df_fluxo_diario.asof(data_projecao)['saldo_projetado'] if data_projecao <= data_fim_projecao else np.nan\n",
    "        projecao.append({'Prazo': nome_prazo, 'Data': data_projecao.strftime('%d/%m/%Y'), 'Saldo Projetado': f\"R$ {saldo:,.2f}\"})\n",
    "    return pd.DataFrame(projecao)\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(f\"ERRO: Nenhum arquivo de carteira encontrado em {PATH_CARTEIRAS_HISTORICO}\")\n",
    "        exit()\n",
    "    arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "    print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_recente)}\")\n",
    "\n",
    "    dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "    df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    fluxos_despesas = projetar_despesas_futuras(PATH_CARTEIRAS_HISTORICO, data_referencia)\n",
    "    \n",
    "    lista_fluxos_final = extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, fluxos_despesas)\n",
    "    \n",
    "    tabela_final = criar_tabela_projecao(lista_fluxos_final, data_referencia)\n",
    "\n",
    "    print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (VERSÃO FINAL CORRIGIDA) ---\")\n",
    "    print(tabela_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52150ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20241101.json\n",
      "\n",
      "Carregando dados de estoque...\n",
      "Dados de estoque consolidados com sucesso.\n",
      "\n",
      "Carregando e consolidando arquivos de despesas...\n",
      "4 despesas com data de pagamento foram carregadas.\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (COM DATAS DE DESPESAS REAIS) ---\n",
      "   Prazo        Data   Saldo Projetado\n",
      "0    D+0  01/11/2024       R$ 1,000.00\n",
      "1    D+1  02/11/2024  R$ 46,964,837.28\n",
      "2   D+30  01/12/2024  R$ 46,964,837.28\n",
      "3   D+90  30/01/2025  R$ 46,964,837.28\n",
      "4  D+180  30/04/2025  R$ 46,964,837.28\n",
      "5  D+365  01/11/2025  R$ 50,649,089.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS DOS DADOS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO DE DADOS ---\n",
    "\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    \"\"\"Lê um arquivo JSON de carteira.\"\"\"\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    \"\"\"Lê e consolida os arquivos de estoque.\"\"\"\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = df[col].astype(str).str.replace(',', '.').astype(float)\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e: print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    \"\"\"\n",
    "    Lê e consolida todos os arquivos 'Despesas_Consolidadas.xlsx' de uma pasta e suas subpastas.\n",
    "    \"\"\"\n",
    "    print(\"\\nCarregando e consolidando arquivos de despesas...\")\n",
    "    # Usa glob para encontrar todos os arquivos com o nome exato, recursivamente\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    \n",
    "    if not arquivos_excel:\n",
    "        print(f\"AVISO: Nenhum arquivo 'Despesas_Consolidadas.xlsx' encontrado em {caminho_pasta}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            # Lê o arquivo, pulando as 6 primeiras linhas e usando a 7ª como cabeçalho\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler o arquivo de despesa {os.path.basename(arquivo)}: {e}\")\n",
    "\n",
    "    if not lista_df_despesas:\n",
    "        print(\"Nenhum dado de despesa foi carregado.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    \n",
    "    # Limpeza e seleção das colunas importantes\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    \n",
    "    # Garante que o valor da despesa seja negativo (saída de caixa)\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "\n",
    "    # Remove linhas onde as informações essenciais são nulas\n",
    "    df_final = df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "    \n",
    "    print(f\"{len(df_final)} despesas com data de pagamento foram carregadas.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE PROJEÇÃO (ATUALIZADAS) ---\n",
    "\n",
    "def extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    \"\"\"Combina todos os fluxos de caixa de diferentes fontes.\"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # 1. Ativos da carteira mais recente (Caixa, Fundos, RF)\n",
    "    # ... (lógica idêntica à anterior)\n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade: fluxos.append({'data': data_base, 'descricao': 'Conta Corrente (Saldo Inicial)', 'valor': disponibilidade['ativos'][0]['saldo'], 'tipo': 'Disponibilidade'})\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']: fluxos.append({'data': data_base + timedelta(days=1), 'descricao': f\"Resgate Fundo '{cota['titulo']}'\", 'valor': cota['valorBruto'], 'tipo': 'Disponibilidade'})\n",
    "    renda_fixa = next((a['RendaFixa'] for a in dados_carteira_recente['ativos'] if 'RendaFixa' in a and a['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']: fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'descricao': f\"Venc. RF '{titulo['codigoCustodia']}'\", 'valor': titulo['mercadoAtual'], 'tipo': 'Disponibilidade'})\n",
    "\n",
    "\n",
    "    # 2. Entradas do Estoque\n",
    "    # ... (lógica idêntica à anterior)\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        fluxo_estoque = estoque_valido.groupby('Data Vencimento')['Valor Presente'].sum().reset_index()\n",
    "        for _, row in fluxo_estoque.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'descricao': 'Recebimento Estoque', 'valor': row['Valor Presente'], 'tipo': 'Disponibilidade'})\n",
    "\n",
    "    # 3. Saídas de Despesas com Data de Pagamento\n",
    "    if not df_despesas_datadas.empty:\n",
    "        for _, despesa in df_despesas_datadas.iterrows():\n",
    "            fluxos.append({\n",
    "                'data': despesa['Data Pagamento'],\n",
    "                'descricao': f\"Despesa: {despesa['Categoria']}\",\n",
    "                'valor': despesa['Valor'],\n",
    "                'tipo': 'Necessidade'\n",
    "            })\n",
    "\n",
    "    # 4. Saídas de Amortização\n",
    "    # ... (lógica idêntica à anterior)\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            while data_amortizacao.weekday() >= 5: data_amortizacao += timedelta(days=1)\n",
    "            fluxos.append({'data': data_amortizacao, 'descricao': f\"Amortização Cota Sênior ({i+1}/36)\", 'valor': valor_amortizacao, 'tipo': 'Necessidade'})\n",
    "            ano, mes = (data_amortizacao.year, data_amortizacao.month + 1)\n",
    "            if mes > 12: mes, ano = (1, ano + 1)\n",
    "            data_amortizacao = data_amortizacao.replace(year=ano, month=mes)\n",
    "\n",
    "    return fluxos\n",
    "\n",
    "def criar_tabela_projecao(fluxos, data_base):\n",
    "    # ... (função idêntica à anterior)\n",
    "    if not fluxos: return pd.DataFrame()\n",
    "    df = pd.DataFrame(fluxos)\n",
    "    df_fluxo_diario = df.groupby('data')['valor'].sum().reset_index()\n",
    "    data_fim_projecao = df_fluxo_diario['data'].max() if not df_fluxo_diario.empty else data_base\n",
    "    idx = pd.date_range(start=data_base, end=data_fim_projecao)\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data').reindex(idx, fill_value=0).reset_index().rename(columns={'index':'data'})\n",
    "    df_fluxo_diario['saldo_projetado'] = df_fluxo_diario['valor'].cumsum()\n",
    "    df_fluxo_diario = df_fluxo_diario.set_index('data')\n",
    "    prazos_dias = {'D+0': 0, 'D+1': 1, 'D+30': 30, 'D+90': 90, 'D+180': 180, 'D+365': 365}\n",
    "    datas_amortizacao = sorted([f['data'] for f in fluxos if 'Amortização' in f['descricao']])\n",
    "    if datas_amortizacao: prazos_dias[f\"1ª Amort.\"] = (datas_amortizacao[0] - data_base).days\n",
    "    projecao = []\n",
    "    for nome_prazo, dias in prazos_dias.items():\n",
    "        data_projecao = data_base + timedelta(days=dias)\n",
    "        saldo = df_fluxo_diario.asof(data_projecao)['saldo_projetado'] if data_projecao <= data_fim_projecao else np.nan\n",
    "        projecao.append({'Prazo': nome_prazo, 'Data': data_projecao.strftime('%d/%m/%Y'), 'Saldo Projetado': f\"R$ {saldo:,.2f}\"})\n",
    "    return pd.DataFrame(projecao)\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Encontra o arquivo de carteira mais recente\n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(f\"ERRO: Nenhum arquivo de carteira encontrado em {PATH_CARTEIRAS_HISTORICO}\")\n",
    "        exit()\n",
    "    arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "    print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_recente)}\")\n",
    "\n",
    "    # Carrega todas as fontes de dados\n",
    "    dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "    df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    df_despesas = processar_dados_despesas(PATH_DESPESAS)\n",
    "    \n",
    "    data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    # Extrai e combina todos os fluxos de caixa\n",
    "    lista_fluxos_final = extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, df_despesas)\n",
    "    \n",
    "    # Gera a tabela final\n",
    "    tabela_final = criar_tabela_projecao(lista_fluxos_final, data_referencia)\n",
    "\n",
    "    print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (COM DATAS DE DESPESAS REAIS) ---\")\n",
    "    print(tabela_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4869a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20241101.json\n",
      "\n",
      "Carregando dados de estoque...\n",
      "Dados de estoque consolidados com sucesso.\n",
      "\n",
      "Carregando e consolidando arquivos de despesas...\n",
      "4 despesas com data de pagamento foram carregadas.\n",
      "\n",
      "--- DECOMPOSIÇÃO MENSAL DO FLUXO DE CAIXA PROJETADO ---\n",
      "categoria  Saldo Inicial Total Entradas Recebimento Estoque Total Saídas Despesas Operacionais Amortização de Cotas Fluxo de Caixa Mês     Saldo Final\n",
      "mes                                                                                                                                                   \n",
      "2024-11         1,000.00  46,963,837.28                0.00         0.00                  0.00                 0.00      46,963,837.28   46,964,837.28\n",
      "2025-05    46,964,837.28           0.00                0.00  -228,889.26           -228,889.26                 0.00        -228,889.26   46,735,948.02\n",
      "2025-10    46,735,948.02   3,913,141.23        3,913,141.23         0.00                  0.00                 0.00       3,913,141.23   50,649,089.25\n",
      "2025-11    50,649,089.25   6,762,041.82        6,762,041.82         0.00                  0.00                 0.00       6,762,041.82   57,411,131.07\n",
      "2025-12    57,411,131.07   6,580,771.83        6,580,771.83         0.00                  0.00                 0.00       6,580,771.83   63,991,902.90\n",
      "2026-01    63,991,902.90   6,404,436.46        6,404,436.46         0.00                  0.00                 0.00       6,404,436.46   70,396,339.37\n",
      "2026-02    70,396,339.37   6,235,364.03        6,235,364.03         0.00                  0.00                 0.00       6,235,364.03   76,631,703.40\n",
      "2026-03    76,631,703.40   6,085,229.71        6,085,229.71         0.00                  0.00                 0.00       6,085,229.71   82,716,933.10\n",
      "2026-04    82,716,933.10   5,914,224.17        5,914,224.17         0.00                  0.00                 0.00       5,914,224.17   88,631,157.27\n",
      "2026-05    88,631,157.27   5,761,502.39        5,761,502.39         0.00                  0.00                 0.00       5,761,502.39   94,392,659.66\n",
      "2026-06    94,392,659.66   5,602,817.36        5,602,817.36         0.00                  0.00                 0.00       5,602,817.36   99,995,477.03\n",
      "2026-07    99,995,477.03   5,451,262.69        5,451,262.69         0.00                  0.00                 0.00       5,451,262.69  105,446,739.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_22716\\766262222.py:158: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return decomposicao_final.applymap(lambda x: f\"{x:,.2f}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS DOS DADOS (sem alterações) ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (sem alterações) ---\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = df[col].astype(str).str.replace(',', '.').astype(float)\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e: print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    print(\"\\nCarregando e consolidando arquivos de despesas...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame()\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception as e: print(f\"Erro ao ler o arquivo de despesa {os.path.basename(arquivo)}: {e}\")\n",
    "    if not lista_df_despesas: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "    df_final = df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "    print(f\"{len(df_final)} despesas com data de pagamento foram carregadas.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- FUNÇÃO DE EXTRAÇÃO DE FLUXOS (COM NOVA CATEGORIZAÇÃO) ---\n",
    "\n",
    "def extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    \"\"\"Combina todos os fluxos de caixa e adiciona uma categoria simplificada para a decomposição.\"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # Saldo Inicial\n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        fluxos.append({'data': data_base, 'categoria': 'Saldo Inicial', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "\n",
    "    # Outras Entradas (Fundos, RF)\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base, 'categoria': 'Investimentos (Fundos/RF)', 'valor': cota['valorBruto']}) # Simplificado para D+0 na agregação mensal\n",
    "    renda_fixa = next((a['RendaFixa'] for a in dados_carteira_recente['ativos'] if 'RendaFixa' in a and a['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Investimentos (Fundos/RF)', 'valor': titulo['mercadoAtual']})\n",
    "\n",
    "    # Entradas do Estoque\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        for _, row in estoque_valido.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Recebimento Estoque', 'valor': row['Valor Presente']})\n",
    "\n",
    "    # Saídas de Despesas\n",
    "    if not df_despesas_datadas.empty:\n",
    "        for _, despesa in df_despesas_datadas.iterrows():\n",
    "            fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas Operacionais', 'valor': despesa['Valor']})\n",
    "\n",
    "    # Saídas de Amortização\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        # ... (lógica de data da amortização sem alterações)\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        # ...\n",
    "        fluxos.append({'data': data_amortizacao, 'categoria': 'Amortização de Cotas', 'valor': valor_amortizacao})\n",
    "\n",
    "\n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "\n",
    "# --- NOVA FUNÇÃO PARA GERAR A TABELA DE DECOMPOSIÇÃO ---\n",
    "\n",
    "def criar_tabela_decomposicao(df_fluxos, data_base):\n",
    "    \"\"\"Cria uma tabela mensal detalhada com a decomposição do fluxo de caixa.\"\"\"\n",
    "    if df_fluxos.empty:\n",
    "        return \"Nenhum fluxo de caixa para analisar.\"\n",
    "\n",
    "    # Filtra fluxos a partir da data base\n",
    "    df_fluxos = df_fluxos[df_fluxos['data'] >= data_base].copy()\n",
    "    \n",
    "    # Prepara o DataFrame para agregação mensal\n",
    "    df_fluxos['mes'] = df_fluxos['data'].dt.to_period('M')\n",
    "\n",
    "    # Agrupa por mês e categoria\n",
    "    decomposicao = df_fluxos.pivot_table(index='mes', columns='categoria', values='valor', aggfunc='sum').fillna(0)\n",
    "    \n",
    "    # Garante que as colunas principais existam\n",
    "    colunas_principais = ['Recebimento Estoque', 'Investimentos (Fundos/RF)', 'Despesas Operacionais', 'Amortização de Cotas']\n",
    "    for col in colunas_principais:\n",
    "        if col not in decomposicao.columns:\n",
    "            decomposicao[col] = 0\n",
    "            \n",
    "    # Calcula totais e saldos\n",
    "    decomposicao['Total Entradas'] = decomposicao['Recebimento Estoque'] + decomposicao['Investimentos (Fundos/RF)']\n",
    "    decomposicao['Total Saídas'] = decomposicao['Despesas Operacionais'] + decomposicao['Amortização de Cotas']\n",
    "    decomposicao['Fluxo de Caixa Mês'] = decomposicao['Total Entradas'] + decomposicao['Total Saídas']\n",
    "    \n",
    "    # Pega o saldo inicial da data base\n",
    "    saldo_inicial_valor = df_fluxos[df_fluxos['categoria'] == 'Saldo Inicial']['valor'].sum()\n",
    "    \n",
    "    decomposicao['Saldo Final'] = decomposicao['Fluxo de Caixa Mês'].cumsum() + saldo_inicial_valor\n",
    "    decomposicao['Saldo Inicial'] = decomposicao['Saldo Final'].shift(1).fillna(saldo_inicial_valor)\n",
    "    \n",
    "    # Formata para exibição\n",
    "    colunas_para_mostrar = [\n",
    "        'Saldo Inicial', 'Total Entradas', 'Recebimento Estoque', 'Total Saídas', \n",
    "        'Despesas Operacionais', 'Amortização de Cotas', 'Fluxo de Caixa Mês', 'Saldo Final'\n",
    "    ]\n",
    "    \n",
    "    # Filtra colunas que realmente existem no dataframe final\n",
    "    colunas_existentes = [col for col in colunas_para_mostrar if col in decomposicao.columns]\n",
    "    \n",
    "    # Exibe apenas os primeiros 12 meses da projeção para clareza\n",
    "    decomposicao_final = decomposicao[colunas_existentes].head(12)\n",
    "    \n",
    "    return decomposicao_final.applymap(lambda x: f\"{x:,.2f}\")\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(f\"ERRO: Nenhum arquivo de carteira encontrado em {PATH_CARTEIRAS_HISTORICO}\")\n",
    "        exit()\n",
    "    arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "    print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_recente)}\")\n",
    "\n",
    "    dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "    df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    df_despesas = processar_dados_despesas(PATH_DESPESAS)\n",
    "    \n",
    "    data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    df_fluxos_final = extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, df_despesas)\n",
    "    \n",
    "    tabela_decomposicao = criar_tabela_decomposicao(df_fluxos_final, data_referencia)\n",
    "\n",
    "    print(\"\\n--- DECOMPOSIÇÃO MENSAL DO FLUXO DE CAIXA PROJETADO ---\")\n",
    "    print(tabela_decomposicao.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86631171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20241101.json\n",
      "\n",
      "Carregando dados de estoque...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de estoque consolidados com sucesso.\n",
      "\n",
      "Carregando e consolidando arquivos de despesas...\n",
      "4 despesas com data de pagamento foram carregadas.\n",
      "\n",
      "--- DECOMPOSIÇÃO MENSAL DO FLUXO DE CAIXA (VERSÃO CORRIGIDA) ---\n",
      "categoria   Saldo Inicial Total Entradas Recebimento Estoque Total Saídas Despesas Operacionais Amortização de Cotas Fluxo de Caixa Mês     Saldo Final\n",
      "2024-11          1,000.00  46,963,837.28                0.00         0.00                  0.00                 0.00      46,963,837.28   46,964,837.28\n",
      "2024-12     46,964,837.28           0.00                0.00         0.00                  0.00                 0.00               0.00   46,964,837.28\n",
      "2025-01     46,964,837.28           0.00                0.00         0.00                  0.00                 0.00               0.00   46,964,837.28\n",
      "2025-02     46,964,837.28           0.00                0.00         0.00                  0.00                 0.00               0.00   46,964,837.28\n",
      "2025-03     46,964,837.28           0.00                0.00         0.00                  0.00                 0.00               0.00   46,964,837.28\n",
      "2025-04     46,964,837.28           0.00                0.00         0.00                  0.00                 0.00               0.00   46,964,837.28\n",
      "2025-05     46,964,837.28           0.00                0.00  -228,889.26           -228,889.26                 0.00        -228,889.26   46,735,948.02\n",
      "2025-06     46,735,948.02           0.00                0.00         0.00                  0.00                 0.00               0.00   46,735,948.02\n",
      "2025-07     46,735,948.02           0.00                0.00         0.00                  0.00                 0.00               0.00   46,735,948.02\n",
      "2025-08     46,735,948.02           0.00                0.00         0.00                  0.00                 0.00               0.00   46,735,948.02\n",
      "2025-09     46,735,948.02           0.00                0.00         0.00                  0.00                 0.00               0.00   46,735,948.02\n",
      "2025-10     46,735,948.02   3,913,141.23        3,913,141.23         0.00                  0.00                 0.00       3,913,141.23   50,649,089.25\n",
      "2025-11     50,649,089.25   6,762,041.82        6,762,041.82         0.00                  0.00                 0.00       6,762,041.82   57,411,131.07\n",
      "2025-12     57,411,131.07   6,580,771.83        6,580,771.83         0.00                  0.00                 0.00       6,580,771.83   63,991,902.90\n",
      "2026-01     63,991,902.90   6,404,436.46        6,404,436.46         0.00                  0.00                 0.00       6,404,436.46   70,396,339.37\n",
      "2026-02     70,396,339.37   6,235,364.03        6,235,364.03         0.00                  0.00                 0.00       6,235,364.03   76,631,703.40\n",
      "2026-03     76,631,703.40   6,085,229.71        6,085,229.71         0.00                  0.00                 0.00       6,085,229.71   82,716,933.10\n",
      "2026-04     82,716,933.10   5,914,224.17        5,914,224.17         0.00                  0.00                 0.00       5,914,224.17   88,631,157.27\n",
      "2026-05     88,631,157.27   5,761,502.39        5,761,502.39         0.00                  0.00                 0.00       5,761,502.39   94,392,659.66\n",
      "2026-06     94,392,659.66   5,602,817.36        5,602,817.36         0.00                  0.00                 0.00       5,602,817.36   99,995,477.03\n",
      "2026-07     99,995,477.03   5,451,262.69        5,451,262.69         0.00                  0.00                 0.00       5,451,262.69  105,446,739.72\n",
      "2026-08    105,446,739.72   5,110,206.24        5,110,206.24         0.00                  0.00                 0.00       5,110,206.24  110,556,945.96\n",
      "2026-09    110,556,945.96   4,860,189.18        4,860,189.18         0.00                  0.00                 0.00       4,860,189.18  115,417,135.14\n",
      "2026-10    115,417,135.14   4,646,753.76        4,646,753.76         0.00                  0.00                 0.00       4,646,753.76  120,063,888.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_22716\\2740654259.py:152: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return decomposicao_final.applymap(lambda x: f\"{x:,.2f}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS DOS DADOS (sem alterações) ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (sem alterações) ---\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = df[col].astype(str).str.replace(',', '.').astype(float)\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e: print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    print(\"\\nCarregando e consolidando arquivos de despesas...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame()\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception as e: print(f\"Erro ao ler o arquivo de despesa {os.path.basename(arquivo)}: {e}\")\n",
    "    if not lista_df_despesas: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "    df_final = df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "    print(f\"{len(df_final)} despesas com data de pagamento foram carregadas.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- FUNÇÃO DE EXTRAÇÃO DE FLUXOS (COM LÓGICA DE AMORTIZAÇÃO CORRIGIDA) ---\n",
    "def extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    \"\"\"Combina todos os fluxos de caixa e adiciona uma categoria simplificada.\"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        fluxos.append({'data': data_base, 'categoria': 'Saldo Inicial', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base, 'categoria': 'Investimentos (Fundos/RF)', 'valor': cota['valorBruto']})\n",
    "            \n",
    "    renda_fixa = next((a['RendaFixa'] for a in dados_carteira_recente['ativos'] if 'RendaFixa' in a and a['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Investimentos (Fundos/RF)', 'valor': titulo['mercadoAtual']})\n",
    "\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        for _, row in estoque_valido.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Recebimento Estoque', 'valor': row['Valor Presente']})\n",
    "\n",
    "    if not df_despesas_datadas.empty:\n",
    "        for _, despesa in df_despesas_datadas.iterrows():\n",
    "            fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas Operacionais', 'valor': despesa['Valor']})\n",
    "\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5:\n",
    "                data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amortização de Cotas', 'valor': valor_amortizacao})\n",
    "\n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "\n",
    "# --- FUNÇÃO DE DECOMPOSIÇÃO (COM A CORREÇÃO DO ERRO) ---\n",
    "def criar_tabela_decomposicao(df_fluxos, data_base):\n",
    "    if df_fluxos.empty:\n",
    "        return \"Nenhum fluxo de caixa para analisar.\"\n",
    "\n",
    "    df_fluxos = df_fluxos[df_fluxos['data'] >= data_base].copy()\n",
    "    df_fluxos['mes'] = df_fluxos['data'].dt.to_period('M')\n",
    "    \n",
    "    decomposicao = df_fluxos.pivot_table(index='mes', columns='categoria', values='valor', aggfunc='sum').fillna(0)\n",
    "    \n",
    "    # ### CORREÇÃO DO BUG ESTÁ AQUI ###\n",
    "    # Converte o 'datetime' do python para 'Timestamp' do pandas antes de usar '.to_period()'\n",
    "    start_period = pd.Timestamp(data_base).to_period('M')\n",
    "    end_period = df_fluxos['mes'].max()\n",
    "    \n",
    "    # Garante que o end_period seja válido antes de criar o range\n",
    "    if pd.isna(end_period):\n",
    "        end_period = start_period\n",
    "\n",
    "    idx_meses = pd.period_range(start=start_period, end=end_period, freq='M')\n",
    "    decomposicao = decomposicao.reindex(idx_meses, fill_value=0)\n",
    "    \n",
    "    colunas_principais = ['Recebimento Estoque', 'Investimentos (Fundos/RF)', 'Despesas Operacionais', 'Amortização de Cotas']\n",
    "    for col in colunas_principais:\n",
    "        if col not in decomposicao.columns:\n",
    "            decomposicao[col] = 0\n",
    "            \n",
    "    decomposicao['Total Entradas'] = decomposicao['Recebimento Estoque'] + decomposicao['Investimentos (Fundos/RF)']\n",
    "    decomposicao['Total Saídas'] = decomposicao['Despesas Operacionais'] + decomposicao['Amortização de Cotas']\n",
    "    decomposicao['Fluxo de Caixa Mês'] = decomposicao['Total Entradas'] + decomposicao['Total Saídas']\n",
    "    \n",
    "    saldo_inicial_valor = df_fluxos[df_fluxos['categoria'] == 'Saldo Inicial']['valor'].sum()\n",
    "    \n",
    "    decomposicao['Saldo Final'] = decomposicao['Fluxo de Caixa Mês'].cumsum() + saldo_inicial_valor\n",
    "    decomposicao['Saldo Inicial'] = decomposicao['Saldo Final'].shift(1).fillna(saldo_inicial_valor)\n",
    "    \n",
    "    colunas_para_mostrar = ['Saldo Inicial', 'Total Entradas', 'Recebimento Estoque', 'Total Saídas', 'Despesas Operacionais', 'Amortização de Cotas', 'Fluxo de Caixa Mês', 'Saldo Final']\n",
    "    colunas_existentes = [col for col in colunas_para_mostrar if col in decomposicao.columns]\n",
    "    \n",
    "    decomposicao_final = decomposicao[colunas_existentes].head(24) # Mostra os primeiros 24 meses\n",
    "    \n",
    "    # Formatação final para melhor leitura\n",
    "    return decomposicao_final.applymap(lambda x: f\"{x:,.2f}\")\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(f\"ERRO: Nenhum arquivo de carteira encontrado em {PATH_CARTEIRAS_HISTORICO}\")\n",
    "        exit()\n",
    "    arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "    print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_recente)}\")\n",
    "\n",
    "    dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "    df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    df_despesas = processar_dados_despesas(PATH_DESPESAS)\n",
    "    \n",
    "    data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    df_fluxos_final = extrair_fluxos_de_caixa(dados_carteira_recente, df_estoque, df_despesas)\n",
    "    \n",
    "    tabela_decomposicao = criar_tabela_decomposicao(df_fluxos_final, data_referencia)\n",
    "\n",
    "    print(\"\\n--- DECOMPOSIÇÃO MENSAL DO FLUXO DE CAIXA (VERSÃO CORRIGIDA) ---\")\n",
    "    print(tabela_decomposicao.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03619038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TESTE DE RECONCILIAÇÃO DE CAIXA ---\n",
      "Analisando o período de 01/11/2024 a 01/09/2025\n",
      "\n",
      "[1] Visão da Carteira (JSONs):\n",
      "   - Saldo de Caixa Inicial...: R$ 1,000.00\n",
      "   - Saldo de Caixa Final.....: R$ 5,292.37\n",
      "   - VARIAÇÃO ESPERADA........: R$ 4,292.37\n",
      "\n",
      "[2] Visão do Caixa Real (Demonstrativo Excel):\n",
      "   - Total de Entradas........: R$ 13,621,819.33\n",
      "   - Total de Saídas..........: R$ 13,642,601.12\n",
      "   - FLUXO DE CAIXA REAL......: R$ -20,781.79\n",
      "\n",
      "[3] Resultado da Reconciliação:\n",
      "   - Diferença (Fluxo Real - Variação Esperada): R$ -25,074.16\n",
      "\n",
      "⚠️ ALERTA: Há uma diferença relevante entre os relatórios.\n",
      "Isso pode indicar que há transações de caixa não capturadas ou desalinhamento entre as datas dos relatórios.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CONFIGURAÇÕES ---\n",
    "# Escolha dois arquivos de carteira que você baixou para definir o período da análise\n",
    "PATH_CARTEIRA_INICIO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20241101.json\"\n",
    "PATH_CARTEIRA_FIM = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250901.json\" # Exemplo, use um arquivo que vc tenha\n",
    "\n",
    "PATH_DEMONSTRATIVO = r\"C:\\Users\\Leo\\Downloads\\130170-Demonstrativo_Caixa.xlsx\"\n",
    "# --- FIM DAS CONFIGURAções ---\n",
    "\n",
    "\n",
    "def extrair_saldo_caixa_json(caminho_arquivo):\n",
    "    \"\"\"Extrai o saldo de caixa de um arquivo de carteira JSON.\"\"\"\n",
    "    try:\n",
    "        with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "            dados = json.load(f)[0]\n",
    "        \n",
    "        data_extracao = datetime.strptime(dados['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "        \n",
    "        disponibilidade = next((a['Disponibilidade'] for a in dados['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "        if disponibilidade and disponibilidade.get('ativos'):\n",
    "            return disponibilidade['ativos'][0]['saldo'], data_extracao\n",
    "        else: # Se não houver 'Disponibilidade', assume R$ 0.00\n",
    "            return 0.0, data_extracao\n",
    "\n",
    "    except (FileNotFoundError, IndexError, KeyError) as e:\n",
    "        print(f\"Erro ao processar o arquivo {os.path.basename(caminho_arquivo)}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def calcular_fluxo_real_demonstrativo(caminho_arquivo, data_inicio, data_fim):\n",
    "    \"\"\"Lê o demonstrativo e calcula o fluxo de caixa líquido em um período.\"\"\"\n",
    "    try:\n",
    "        df_caixa = pd.read_excel(caminho_arquivo, header=None, skiprows=4)\n",
    "        df_caixa.columns = ['Titulo', 'Historico_1', 'Historico_2', 'Data', 'Tipo', 'Entrada', 'Saida', 'Saldo']\n",
    "\n",
    "        def limpar_valor(valor):\n",
    "            if isinstance(valor, str):\n",
    "                valor = valor.replace('R$ ', '').strip().replace('.', '').replace(',', '.')\n",
    "            return pd.to_numeric(valor, errors='coerce')\n",
    "\n",
    "        df_caixa['Entrada_Num'] = df_caixa['Entrada'].apply(limpar_valor).fillna(0)\n",
    "        df_caixa['Saida_Num'] = df_caixa['Saida'].apply(limpar_valor).fillna(0)\n",
    "        df_caixa['Data'] = pd.to_datetime(df_caixa['Data'], errors='coerce', dayfirst=True)\n",
    "        \n",
    "        # Filtra o DataFrame para o período de interesse\n",
    "        df_periodo = df_caixa[(df_caixa['Data'] >= data_inicio) & (df_caixa['Data'] <= data_fim)]\n",
    "        \n",
    "        total_entradas = df_periodo['Entrada_Num'].sum()\n",
    "        total_saidas = df_periodo['Saida_Num'].sum()\n",
    "        fluxo_liquido = total_entradas - total_saidas\n",
    "        \n",
    "        return fluxo_liquido, total_entradas, total_saidas\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o demonstrativo de caixa: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# --- EXECUÇÃO DO TESTE DE RECONCILIAÇÃO ---\n",
    "if __name__ == \"__main__\":\n",
    "    saldo_inicial, data_inicial = extrair_saldo_caixa_json(PATH_CARTEIRA_INICIO)\n",
    "    saldo_final, data_final = extrair_saldo_caixa_json(PATH_CARTEIRA_FIM)\n",
    "\n",
    "    if saldo_inicial is not None and saldo_final is not None:\n",
    "        print(\"\\n--- TESTE DE RECONCILIAÇÃO DE CAIXA ---\")\n",
    "        print(f\"Analisando o período de {data_inicial.strftime('%d/%m/%Y')} a {data_final.strftime('%d/%m/%Y')}\")\n",
    "        \n",
    "        # 1. Variação de caixa segundo os relatórios de carteira (JSON)\n",
    "        variacao_esperada = saldo_final - saldo_inicial\n",
    "        print(\"\\n[1] Visão da Carteira (JSONs):\")\n",
    "        print(f\"   - Saldo de Caixa Inicial...: R$ {saldo_inicial:,.2f}\")\n",
    "        print(f\"   - Saldo de Caixa Final.....: R$ {saldo_final:,.2f}\")\n",
    "        print(f\"   - VARIAÇÃO ESPERADA........: R$ {variacao_esperada:,.2f}\")\n",
    "\n",
    "        # 2. Fluxo de caixa segundo o demonstrativo (Excel)\n",
    "        fluxo_real, entradas, saidas = calcular_fluxo_real_demonstrativo(PATH_DEMONSTRATIVO, data_inicial, data_final)\n",
    "        \n",
    "        if fluxo_real is not None:\n",
    "            print(\"\\n[2] Visão do Caixa Real (Demonstrativo Excel):\")\n",
    "            print(f\"   - Total de Entradas........: R$ {entradas:,.2f}\")\n",
    "            print(f\"   - Total de Saídas..........: R$ {saidas:,.2f}\")\n",
    "            print(f\"   - FLUXO DE CAIXA REAL......: R$ {fluxo_real:,.2f}\")\n",
    "\n",
    "            # 3. Comparação Final\n",
    "            diferenca = fluxo_real - variacao_esperada\n",
    "            print(\"\\n[3] Resultado da Reconciliação:\")\n",
    "            print(f\"   - Diferença (Fluxo Real - Variação Esperada): R$ {diferenca:,.2f}\")\n",
    "\n",
    "            if abs(diferenca) < 1000: # Uma pequena tolerância para arredondamentos\n",
    "                print(\"\\n✅ CONCLUSÃO: Os dados são consistentes! A diferença é mínima.\")\n",
    "                print(\"Isso confirma que o saldo de caixa elevado é real, assumindo que o fundo pare de reinvestir.\")\n",
    "            else:\n",
    "                print(\"\\n⚠️ ALERTA: Há uma diferença relevante entre os relatórios.\")\n",
    "                print(\"Isso pode indicar que há transações de caixa não capturadas ou desalinhamento entre as datas dos relatórios.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7e52cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de estoque para análise de entradas...\n",
      "Carregando demonstrativo de caixa para análise de saídas...\n",
      "\n",
      "--- ANÁLISE DA TAXA DE REINVESTIMENTO HISTÓRICA ---\n",
      "Visão mensal (Entradas do Estoque vs. Saídas para Aquisição de novos ativos):\n",
      "    mes Entradas_Estoque Saidas_Aquisicao Taxa_Reinvestimento_Percentual\n",
      "2025-07     2,968,999.98     8,515,618.97                         286.8%\n",
      "2025-08     4,742,097.54     2,507,538.35                          52.9%\n",
      "\n",
      "---------------------------------------------------------\n",
      ">>> Taxa Média de Reinvestimento Histórica: 169.8%\n",
      "---------------------------------------------------------\n",
      "\n",
      "Use este valor na sua projeção para simular o comportamento futuro do gestor.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CAMINHOS (verifique se estão corretos) ---\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DEMONSTRATIVO = r\"C:\\Users\\Leo\\Downloads\\130170-Demonstrativo_Caixa.xlsx\"\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (versões simplificadas para esta análise) ---\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    \"\"\"Lê e consolida os arquivos de estoque, focando em datas e valores.\"\"\"\n",
    "    print(\"Carregando dados de estoque para análise de entradas...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    \n",
    "    all_dfs = []\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            df['Valor Presente'] = df['Valor Presente'].astype(str).str.replace(',', '.').astype(float)\n",
    "            df['Data Vencimento'] = pd.to_datetime(df['Data Vencimento'], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "            all_dfs.append(df[['Data Vencimento', 'Valor Presente']])\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "def processar_demonstrativo_caixa(caminho_arquivo):\n",
    "    \"\"\"Lê o demonstrativo e foca nas saídas para aquisição de ativos.\"\"\"\n",
    "    print(\"Carregando demonstrativo de caixa para análise de saídas...\")\n",
    "    try:\n",
    "        df_caixa = pd.read_excel(caminho_arquivo, header=None, skiprows=4)\n",
    "        df_caixa.columns = ['Titulo', 'Historico_1', 'Historico_2', 'Data', 'Tipo', 'Entrada', 'Saida', 'Saldo']\n",
    "\n",
    "        def limpar_valor(valor):\n",
    "            if isinstance(valor, str):\n",
    "                valor = valor.replace('R$ ', '').strip().replace('.', '').replace(',', '.')\n",
    "            return pd.to_numeric(valor, errors='coerce')\n",
    "\n",
    "        df_caixa['Saida_Num'] = df_caixa['Saida'].apply(limpar_valor).fillna(0)\n",
    "        df_caixa['Data'] = pd.to_datetime(df_caixa['Data'], errors='coerce', dayfirst=True)\n",
    "        \n",
    "        return df_caixa[['Data', 'Historico_2', 'Saida_Num']].dropna(subset=['Data'])\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- EXECUÇÃO DA ANÁLISE ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Calcula as ENTRADAS mensais do Estoque\n",
    "    df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    df_estoque['mes'] = df_estoque['Data Vencimento'].dt.to_period('M')\n",
    "    entradas_mensais = df_estoque.groupby('mes')['Valor Presente'].sum().reset_index()\n",
    "    entradas_mensais.rename(columns={'Valor Presente': 'Entradas_Estoque'}, inplace=True)\n",
    "\n",
    "    # 2. Calcula as SAÍDAS mensais para Aquisição de Ativos\n",
    "    df_caixa = processar_demonstrativo_caixa(PATH_DEMONSTRATIVO)\n",
    "    df_caixa['mes'] = df_caixa['Data'].dt.to_period('M')\n",
    "    \n",
    "    # Filtra apenas as saídas que são para compra de novos ativos\n",
    "    saidas_aquisicao = df_caixa[df_caixa['Historico_2'] == 'DC C AQUIS']\n",
    "    saidas_mensais = saidas_aquisicao.groupby('mes')['Saida_Num'].sum().reset_index()\n",
    "    saidas_mensais.rename(columns={'Saida_Num': 'Saidas_Aquisicao'}, inplace=True)\n",
    "    \n",
    "    # 3. Combina os dados e calcula a taxa\n",
    "    df_analise = pd.merge(entradas_mensais, saidas_mensais, on='mes', how='inner')\n",
    "    \n",
    "    # Evita divisão por zero\n",
    "    df_analise = df_analise[df_analise['Entradas_Estoque'] > 0]\n",
    "    \n",
    "    df_analise['Taxa_Reinvestimento'] = df_analise['Saidas_Aquisicao'] / df_analise['Entradas_Estoque']\n",
    "    \n",
    "    print(\"\\n--- ANÁLISE DA TAXA DE REINVESTIMENTO HISTÓRICA ---\")\n",
    "    if df_analise.empty:\n",
    "        print(\"Não foi possível encontrar dados sobrepostos de entradas e saídas para calcular a taxa.\")\n",
    "    else:\n",
    "        # Formata para exibição\n",
    "        df_analise['Entradas_Estoque'] = df_analise['Entradas_Estoque'].map('{:,.2f}'.format)\n",
    "        df_analise['Saidas_Aquisicao'] = df_analise['Saidas_Aquisicao'].map('{:,.2f}'.format)\n",
    "        df_analise['Taxa_Reinvestimento'] = pd.to_numeric(df_analise['Taxa_Reinvestimento'])\n",
    "        df_analise['Taxa_Reinvestimento_Percentual'] = df_analise['Taxa_Reinvestimento'].map('{:.1%}'.format)\n",
    "        \n",
    "        print(\"Visão mensal (Entradas do Estoque vs. Saídas para Aquisição de novos ativos):\")\n",
    "        print(df_analise[['mes', 'Entradas_Estoque', 'Saidas_Aquisicao', 'Taxa_Reinvestimento_Percentual']].to_string(index=False))\n",
    "        \n",
    "        # 4. Calcula a média\n",
    "        taxa_media = df_analise['Taxa_Reinvestimento'].mean()\n",
    "        print(\"\\n---------------------------------------------------------\")\n",
    "        print(f\">>> Taxa Média de Reinvestimento Histórica: {taxa_media:.1%}\")\n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(\"\\nUse este valor na sua projeção para simular o comportamento futuro do gestor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89e6b9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20241101.json\n",
      "\n",
      "Carregando dados de estoque...\n",
      "Dados de estoque consolidados com sucesso.\n",
      "\n",
      "Carregando e consolidando arquivos de despesas...\n",
      "4 despesas com data de pagamento foram carregadas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_22716\\1147000862.py:115: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  entradas_estoque_mensal = estoque_valido.groupby(pd.Grouper(key='Data Vencimento', freq='M'))['Valor Presente'].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DECOMPOSIÇÃO MENSAL (COM SIMULAÇÃO DE REINVESTIMENTO) ---\n",
      "Usando uma taxa de reinvestimento de 52.9%\n",
      "categoria  Saldo Inicial Total Entradas Recebimento Estoque   Total Saídas Reinvestimento (Simulado) Despesas Operacionais Amortização de Cotas Fluxo de Caixa Mês    Saldo Final\n",
      "2024-11         1,000.00  46,963,837.28                0.00           0.00                      0.00                  0.00                 0.00      46,963,837.28  46,964,837.28\n",
      "2024-12    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-01    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-02    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-03    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-04    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-05    46,964,837.28           0.00                0.00    -228,889.26                      0.00           -228,889.26                 0.00        -228,889.26  46,735,948.02\n",
      "2025-06    46,735,948.02           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,735,948.02\n",
      "2025-07    46,735,948.02           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,735,948.02\n",
      "2025-08    46,735,948.02           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,735,948.02\n",
      "2025-09    46,735,948.02           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,735,948.02\n",
      "2025-10    46,735,948.02   3,913,141.23        3,913,141.23  -2,070,051.71             -2,070,051.71                  0.00                 0.00       1,843,089.52  48,579,037.54\n",
      "2025-11    48,579,037.54   6,762,041.82        6,762,041.82  -3,577,120.12             -3,577,120.12                  0.00                 0.00       3,184,921.70  51,763,959.24\n",
      "2025-12    51,763,959.24   6,580,771.83        6,580,771.83  -3,481,228.30             -3,481,228.30                  0.00                 0.00       3,099,543.53  54,863,502.77\n",
      "2026-01    54,863,502.77   6,404,436.46        6,404,436.46  -3,387,946.89             -3,387,946.89                  0.00                 0.00       3,016,489.57  57,879,992.34\n",
      "2026-02    57,879,992.34   6,235,364.03        6,235,364.03  -3,298,507.57             -3,298,507.57                  0.00                 0.00       2,936,856.46  60,816,848.80\n",
      "2026-03    60,816,848.80   6,085,229.71        6,085,229.71  -3,219,086.51             -3,219,086.51                  0.00                 0.00       2,866,143.19  63,682,991.99\n",
      "2026-04    63,682,991.99   5,914,224.17        5,914,224.17  -3,128,624.59             -3,128,624.59                  0.00                 0.00       2,785,599.58  66,468,591.58\n",
      "2026-05    66,468,591.58   5,761,502.39        5,761,502.39  -3,047,834.76             -3,047,834.76                  0.00                 0.00       2,713,667.63  69,182,259.20\n",
      "2026-06    69,182,259.20   5,602,817.36        5,602,817.36  -2,963,890.39             -2,963,890.39                  0.00                 0.00       2,638,926.98  71,821,186.18\n",
      "2026-07    71,821,186.18   5,451,262.69        5,451,262.69  -2,883,717.97             -2,883,717.97                  0.00                 0.00       2,567,544.73  74,388,730.91\n",
      "2026-08    74,388,730.91   5,110,206.24        5,110,206.24  -2,703,299.10             -2,703,299.10                  0.00                 0.00       2,406,907.14  76,795,638.05\n",
      "2026-09    76,795,638.05   4,860,189.18        4,860,189.18  -2,571,040.08             -2,571,040.08                  0.00                 0.00       2,289,149.10  79,084,787.15\n",
      "2026-10    79,084,787.15   4,646,753.76        4,646,753.76  -2,458,132.74             -2,458,132.74                  0.00                 0.00       2,188,621.02  81,273,408.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_22716\\1147000862.py:145: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return decomposicao_final.applymap(lambda x: f\"{x:,.2f}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS (sem alterações) ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "# --- Premissa Principal (Ajuste aqui para testar cenários) ---\n",
    "TAXA_DE_REINVESTIMENTO = 0.529  # 52.9%\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (COM A CORREÇÃO EM processar_dados_estoque) ---\n",
    "\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv:\n",
    "        print(f\"AVISO: Nenhum arquivo CSV de estoque encontrado em {caminho_pasta}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                \n",
    "                # ### CORREÇÃO DO BUG ESTÁ AQUI ###\n",
    "                # Mantém todas as colunas do DataFrame, em vez de selecionar apenas duas\n",
    "                all_dfs.append(df)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    \n",
    "    if not all_dfs:\n",
    "        print(\"Nenhum dado de estoque foi carregado.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    print(\"\\nCarregando e consolidando arquivos de despesas...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame()\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception as e: print(f\"Erro ao ler o arquivo de despesa {os.path.basename(arquivo)}: {e}\")\n",
    "    if not lista_df_despesas: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "    df_final = df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "    print(f\"{len(df_final)} despesas com data de pagamento foram carregadas.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- DEMAIS FUNÇÕES (sem alterações) ---\n",
    "\n",
    "def extrair_fluxos_de_caixa_com_reinvestimento(dados_carteira_recente, df_estoque, df_despesas_datadas, taxa_reinvest):\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    # ... (lógica interna desta função não precisa mudar)\n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        fluxos.append({'data': data_base, 'categoria': 'Saldo Inicial', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base, 'categoria': 'Investimentos (Fundos/RF)', 'valor': cota['valorBruto']})\n",
    "    renda_fixa = next((a['RendaFixa'] for a in dados_carteira_recente['ativos'] if 'RendaFixa' in a and a['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Investimentos (Fundos/RF)', 'valor': titulo['mercadoAtual']})\n",
    "    if not df_despesas_datadas.empty:\n",
    "        for _, despesa in df_despesas_datadas.iterrows():\n",
    "            fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas Operacionais', 'valor': despesa['Valor']})\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amortização de Cotas', 'valor': valor_amortizacao})\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        for _, row in estoque_valido.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Recebimento Estoque', 'valor': row['Valor Presente']})\n",
    "        entradas_estoque_mensal = estoque_valido.groupby(pd.Grouper(key='Data Vencimento', freq='M'))['Valor Presente'].sum()\n",
    "        for data_mes, total_entrada_mes in entradas_estoque_mensal.items():\n",
    "            valor_reinvestimento = total_entrada_mes * taxa_reinvest * -1\n",
    "            if valor_reinvestimento != 0:\n",
    "                fluxos.append({'data': data_mes, 'categoria': 'Reinvestimento (Simulado)','valor': valor_reinvestimento})\n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "def criar_tabela_decomposicao(df_fluxos, data_base):\n",
    "    if df_fluxos.empty: return \"Nenhum fluxo de caixa para analisar.\"\n",
    "    # ... (código da função sem alterações) ...\n",
    "    df_fluxos = df_fluxos[df_fluxos['data'] >= data_base].copy()\n",
    "    df_fluxos['mes'] = df_fluxos['data'].dt.to_period('M')\n",
    "    decomposicao = df_fluxos.pivot_table(index='mes', columns='categoria', values='valor', aggfunc='sum').fillna(0)\n",
    "    start_period = pd.Timestamp(data_base).to_period('M')\n",
    "    end_period = df_fluxos['mes'].max()\n",
    "    if pd.isna(end_period): end_period = start_period\n",
    "    idx_meses = pd.period_range(start=start_period, end=end_period, freq='M')\n",
    "    decomposicao = decomposicao.reindex(idx_meses, fill_value=0)\n",
    "    colunas_principais = ['Recebimento Estoque', 'Investimentos (Fundos/RF)', 'Despesas Operacionais', 'Amortização de Cotas', 'Reinvestimento (Simulado)']\n",
    "    for col in colunas_principais:\n",
    "        if col not in decomposicao.columns: decomposicao[col] = 0\n",
    "    decomposicao['Total Entradas'] = decomposicao['Recebimento Estoque'] + decomposicao['Investimentos (Fundos/RF)']\n",
    "    decomposicao['Total Saídas'] = decomposicao['Despesas Operacionais'] + decomposicao['Amortização de Cotas'] + decomposicao['Reinvestimento (Simulado)']\n",
    "    decomposicao['Fluxo de Caixa Mês'] = decomposicao['Total Entradas'] + decomposicao['Total Saídas']\n",
    "    saldo_inicial_valor = df_fluxos[df_fluxos['categoria'] == 'Saldo Inicial']['valor'].sum()\n",
    "    decomposicao['Saldo Final'] = decomposicao['Fluxo de Caixa Mês'].cumsum() + saldo_inicial_valor\n",
    "    decomposicao['Saldo Inicial'] = decomposicao['Saldo Final'].shift(1).fillna(saldo_inicial_valor)\n",
    "    colunas_para_mostrar = ['Saldo Inicial', 'Total Entradas', 'Recebimento Estoque', 'Total Saídas', 'Reinvestimento (Simulado)', 'Despesas Operacionais', 'Amortização de Cotas', 'Fluxo de Caixa Mês', 'Saldo Final']\n",
    "    colunas_existentes = [col for col in colunas_para_mostrar if col in decomposicao.columns]\n",
    "    decomposicao_final = decomposicao[colunas_existentes].head(24)\n",
    "    return decomposicao_final.applymap(lambda x: f\"{x:,.2f}\")\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Carrega os dados (pode ser executado em células separadas no Jupyter)\n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(f\"ERRO: Nenhum arquivo de carteira encontrado em {PATH_CARTEIRAS_HISTORICO}\")\n",
    "        exit()\n",
    "    arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "    print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_recente)}\")\n",
    "\n",
    "    dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "    df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    df_despesas = processar_dados_despesas(PATH_DESPESAS)\n",
    "    \n",
    "    data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    # Gera os fluxos e a tabela final\n",
    "    df_fluxos_final = extrair_fluxos_de_caixa_com_reinvestimento(dados_carteira_recente, df_estoque, df_despesas, TAXA_DE_REINVESTIMENTO)\n",
    "    tabela_decomposicao_final = criar_tabela_decomposicao(df_fluxos_final, data_referencia)\n",
    "\n",
    "    print(\"\\n--- DECOMPOSIÇÃO MENSAL (COM SIMULAÇÃO DE REINVESTIMENTO) ---\")\n",
    "    print(f\"Usando uma taxa de reinvestimento de {TAXA_DE_REINVESTIMENTO:.1%}\")\n",
    "    print(tabela_decomposicao_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c838948f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando demonstrativo de caixa completo de: C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Demonstrativos\\143414-Demonstrativo_Caixa.xlsx\n",
      "Analisando o período de 31/07/2024 a 30/08/2024\n",
      "\n",
      "--- ANÁLISE DE FONTES E USOS DE CAIXA (DADOS COMPLETOS) ---\n",
      "        Saldo Inicial Entradas Estoque Outras Entradas   Total Fontes Saídas Aquisição Outras Saídas Saldo Final\n",
      "Mês                                                                                                             \n",
      "2024-07          0.00        18,890.91    2,397,087.42   2,415,978.33     1,198,249.93  1,198,249.93      293.78\n",
      "2024-08        293.78        64,623.75   26,781,069.93  26,845,987.46    20,698,693.91  6,082,669.80        0.00\n",
      "\n",
      "--- CONCLUSÃO DA ANÁLISE ---\n",
      "Observe o comportamento mensal. Agora podemos ver com mais clareza como o fundo utiliza seu caixa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_22716\\4257945184.py:98: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  print(df_resultado.applymap('{:,.2f}'.format).to_string())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- NOVO CAMINHO PARA O ARQUIVO ---\n",
    "PATH_DEMONSTRATIVO_COMPLETO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Demonstrativos\\143414-Demonstrativo_Caixa.xlsx\"\n",
    "\n",
    "# (Assumindo que 'df_estoque' já existe no seu notebook)\n",
    "\n",
    "# --- Nova função para processar o demonstrativo de caixa ---\n",
    "# (Criamos uma nova para manter a anterior, se necessário)\n",
    "def processar_demonstrativo_caixa_completo(caminho_arquivo):\n",
    "    \"\"\"Lê o demonstrativo de caixa, focando em datas, históricos e valores.\"\"\"\n",
    "    print(f\"Carregando demonstrativo de caixa completo de: {caminho_arquivo}\")\n",
    "    try:\n",
    "        # A estrutura parece ser a mesma, com cabeçalho a ser pulado\n",
    "        df_caixa = pd.read_excel(caminho_arquivo, header=None, skiprows=4)\n",
    "        df_caixa.columns = ['Titulo', 'Historico_1', 'Historico_2', 'Data', 'Tipo', 'Entrada', 'Saida', 'Saldo']\n",
    "\n",
    "        def limpar_valor(valor):\n",
    "            if isinstance(valor, str):\n",
    "                valor = valor.replace('R$ ', '').strip().replace('.', '').replace(',', '.')\n",
    "            return pd.to_numeric(valor, errors='coerce')\n",
    "\n",
    "        df_caixa['Entrada_Num'] = df_caixa['Entrada'].apply(limpar_valor).fillna(0)\n",
    "        df_caixa['Saida_Num'] = df_caixa['Saida'].apply(limpar_valor).fillna(0)\n",
    "        df_caixa['Data'] = pd.to_datetime(df_caixa['Data'], errors='coerce', dayfirst=True)\n",
    "        \n",
    "        # Mantém a coluna de Saldo numérico para os cálculos\n",
    "        df_caixa['Saldo'] = df_caixa['Saldo'].apply(limpar_valor)\n",
    "        \n",
    "        return df_caixa.dropna(subset=['Data'])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRO: Arquivo não encontrado em {caminho_arquivo}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao processar o arquivo: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# A função de análise de Fontes e Usos permanece a mesma\n",
    "def analise_fontes_e_usos(df_estoque, df_caixa):\n",
    "    \"\"\"\n",
    "    Realiza uma análise de Fontes e Usos de Caixa para entender o comportamento\n",
    "    de investimento do gestor.\n",
    "    \"\"\"\n",
    "    if df_caixa.empty:\n",
    "        print(\"DataFrame de caixa está vazio.\")\n",
    "        return\n",
    "\n",
    "    # Determina o período de tempo real dos dados de caixa\n",
    "    data_inicio_real = df_caixa['Data'].min()\n",
    "    data_fim_real = df_caixa['Data'].max()\n",
    "    print(f\"Analisando o período de {data_inicio_real.strftime('%d/%m/%Y')} a {data_fim_real.strftime('%d/%m/%Y')}\\n\")\n",
    "\n",
    "    # Prepara os DataFrames com uma coluna de 'mes'\n",
    "    df_caixa['mes'] = df_caixa['Data'].dt.to_period('M')\n",
    "    df_estoque['mes'] = df_estoque['Data Vencimento'].dt.to_period('M')\n",
    "\n",
    "    meses_analise = sorted(df_caixa['mes'].unique())\n",
    "    \n",
    "    resultados = []\n",
    "    saldo_inicial_mes = None\n",
    "\n",
    "    for mes in meses_analise:\n",
    "        df_caixa_mes = df_caixa[df_caixa['mes'] == mes]\n",
    "        df_estoque_mes = df_estoque[df_estoque['mes'] == mes]\n",
    "\n",
    "        # Encontra o saldo inicial (último saldo do mês anterior ou o primeiro do mês atual)\n",
    "        if saldo_inicial_mes is None:\n",
    "            primeira_transacao_mes = df_caixa_mes.sort_values('Data').iloc[0]\n",
    "            saldo_inicial_mes = primeira_transacao_mes['Saldo'] - (primeira_transacao_mes['Entrada_Num'] - primeira_transacao_mes['Saida_Num'])\n",
    "        \n",
    "        # FONTES DE CAIXA\n",
    "        entradas_estoque = df_estoque_mes['Valor Presente'].sum()\n",
    "        saidas_aquisicao = df_caixa_mes[df_caixa_mes['Historico_2'] == 'DC C AQUIS']['Saida_Num'].sum()\n",
    "        \n",
    "        # Todas as outras entradas e saídas do extrato\n",
    "        outras_entradas = df_caixa_mes[df_caixa_mes['Historico_2'] != 'DC C AQUIS']['Entrada_Num'].sum()\n",
    "        outras_saidas = df_caixa_mes[df_caixa_mes['Historico_2'] != 'DC C AQUIS']['Saida_Num'].sum()\n",
    "\n",
    "        saldo_final_mes = df_caixa_mes.sort_values('Data').iloc[-1]['Saldo']\n",
    "\n",
    "        resultados.append({\n",
    "            'Mês': mes,\n",
    "            'Saldo Inicial': saldo_inicial_mes,\n",
    "            'Entradas Estoque': entradas_estoque,\n",
    "            'Outras Entradas': outras_entradas,\n",
    "            'Total Fontes': saldo_inicial_mes + entradas_estoque + outras_entradas,\n",
    "            'Saídas Aquisição': saidas_aquisicao,\n",
    "            'Outras Saídas': outras_saidas,\n",
    "            'Saldo Final': saldo_final_mes,\n",
    "        })\n",
    "        \n",
    "        saldo_inicial_mes = saldo_final_mes\n",
    "\n",
    "    df_resultado = pd.DataFrame(resultados).set_index('Mês')\n",
    "    \n",
    "    print(\"--- ANÁLISE DE FONTES E USOS DE CAIXA (DADOS COMPLETOS) ---\")\n",
    "    print(df_resultado.applymap('{:,.2f}'.format).to_string())\n",
    "    \n",
    "    print(\"\\n--- CONCLUSÃO DA ANÁLISE ---\")\n",
    "    print(\"Observe o comportamento mensal. Agora podemos ver com mais clareza como o fundo utiliza seu caixa.\")\n",
    "\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO ---\n",
    "# Carrega o NOVO demonstrativo de caixa\n",
    "df_caixa_completo = processar_demonstrativo_caixa_completo(PATH_DEMONSTRATIVO_COMPLETO)\n",
    "\n",
    "# Executa a análise com o novo arquivo\n",
    "analise_fontes_e_usos(df_estoque, df_caixa_completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf73ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo todos os arquivos de demonstrativo da pasta: C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Demonstrativos\n",
      "Foram consolidados 12 arquivos de demonstrativo, resultando em 2187 transações.\n",
      "Analisando o período consolidado de 31/07/2024 a 31/07/2025\n",
      "\n",
      "--- ANÁLISE DE FONTES E USOS DE CAIXA (HISTÓRICO CONSOLIDADO) ---\n",
      "        Saldo Inicial Entradas Estoque Outras Entradas Saídas Aquisição   Outras Saídas  Saldo Final\n",
      "Mês                                                                                                 \n",
      "2024-07          0.00        18,890.91    2,397,087.42     1,198,249.93    1,198,249.93  -357,221.15\n",
      "2024-08   -357,221.15        64,623.75   26,781,069.93    20,698,693.91    6,082,669.80         0.00\n",
      "2024-09          0.00        73,910.95   79,481,234.21    18,825,962.15   60,654,272.06         0.00\n",
      "2024-10          0.00        78,902.67  142,306,785.29    24,915,228.73  117,389,556.56   104,917.88\n",
      "2024-11    104,917.88       140,920.39  118,643,613.46    47,871,339.45   71,741,232.65       961.19\n",
      "2024-12        961.19       183,170.77  200,000,000.00             0.00  200,000,000.00         0.00\n",
      "2025-01          0.00       281,575.69   25,491,919.43    24,189,835.09    2,333,331.82   916,156.14\n",
      "2025-02    916,156.14       492,338.31   30,334,556.07    19,859,913.79   11,415,413.62   438,582.27\n",
      "2025-03    438,582.27       789,229.71   22,873,413.00    14,187,368.26    8,686,044.73     1,000.01\n",
      "2025-04      1,000.01       861,255.76    8,817,179.28     4,667,397.98    4,150,781.31         0.00\n",
      "2025-05          0.00     1,147,631.89    7,190,268.33     3,951,621.84    3,237,646.49    27,482.49\n",
      "2025-06     27,482.49     1,653,717.46   12,811,890.37     4,542,421.41    8,264,816.15     1,000.00\n",
      "2025-07      1,000.00     2,968,999.98   12,024,831.70     9,932,368.35    2,092,463.35       999.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_22716\\1484511809.py:104: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  print(df_resultado.applymap('{:,.2f}'.format).to_string())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- CAMINHO PARA A PASTA COM TODOS OS DEMONSTRATIVOS ---\n",
    "PATH_PASTA_DEMONSTRATIVOS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Demonstrativos\"\n",
    "\n",
    "# (Assumindo que 'df_estoque' já existe no seu notebook)\n",
    "\n",
    "# --- Nova função para ler e consolidar TODOS os demonstrativos de uma pasta ---\n",
    "def processar_demonstrativos_pasta(caminho_pasta):\n",
    "    \"\"\"\n",
    "    Lê todos os arquivos Excel de uma pasta, os consolida em um único DataFrame\n",
    "    e o prepara para a análise.\n",
    "    \"\"\"\n",
    "    print(f\"Lendo todos os arquivos de demonstrativo da pasta: {caminho_pasta}\")\n",
    "    \n",
    "    # Pega todos os arquivos .xlsx na pasta\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, \"*.xlsx\"))\n",
    "    \n",
    "    if not arquivos_excel:\n",
    "        print(f\"ERRO: Nenhum arquivo Excel (.xlsx) encontrado em {caminho_pasta}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    lista_dfs_mensais = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df_mes = pd.read_excel(arquivo, header=None, skiprows=4)\n",
    "            lista_dfs_mensais.append(df_mes)\n",
    "        except Exception as e:\n",
    "            print(f\"AVISO: Não foi possível ler o arquivo '{os.path.basename(arquivo)}'. Erro: {e}\")\n",
    "\n",
    "    if not lista_dfs_mensais:\n",
    "        print(\"ERRO: Nenhum arquivo de demonstrativo pôde ser lido com sucesso.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Consolida todos os dataframes em um só\n",
    "    df_consolidado = pd.concat(lista_dfs_mensais, ignore_index=True)\n",
    "    \n",
    "    # Limpeza e preparação (mesma lógica de antes)\n",
    "    df_consolidado.columns = ['Titulo', 'Historico_1', 'Historico_2', 'Data', 'Tipo', 'Entrada', 'Saida', 'Saldo']\n",
    "\n",
    "    def limpar_valor(valor):\n",
    "        if isinstance(valor, str):\n",
    "            valor = valor.replace('R$ ', '').strip().replace('.', '').replace(',', '.')\n",
    "        return pd.to_numeric(valor, errors='coerce')\n",
    "\n",
    "    df_consolidado['Entrada_Num'] = df_consolidado['Entrada'].apply(limpar_valor).fillna(0)\n",
    "    df_consolidado['Saida_Num'] = df_consolidado['Saida'].apply(limpar_valor).fillna(0)\n",
    "    df_consolidado['Data'] = pd.to_datetime(df_consolidado['Data'], errors='coerce', dayfirst=True)\n",
    "    df_consolidado['Saldo'] = df_consolidado['Saldo'].apply(limpar_valor)\n",
    "    \n",
    "    df_final = df_consolidado.dropna(subset=['Data']).sort_values('Data').reset_index(drop=True)\n",
    "    print(f\"Foram consolidados {len(arquivos_excel)} arquivos de demonstrativo, resultando em {len(df_final)} transações.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# A função de análise de Fontes e Usos permanece a mesma\n",
    "def analise_fontes_e_usos(df_estoque, df_caixa):\n",
    "    if df_caixa.empty:\n",
    "        print(\"DataFrame de caixa está vazio.\")\n",
    "        return\n",
    "\n",
    "    data_inicio_real = df_caixa['Data'].min()\n",
    "    data_fim_real = df_caixa['Data'].max()\n",
    "    print(f\"Analisando o período consolidado de {data_inicio_real.strftime('%d/%m/%Y')} a {data_fim_real.strftime('%d/%m/%Y')}\\n\")\n",
    "\n",
    "    df_caixa['mes'] = df_caixa['Data'].dt.to_period('M')\n",
    "    df_estoque['mes'] = df_estoque['Data Vencimento'].dt.to_period('M')\n",
    "\n",
    "    meses_analise = sorted(df_caixa['mes'].unique())\n",
    "    resultados = []\n",
    "    saldo_inicial_mes = None\n",
    "\n",
    "    for mes in meses_analise:\n",
    "        df_caixa_mes = df_caixa[df_caixa['mes'] == mes]\n",
    "        df_estoque_mes = df_estoque[df_estoque['mes'] == mes]\n",
    "\n",
    "        if saldo_inicial_mes is None:\n",
    "            primeira_transacao = df_caixa.iloc[0]\n",
    "            saldo_inicial_mes = primeira_transacao['Saldo'] - (primeira_transacao['Entrada_Num'] - primeira_transacao['Saida_Num'])\n",
    "        \n",
    "        entradas_estoque = df_estoque_mes['Valor Presente'].sum()\n",
    "        saidas_aquisicao = df_caixa_mes[df_caixa_mes['Historico_2'] == 'DC C AQUIS']['Saida_Num'].sum()\n",
    "        outras_entradas = df_caixa_mes[df_caixa_mes['Historico_2'] != 'DC C AQUIS']['Entrada_Num'].sum()\n",
    "        outras_saidas = df_caixa_mes[df_caixa_mes['Historico_2'] != 'DC C AQUIS']['Saida_Num'].sum()\n",
    "        saldo_final_mes = df_caixa_mes.sort_values('Data').iloc[-1]['Saldo']\n",
    "\n",
    "        resultados.append({\n",
    "            'Mês': mes,\n",
    "            'Saldo Inicial': saldo_inicial_mes,\n",
    "            'Entradas Estoque': entradas_estoque,\n",
    "            'Outras Entradas': outras_entradas,\n",
    "            'Saídas Aquisição': saidas_aquisicao,\n",
    "            'Outras Saídas': outras_saidas,\n",
    "            'Saldo Final': saldo_final_mes,\n",
    "        })\n",
    "        saldo_inicial_mes = saldo_final_mes\n",
    "\n",
    "    df_resultado = pd.DataFrame(resultados).set_index('Mês')\n",
    "    \n",
    "    print(\"--- ANÁLISE DE FONTES E USOS DE CAIXA (HISTÓRICO CONSOLIDADO) ---\")\n",
    "    print(df_resultado.applymap('{:,.2f}'.format).to_string())\n",
    "\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO ---\n",
    "# 1. Carrega e consolida TODOS os demonstrativos da pasta\n",
    "df_caixa_consolidado = processar_demonstrativos_pasta(PATH_PASTA_DEMONSTRATIVOS)\n",
    "\n",
    "# 2. Executa a análise com o DataFrame consolidado\n",
    "analise_fontes_e_usos(df_estoque, df_caixa_consolidado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdceff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoria Saldo Inicial Total Entradas Recebimento Estoque    Total Saídas  \\\n",
      "2024-11        1,000.00  46,963,837.28                0.00  -46,953,837.28   \n",
      "2024-12       11,000.00           0.00                0.00            0.00   \n",
      "2025-01       11,000.00           0.00                0.00            0.00   \n",
      "2025-02       11,000.00           0.00                0.00            0.00   \n",
      "2025-03       11,000.00           0.00                0.00            0.00   \n",
      "2025-04       11,000.00           0.00                0.00            0.00   \n",
      "2025-05       11,000.00           0.00                0.00     -228,889.26   \n",
      "2025-06     -217,889.26           0.00                0.00            0.00   \n",
      "2025-07     -217,889.26           0.00                0.00            0.00   \n",
      "2025-08     -217,889.26           0.00                0.00            0.00   \n",
      "2025-09     -217,889.26           0.00                0.00            0.00   \n",
      "2025-10     -217,889.26   3,913,141.23        3,913,141.23   -3,684,251.97   \n",
      "2025-11       11,000.00   6,762,041.82        6,762,041.82   -6,762,041.82   \n",
      "2025-12       11,000.00   6,580,771.83        6,580,771.83   -6,580,771.83   \n",
      "2026-01       11,000.00   6,404,436.46        6,404,436.46   -6,404,436.46   \n",
      "2026-02       11,000.00   6,235,364.03        6,235,364.03   -6,235,364.03   \n",
      "2026-03       11,000.00   6,085,229.71        6,085,229.71   -6,085,229.71   \n",
      "2026-04       11,000.00   5,914,224.17        5,914,224.17   -5,914,224.17   \n",
      "2026-05       11,000.00   5,761,502.39        5,761,502.39   -5,761,502.39   \n",
      "2026-06       11,000.00   5,602,817.36        5,602,817.36   -5,602,817.36   \n",
      "2026-07       11,000.00   5,451,262.69        5,451,262.69   -5,451,262.69   \n",
      "2026-08       11,000.00   5,110,206.24        5,110,206.24   -5,110,206.24   \n",
      "2026-09       11,000.00   4,860,189.18        4,860,189.18   -4,860,189.18   \n",
      "2026-10       11,000.00   4,646,753.76        4,646,753.76   -4,646,753.76   \n",
      "\n",
      "categoria Reinvestimento (Simulado) Despesas Operacionais  \\\n",
      "2024-11              -46,953,837.28                  0.00   \n",
      "2024-12                        0.00                  0.00   \n",
      "2025-01                        0.00                  0.00   \n",
      "2025-02                        0.00                  0.00   \n",
      "2025-03                        0.00                  0.00   \n",
      "2025-04                        0.00                  0.00   \n",
      "2025-05                        0.00           -228,889.26   \n",
      "2025-06                        0.00                  0.00   \n",
      "2025-07                        0.00                  0.00   \n",
      "2025-08                        0.00                  0.00   \n",
      "2025-09                        0.00                  0.00   \n",
      "2025-10               -3,684,251.97                  0.00   \n",
      "2025-11               -6,762,041.82                  0.00   \n",
      "2025-12               -6,580,771.83                  0.00   \n",
      "2026-01               -6,404,436.46                  0.00   \n",
      "2026-02               -6,235,364.03                  0.00   \n",
      "2026-03               -6,085,229.71                  0.00   \n",
      "2026-04               -5,914,224.17                  0.00   \n",
      "2026-05               -5,761,502.39                  0.00   \n",
      "2026-06               -5,602,817.36                  0.00   \n",
      "2026-07               -5,451,262.69                  0.00   \n",
      "2026-08               -5,110,206.24                  0.00   \n",
      "2026-09               -4,860,189.18                  0.00   \n",
      "2026-10               -4,646,753.76                  0.00   \n",
      "\n",
      "categoria Amortização de Cotas Fluxo de Caixa Mês  Saldo Final  \n",
      "2024-11                   0.00          10,000.00    11,000.00  \n",
      "2024-12                   0.00               0.00    11,000.00  \n",
      "2025-01                   0.00               0.00    11,000.00  \n",
      "2025-02                   0.00               0.00    11,000.00  \n",
      "2025-03                   0.00               0.00    11,000.00  \n",
      "2025-04                   0.00               0.00    11,000.00  \n",
      "2025-05                   0.00        -228,889.26  -217,889.26  \n",
      "2025-06                   0.00               0.00  -217,889.26  \n",
      "2025-07                   0.00               0.00  -217,889.26  \n",
      "2025-08                   0.00               0.00  -217,889.26  \n",
      "2025-09                   0.00               0.00  -217,889.26  \n",
      "2025-10                   0.00         228,889.26    11,000.00  \n",
      "2025-11                   0.00               0.00    11,000.00  \n",
      "2025-12                   0.00               0.00    11,000.00  \n",
      "2026-01                   0.00               0.00    11,000.00  \n",
      "2026-02                   0.00               0.00    11,000.00  \n",
      "2026-03                   0.00               0.00    11,000.00  \n",
      "2026-04                   0.00               0.00    11,000.00  \n",
      "2026-05                   0.00               0.00    11,000.00  \n",
      "2026-06                   0.00               0.00    11,000.00  \n",
      "2026-07                   0.00               0.00    11,000.00  \n",
      "2026-08                   0.00               0.00    11,000.00  \n",
      "2026-09                   0.00               0.00    11,000.00  \n",
      "2026-10                   0.00               0.00    11,000.00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_22716\\527954461.py:174: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return decomposicao_final.applymap(lambda x: f\"{x:,.2f}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS E PREMISSAS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "# Premissa final baseada na análise histórica: o saldo de caixa que o gestor tenta manter.\n",
    "SALDO_CAIXA_ALVO = 10000.00\n",
    "\n",
    "\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv:\n",
    "        print(f\"AVISO: Nenhum arquivo CSV de estoque encontrado em {caminho_pasta}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                \n",
    "                # ### CORREÇÃO DO BUG ESTÁ AQUI ###\n",
    "                # Mantém todas as colunas do DataFrame, em vez de selecionar apenas duas\n",
    "                all_dfs.append(df)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    \n",
    "    if not all_dfs:\n",
    "        print(\"Nenhum dado de estoque foi carregado.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    print(\"\\nCarregando e consolidando arquivos de despesas...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame()\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception as e: print(f\"Erro ao ler o arquivo de despesa {os.path.basename(arquivo)}: {e}\")\n",
    "    if not lista_df_despesas: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "    df_final = df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "    print(f\"{len(df_final)} despesas com data de pagamento foram carregadas.\")\n",
    "    return df_final\n",
    "\n",
    "# --- FUNÇÃO DE PROJEÇÃO FINAL (COM LÓGICA DE SALDO ALVO) ---\n",
    "def extrair_fluxos_de_caixa_final(dados_carteira_recente, df_estoque, df_despesas_datadas, saldo_alvo):\n",
    "    \"\"\"\n",
    "    Gera a lista completa de fluxos de caixa, simulando o reinvestimento\n",
    "    para manter um saldo de caixa alvo.\n",
    "    \"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    # Adiciona todos os fluxos, exceto o reinvestimento, a uma lista temporária\n",
    "    fluxos_pre_reinvest = []\n",
    "    \n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        fluxos.append({'data': data_base, 'categoria': 'Saldo Inicial', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos_pre_reinvest.append({'data': data_base, 'categoria': 'Investimentos (Fundos/RF)', 'valor': cota['valorBruto']})\n",
    "            \n",
    "    # ... (Restante da extração de RF, Estoque, Despesas, Amortização como antes) ...\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        for _, row in estoque_valido.iterrows():\n",
    "            fluxos_pre_reinvest.append({'data': row['Data Vencimento'], 'categoria': 'Recebimento Estoque', 'valor': row['Valor Presente']})\n",
    "    \n",
    "    if not df_despesas_datadas.empty:\n",
    "        for _, despesa in df_despesas_datadas.iterrows():\n",
    "            fluxos_pre_reinvest.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas Operacionais', 'valor': despesa['Valor']})\n",
    "\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos_pre_reinvest.append({'data': data_pagamento, 'categoria': 'Amortização de Cotas', 'valor': valor_amortizacao})\n",
    "\n",
    "\n",
    "    df_pre_reinvest = pd.DataFrame(fluxos_pre_reinvest)\n",
    "    df_pre_reinvest['mes'] = df_pre_reinvest['data'].dt.to_period('M')\n",
    "    \n",
    "    # Calcula o fluxo de caixa operacional de cada mês\n",
    "    fluxo_op_mensal = df_pre_reinvest.groupby('mes')['valor'].sum()\n",
    "    \n",
    "    # Adiciona os fluxos originais à lista final\n",
    "    fluxos.extend(fluxos_pre_reinvest)\n",
    "    \n",
    "    # Calcula e adiciona as saídas de reinvestimento\n",
    "    saldo_acumulado = 0 # Começa do zero pois o saldo inicial já está na lista principal\n",
    "    for mes, fluxo_do_mes in fluxo_op_mensal.items():\n",
    "        caixa_disponivel_antes = saldo_acumulado + fluxo_do_mes\n",
    "        excedente = caixa_disponivel_antes - saldo_alvo\n",
    "        \n",
    "        if excedente > 0:\n",
    "            valor_reinvestimento = -excedente\n",
    "            fluxos.append({\n",
    "                'data': mes.to_timestamp(how='end'), # Adiciona no final do mês\n",
    "                'categoria': 'Reinvestimento (Simulado)',\n",
    "                'valor': valor_reinvestimento\n",
    "            })\n",
    "            saldo_acumulado += fluxo_do_mes + valor_reinvestimento\n",
    "        else:\n",
    "            saldo_acumulado += fluxo_do_mes\n",
    "            \n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "# A função criar_tabela_decomposicao permanece a mesma\n",
    "def criar_tabela_decomposicao(df_fluxos, data_base):\n",
    "    if df_fluxos.empty: return \"Nenhum fluxo de caixa para analisar.\"\n",
    "    # ... (código da função sem alterações) ...\n",
    "    df_fluxos = df_fluxos[df_fluxos['data'] >= data_base].copy()\n",
    "    df_fluxos['mes'] = df_fluxos['data'].dt.to_period('M')\n",
    "    decomposicao = df_fluxos.pivot_table(index='mes', columns='categoria', values='valor', aggfunc='sum').fillna(0)\n",
    "    start_period = pd.Timestamp(data_base).to_period('M')\n",
    "    end_period = df_fluxos['mes'].max()\n",
    "    if pd.isna(end_period): end_period = start_period\n",
    "    idx_meses = pd.period_range(start=start_period, end=end_period, freq='M')\n",
    "    decomposicao = decomposicao.reindex(idx_meses, fill_value=0)\n",
    "    colunas_principais = ['Recebimento Estoque', 'Investimentos (Fundos/RF)', 'Despesas Operacionais', 'Amortização de Cotas', 'Reinvestimento (Simulado)']\n",
    "    for col in colunas_principais:\n",
    "        if col not in decomposicao.columns: decomposicao[col] = 0\n",
    "    decomposicao['Total Entradas'] = decomposicao['Recebimento Estoque'] + decomposicao['Investimentos (Fundos/RF)']\n",
    "    decomposicao['Total Saídas'] = decomposicao['Despesas Operacionais'] + decomposicao['Amortização de Cotas'] + decomposicao['Reinvestimento (Simulado)']\n",
    "    decomposicao['Fluxo de Caixa Mês'] = decomposicao['Total Entradas'] + decomposicao['Total Saídas']\n",
    "    saldo_inicial_valor = df_fluxos[df_fluxos['categoria'] == 'Saldo Inicial']['valor'].sum()\n",
    "    decomposicao['Saldo Final'] = decomposicao['Fluxo de Caixa Mês'].cumsum() + saldo_inicial_valor\n",
    "    decomposicao['Saldo Inicial'] = decomposicao['Saldo Final'].shift(1).fillna(saldo_inicial_valor)\n",
    "    colunas_para_mostrar = ['Saldo Inicial', 'Total Entradas', 'Recebimento Estoque', 'Total Saídas', 'Reinvestimento (Simulado)', 'Despesas Operacionais', 'Amortização de Cotas', 'Fluxo de Caixa Mês', 'Saldo Final']\n",
    "    colunas_existentes = [col for col in colunas_para_mostrar if col in decomposicao.columns]\n",
    "    decomposicao_final = decomposicao[colunas_existentes].head(24)\n",
    "    return decomposicao_final.applymap(lambda x: f\"{x:,.2f}\")\n",
    "\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO ---\n",
    "# (Assumindo que os dataframes já foram carregados)\n",
    "\n",
    "df_fluxos_final = extrair_fluxos_de_caixa_final(dados_carteira_recente, df_estoque, df_despesas, SALDO_CAIXA_ALVO)\n",
    "tabela_final = criar_tabela_decomposicao(df_fluxos_final, data_referencia)\n",
    "print(tabela_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91aea58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usando carteira: carteira_52203615000119_20241101.json\n",
      "\n",
      "carregando dados de estoque...\n",
      "dados de estoque consolidados.\n",
      "\n",
      "carregando despesas...\n",
      "4 despesas carregadas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\1717109862.py:112: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  entradas_mes = estoque.groupby(pd.Grouper(key='Data Vencimento', freq='M'))['Valor Presente'].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DECOMPOSICAO MENSAL (COM SIMULACAO DE REINVESTIMENTO) ---\n",
      "taxa de reinvestimento: 52.9%\n",
      "categoria  Saldo Inicial Total Entradas Recebimento Estoque   Total Saídas Reinvestimento (Simulado) Despesas Operacionais Amortização de Cotas Fluxo de Caixa Mês    Saldo Final\n",
      "2024-11         1,000.00  46,963,837.28                0.00           0.00                      0.00                  0.00                 0.00      46,963,837.28  46,964,837.28\n",
      "2024-12    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-01    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-02    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-03    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-04    46,964,837.28           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,964,837.28\n",
      "2025-05    46,964,837.28           0.00                0.00    -228,889.26                      0.00           -228,889.26                 0.00        -228,889.26  46,735,948.02\n",
      "2025-06    46,735,948.02           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,735,948.02\n",
      "2025-07    46,735,948.02           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,735,948.02\n",
      "2025-08    46,735,948.02           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,735,948.02\n",
      "2025-09    46,735,948.02           0.00                0.00           0.00                      0.00                  0.00                 0.00               0.00  46,735,948.02\n",
      "2025-10    46,735,948.02   3,913,141.23        3,913,141.23  -2,070,051.71             -2,070,051.71                  0.00                 0.00       1,843,089.52  48,579,037.54\n",
      "2025-11    48,579,037.54   6,762,041.82        6,762,041.82  -3,577,120.12             -3,577,120.12                  0.00                 0.00       3,184,921.70  51,763,959.24\n",
      "2025-12    51,763,959.24   6,580,771.83        6,580,771.83  -3,481,228.30             -3,481,228.30                  0.00                 0.00       3,099,543.53  54,863,502.77\n",
      "2026-01    54,863,502.77   6,404,436.46        6,404,436.46  -3,387,946.89             -3,387,946.89                  0.00                 0.00       3,016,489.57  57,879,992.34\n",
      "2026-02    57,879,992.34   6,235,364.03        6,235,364.03  -3,298,507.57             -3,298,507.57                  0.00                 0.00       2,936,856.46  60,816,848.80\n",
      "2026-03    60,816,848.80   6,085,229.71        6,085,229.71  -3,219,086.51             -3,219,086.51                  0.00                 0.00       2,866,143.19  63,682,991.99\n",
      "2026-04    63,682,991.99   5,914,224.17        5,914,224.17  -3,128,624.59             -3,128,624.59                  0.00                 0.00       2,785,599.58  66,468,591.58\n",
      "2026-05    66,468,591.58   5,761,502.39        5,761,502.39  -3,047,834.76             -3,047,834.76                  0.00                 0.00       2,713,667.63  69,182,259.20\n",
      "2026-06    69,182,259.20   5,602,817.36        5,602,817.36  -2,963,890.39             -2,963,890.39                  0.00                 0.00       2,638,926.98  71,821,186.18\n",
      "2026-07    71,821,186.18   5,451,262.69        5,451,262.69  -2,883,717.97             -2,883,717.97                  0.00                 0.00       2,567,544.73  74,388,730.91\n",
      "2026-08    74,388,730.91   5,110,206.24        5,110,206.24  -2,703,299.10             -2,703,299.10                  0.00                 0.00       2,406,907.14  76,795,638.05\n",
      "2026-09    76,795,638.05   4,860,189.18        4,860,189.18  -2,571,040.08             -2,571,040.08                  0.00                 0.00       2,289,149.10  79,084,787.15\n",
      "2026-10    79,084,787.15   4,646,753.76        4,646,753.76  -2,458,132.74             -2,458,132.74                  0.00                 0.00       2,188,621.02  81,273,408.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\1717109862.py:148: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return dec_final.applymap(lambda x: f\"{x:,.2f}\")\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#%%\n",
    "#! paths !################################################################################\n",
    "path_carteiras = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "path_estoque = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "path_despesas = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "#!#######################################################################################\n",
    "# possibilidade de estimar com uma taxa constante de reinvestimento\n",
    "taxa_reinvest = 0.00 \n",
    "\n",
    "#%%\n",
    "#? funcoes de carregar os dados \n",
    "\n",
    "def load_carteira(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def load_estoque(path):\n",
    "    print(\"\\ncarregando dados de estoque...\")\n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    \n",
    "    dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    \n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        for col in float_cols:\n",
    "            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "        for col in date_cols:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "        \n",
    "        dfs.append(df)\n",
    "        \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(\"dados de estoque consolidados.\")\n",
    "    return df\n",
    "\n",
    "def load_despesas(path):\n",
    "    print(\"\\ncarregando despesas...\")\n",
    "    excel_files = glob.glob(os.path.join(path, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    \n",
    "    dfs = []\n",
    "    for file in excel_files:\n",
    "        df = pd.read_excel(file, header=6) \n",
    "        dfs.append(df)\n",
    "        \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    \n",
    "    df['Data Pagamento'] = pd.to_datetime(df['Data Pagamento'], errors='coerce')\n",
    "    df['Valor'] = pd.to_numeric(df['Valor'], errors='coerce')\n",
    "    df['Valor'] = -df['Valor'].abs() # valor fica negativo pois eh uma saida\n",
    "    \n",
    "    df = df[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "    print(f\"{len(df)} despesas carregadas.\")\n",
    "    return df\n",
    "\n",
    "#%%\n",
    "#? funcoes de calc\n",
    "\n",
    "def get_fluxos(carteira_data, estoque, despesas, reinvest_rate):\n",
    "    fluxos = []\n",
    "    base_date = datetime.strptime(carteira_data['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    # busca os saldos/investimentos iniciais\n",
    "    disp = next((a['Disponibilidade'] for a in carteira_data['ativos'] if 'Disponibilidade' in a), None)\n",
    "    if disp:\n",
    "        fluxos.append({'data': base_date, 'categoria': 'Saldo Inicial', 'valor': disp['ativos'][0]['saldo']})\n",
    "\n",
    "    cotas = next((a['Cotas'] for a in carteira_data['ativos'] if 'Cotas' in a), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': base_date, 'categoria': 'Investimentos (Fundos/RF)', 'valor': cota['valorBruto']})\n",
    "            \n",
    "    rf = next((a['RendaFixa'] for a in carteira_data['ativos'] if 'RendaFixa' in a), None)\n",
    "    if rf:\n",
    "        for titulo in rf['ativos']:\n",
    "            venc = datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d')\n",
    "            fluxos.append({'data': venc, 'categoria': 'Investimentos (Fundos/RF)', 'valor': titulo['mercadoAtual']})\n",
    "            \n",
    "    # add despesas operacionais\n",
    "    for _, row in despesas.iterrows():\n",
    "        fluxos.append({'data': row['Data Pagamento'], 'categoria': 'Despesas Operacionais', 'valor': row['Valor']})\n",
    "\n",
    "    # calcula amortizacao da cota senior\n",
    "    sr_carteira = next((c for c in carteira_data['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if sr_carteira:\n",
    "        pl_sr = sr_carteira['pl']\n",
    "        amort_val = (pl_sr / 36) * -1\n",
    "        amort_date = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            pay_date = amort_date + relativedelta(months=i)\n",
    "            while pay_date.weekday() >= 5: pay_date += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': pay_date, 'categoria': 'Amortização de Cotas', 'valor': amort_val})\n",
    "    \n",
    "    # adiciona recebimentos e reinvestimentos do estoque\n",
    "    estoque = estoque.dropna(subset=['Data Vencimento'])\n",
    "    estoque = estoque[estoque['Status'] == 'A vencer']\n",
    "    for _, row in estoque.iterrows():\n",
    "        fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Recebimento Estoque', 'valor': row['Valor Presente']})\n",
    "        \n",
    "    entradas_mes = estoque.groupby(pd.Grouper(key='Data Vencimento', freq='M'))['Valor Presente'].sum()\n",
    "    for data, total in entradas_mes.items():\n",
    "        reinvest_val = total * reinvest_rate * -1\n",
    "        if reinvest_val != 0:\n",
    "            fluxos.append({'data': data, 'categoria': 'Reinvestimento (Simulado)','valor': reinvest_val})\n",
    "\n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "def make_dec_table(fluxos, base_date):\n",
    "    fluxos = fluxos[fluxos['data'] >= base_date].copy()\n",
    "    fluxos['mes'] = fluxos['data'].dt.to_period('M')\n",
    "    \n",
    "    dec = fluxos.pivot_table(index='mes', columns='categoria', values='valor', aggfunc='sum').fillna(0)\n",
    "    \n",
    "    start_p = pd.Timestamp(base_date).to_period('M')\n",
    "    end_p = fluxos['mes'].max()\n",
    "    idx_meses = pd.period_range(start=start_p, end=end_p, freq='M')\n",
    "    dec = dec.reindex(idx_meses, fill_value=0)\n",
    "    \n",
    "    # garante que as colunas principais existem\n",
    "    main_cols = ['Recebimento Estoque', 'Investimentos (Fundos/RF)', 'Despesas Operacionais', 'Amortização de Cotas', 'Reinvestimento (Simulado)']\n",
    "    for col in main_cols:\n",
    "        if col not in dec.columns: dec[col] = 0\n",
    "\n",
    "    dec['Total Entradas'] = dec['Recebimento Estoque'] + dec.get('Investimentos (Fundos/RF)', 0)\n",
    "    dec['Total Saídas'] = dec['Despesas Operacionais'] + dec['Amortização de Cotas'] + dec['Reinvestimento (Simulado)']\n",
    "    dec['Fluxo de Caixa Mês'] = dec['Total Entradas'] + dec['Total Saídas']\n",
    "    \n",
    "    saldo_ini_val = fluxos[fluxos['categoria'] == 'Saldo Inicial']['valor'].sum()\n",
    "    dec['Saldo Final'] = dec['Fluxo de Caixa Mês'].cumsum() + saldo_ini_val\n",
    "    dec['Saldo Inicial'] = dec['Saldo Final'].shift(1).fillna(saldo_ini_val)\n",
    "    \n",
    "    cols_ordem = ['Saldo Inicial', 'Total Entradas', 'Recebimento Estoque', 'Total Saídas', 'Reinvestimento (Simulado)', 'Despesas Operacionais', 'Amortização de Cotas', 'Fluxo de Caixa Mês', 'Saldo Final']\n",
    "    cols_final = [col for col in cols_ordem if col in dec.columns]\n",
    "    \n",
    "    dec_final = dec[cols_final].head(24)\n",
    "    return dec_final.applymap(lambda x: f\"{x:,.2f}\")\n",
    "\n",
    "#%%\n",
    "# main >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# carrega os dados\n",
    "carteira_files = glob.glob(os.path.join(path_carteiras, \"*.json\"))\n",
    "latest_file = max(carteira_files, key=os.path.getctime)\n",
    "print(f\"usando carteira: {os.path.basename(latest_file)}\")\n",
    "\n",
    "carteira_data = load_carteira(latest_file)\n",
    "estoque = load_estoque(path_estoque)\n",
    "despesas = load_despesas(path_despesas)\n",
    "\n",
    "# gero os fluxos e a tabela final ############################\n",
    "ref_date = datetime.strptime(carteira_data['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "fluxos = get_fluxos(carteira_data, estoque, despesas, taxa_reinvest)\n",
    "dec_table = make_dec_table(fluxos, ref_date)\n",
    "\n",
    "# imprime o resultado\n",
    "print(\"\\n--- DECOMPOSICAO MENSAL  ---\")\n",
    "print(f\"taxa de reinvestimento: {taxa_reinvest:.1%}\")\n",
    "print(dec_table.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e85603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20250818.json\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (FORMATO SOLICITADO) ---\n",
      "      Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque     Despesas Amort./ Resgat. Cota Disponibilidades Necessidades Caixa Projetado\n",
      "Prazo                                                                                                                                              \n",
      "D+0      1,000.00        0.00               0.00               0.00  -228,889.26                 0.00         1,000.00  -228,889.26     -227,889.26\n",
      "D+1      1,000.00  661,422.32               0.00               0.00  -228,889.26                 0.00       662,422.32  -228,889.26      433,533.06\n",
      "D+5      1,000.00  661,422.32               0.00               0.00  -228,889.26                 0.00       662,422.32  -228,889.26      433,533.06\n",
      "D+10     1,000.00  661,422.32               0.00               0.00  -228,889.26                 0.00       662,422.32  -228,889.26      433,533.06\n",
      "D+21     1,000.00  661,422.32               0.00               0.00  -228,889.26                 0.00       662,422.32  -228,889.26      433,533.06\n",
      "D+63     1,000.00  661,422.32               0.00       2,263,227.25  -228,889.26                 0.00     2,925,649.57  -228,889.26    2,696,760.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\1784773212.py:165: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_relatorio.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS PARA AS FONTES DE DADOS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (sem alterações) ---\n",
    "# (As funções carregar_dados_carteira, processar_dados_estoque, e\n",
    "# processar_dados_despesas que já usamos antes entram aqui. Omitidas para brevidade.)\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (COM A CORREÇÃO EM processar_dados_estoque) ---\n",
    "\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"\\nCarregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv:\n",
    "        print(f\"AVISO: Nenhum arquivo CSV de estoque encontrado em {caminho_pasta}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                \n",
    "                # ### CORREÇÃO DO BUG ESTÁ AQUI ###\n",
    "                # Mantém todas as colunas do DataFrame, em vez de selecionar apenas duas\n",
    "                all_dfs.append(df)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    \n",
    "    if not all_dfs:\n",
    "        print(\"Nenhum dado de estoque foi carregado.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Dados de estoque consolidados com sucesso.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    print(\"\\nCarregando e consolidando arquivos de despesas...\")\n",
    "    # ... (função completa sem alterações)\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame()\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception as e: print(f\"Erro ao ler o arquivo de despesa {os.path.basename(arquivo)}: {e}\")\n",
    "    if not lista_df_despesas: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "    df_final = df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "    print(f\"{len(df_final)} despesas com data de pagamento foram carregadas.\")\n",
    "    return df_final\n",
    "\n",
    "# --- NOVA LÓGICA DE GERAÇÃO DO RELATÓRIO ---\n",
    "\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    \"\"\"\n",
    "    Cria uma lista de TODOS os eventos de fluxo de caixa futuros,\n",
    "    categorizados exatamente como na tabela do chefe.\n",
    "    \"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # Disponibilidades\n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        fluxos.append({'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            # Assumindo liquidez D+1 para fundos\n",
    "            fluxos.append({'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': cota['valorBruto']})\n",
    "            \n",
    "    renda_fixa = next((a['RendaFixa'] for a in dados_carteira_recente['ativos'] if 'RendaFixa' in a and a['RendaFixa']), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': titulo['mercadoAtual']})\n",
    "\n",
    "    # Pagamentos do Estoque\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente'])\n",
    "        estoque_valido = estoque_valido[estoque_valido['Status'] == 'A vencer']\n",
    "        for _, row in estoque_valido.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Pagamentos Estoque', 'valor': row['Valor Presente']})\n",
    "\n",
    "    # Necessidades\n",
    "    if not df_despesas_datadas.empty:\n",
    "        for _, despesa in df_despesas_datadas.iterrows():\n",
    "            fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas', 'valor': despesa['Valor']})\n",
    "\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5:\n",
    "                data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "\n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "def gerar_relatorio_d_mais(df_fluxos, data_base):\n",
    "    \"\"\"\n",
    "    Gera a tabela final no formato D+N solicitado pelo chefe.\n",
    "    \"\"\"\n",
    "    prazos = [0, 1, 5, 10, 21, 63]\n",
    "    colunas_relatorio = ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
    "    \n",
    "    linhas_relatorio = []\n",
    "\n",
    "    for dias in prazos:\n",
    "        data_limite = data_base + timedelta(days=dias)\n",
    "        \n",
    "        # Filtra todos os eventos de caixa que ocorrem ATÉ a data limite\n",
    "        fluxos_ate_data = df_fluxos[df_fluxos['data'] <= data_limite]\n",
    "        \n",
    "        # Agrupa por categoria e soma os valores acumulados\n",
    "        saldos_acumulados = fluxos_ate_data.groupby('categoria')['valor'].sum()\n",
    "        \n",
    "        # Cria a linha do relatório\n",
    "        linha = {'Prazo': f\"D+{dias}\"}\n",
    "        for col in colunas_relatorio:\n",
    "            linha[col] = saldos_acumulados.get(col, 0.0)\n",
    "        \n",
    "        linhas_relatorio.append(linha)\n",
    "        \n",
    "    df_relatorio = pd.DataFrame(linhas_relatorio).set_index('Prazo')\n",
    "    \n",
    "    # Adiciona as colunas de totais e saldo final\n",
    "    df_relatorio['Disponibilidades'] = df_relatorio['Conta Corr.'] + df_relatorio['Fundo inv.'] + df_relatorio['Títulos Renda Fixa'] + df_relatorio['Pagamentos Estoque']\n",
    "    df_relatorio['Necessidades'] = df_relatorio['Despesas'] + df_relatorio['Amort./ Resgat. Cota']\n",
    "    df_relatorio['Caixa Projetado'] = df_relatorio['Disponibilidades'] + df_relatorio['Necessidades'] # Necessidades já são negativas\n",
    "    \n",
    "    return df_relatorio.applymap('{:,.2f}'.format)\n",
    "\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Carrega os dados (substitua os placeholders pelas funções completas)\n",
    "    #df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    #df_despesas = processar_dados_despesas(PATH_DESPESAS)\n",
    "    \n",
    "    # Encontra o arquivo de carteira mais recente\n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(f\"ERRO: Nenhum arquivo de carteira encontrado.\")\n",
    "        exit()\n",
    "    arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "    print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_recente)}\")\n",
    "\n",
    "    dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "    data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    # Prepara a lista de todos os eventos de fluxo de caixa futuros\n",
    "    # (Use seus DataFrames já carregados aqui)\n",
    "    df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "    \n",
    "    # Gera o relatório no formato D+N\n",
    "    relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "\n",
    "    print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (FORMATO SOLICITADO) ---\")\n",
    "    print(relatorio_final.to_string())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee0a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serao buscadas as carteiras de 14 dias.\n",
      "periodo: de 2025-08-16 (16/08/2025) a 2025-08-29 (29/08/2025)\n",
      "gerando token jwt com o final: ...04f559\n",
      ">>> token jwt gerado com sucesso.\n",
      "\n",
      "buscando carteira para 2025-08-29\n",
      "-> carteira de 2025-08-29 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250829.json'\n",
      "\n",
      "buscando carteira para 2025-08-28\n",
      "-> carteira de 2025-08-28 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250828.json'\n",
      "\n",
      "buscando carteira para 2025-08-27\n",
      "-> carteira de 2025-08-27 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250827.json'\n",
      "\n",
      "buscando carteira para 2025-08-26\n",
      "-> carteira de 2025-08-26 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250826.json'\n",
      "\n",
      "buscando carteira para 2025-08-25\n",
      "-> carteira de 2025-08-25 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250825.json'\n",
      "\n",
      "buscando carteira para 2025-08-24\n",
      "falha ao obter carteira de 2025-08-24. status: 500\n",
      "problema ao obter a carteira para 2025-08-24. continuando...\n",
      "\n",
      "buscando carteira para 2025-08-23\n",
      "falha ao obter carteira de 2025-08-23. status: 500\n",
      "problema ao obter a carteira para 2025-08-23. continuando...\n",
      "\n",
      "buscando carteira para 2025-08-22\n",
      "-> carteira de 2025-08-22 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250822.json'\n",
      "\n",
      "buscando carteira para 2025-08-21\n",
      "-> carteira de 2025-08-21 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250821.json'\n",
      "\n",
      "buscando carteira para 2025-08-20\n",
      "-> carteira de 2025-08-20 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250820.json'\n",
      "\n",
      "buscando carteira para 2025-08-19\n",
      "-> carteira de 2025-08-19 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250819.json'\n",
      "\n",
      "buscando carteira para 2025-08-18\n",
      "-> carteira de 2025-08-18 salva em: 'C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\\carteira_52203615000119_20250818.json'\n",
      "\n",
      "buscando carteira para 2025-08-17\n",
      "falha ao obter carteira de 2025-08-17. status: 500\n",
      "problema ao obter a carteira para 2025-08-17. continuando...\n",
      "\n",
      "buscando carteira para 2025-08-16\n",
      "falha ao obter carteira de 2025-08-16. status: 500\n",
      "problema ao obter a carteira para 2025-08-16. continuando...\n",
      "\n",
      "--- downloads concluidos ---\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# imports\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "\n",
    "#%%\n",
    "# --- configuracoes ---\n",
    "cnpjs = [\"52203615000119\"]\n",
    "tokens = [\n",
    "    \"96cc2224-0c2f-454f-b785-db8dd204f559\",\n",
    "    \"d1bd877a-8b21-4c29-b005-dd5540d38673\",\n",
    "    \"ad647ac8-188d-4d50-a6ff-6ef2524ac3ca\"\n",
    "]\n",
    "cpf = \"10142836982\"\n",
    "pasta_saida = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "url_auth = \"https://apis.vortx.com.br/vxlogin/api/user/AuthUserApi\"\n",
    "url_base = \"https://apis.vortx.com.br\"\n",
    "\n",
    "#%%\n",
    "# --- funcoes ---\n",
    "\n",
    "def gerar_jwt(token_acesso, cpf_usuario):\n",
    "    \"\"\"tenta gerar um token de autenticacao temporario.\"\"\"\n",
    "    print(f\"gerando token jwt com o final: ...{token_acesso[-6:]}\")\n",
    "    payload = {\"token\": token_acesso, \"login\": cpf_usuario}\n",
    "    try:\n",
    "        r = requests.post(url_auth, json=payload, timeout=15)\n",
    "        if r.status_code == 200:\n",
    "            jwt = r.json().get(\"token\")\n",
    "            if jwt:\n",
    "                print(\">>> token jwt gerado com sucesso.\")\n",
    "                return jwt\n",
    "        print(f\"falha na autenticacao. status: {r.status_code}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"erro de conexao ao autenticar: {e}\")\n",
    "        return None\n",
    "\n",
    "def obter_carteira(jwt, cnpjs_lista, data_str, pasta):\n",
    "    \"\"\"busca e salva o arquivo json da carteira para uma data especifica.\"\"\"\n",
    "    print(f\"\\nbuscando carteira para {data_str}\")\n",
    "    url = f\"{url_base}/carteira-liberada/buscarCarteiraJSON\"\n",
    "    headers = {\"Authorization\": f\"Bearer {jwt}\"}\n",
    "    params = {\"cnpjFundos[]\": cnpjs_lista, \"dataCarteira\": data_str}\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, params=params, timeout=45)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"falha ao obter carteira de {data_str}. status: {r.status_code}\")\n",
    "            return False\n",
    "\n",
    "        dados = r.json()\n",
    "        \n",
    "        if not dados or not dados[0].get('carteiras'):\n",
    "            print(f\"aviso: dados da carteira para {data_str} vieram vazios. pulando.\")\n",
    "            return False\n",
    "\n",
    "        cnpjs_str = \"_\".join(cnpjs_lista)\n",
    "        nome_arquivo = f\"carteira_{cnpjs_str}_{data_str.replace('-', '')}.json\"\n",
    "        caminho = os.path.join(pasta, nome_arquivo)\n",
    "\n",
    "        with open(caminho, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dados, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"-> carteira de {data_str} salva em: '{caminho}'\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"erro de conexao ao buscar a carteira de {data_str}: {e}\")\n",
    "        return False\n",
    "\n",
    "#%%\n",
    "# --- execucao ---\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(pasta_saida, exist_ok=True) \n",
    "\n",
    "    # --- ALTERACAO PRINCIPAL AQUI ---\n",
    "    # gera a lista de datas para um periodo de 2 semanas terminando em 29/08/2025\n",
    "    datas = []\n",
    "    data_final = date(2025, 8, 29) # data final fixa, conforme solicitado\n",
    "    # comecamos 13 dias antes para ter um periodo total de 14 dias\n",
    "    data_inicial = data_final - timedelta(days=13) \n",
    "    \n",
    "    d = data_inicial\n",
    "    while d <= data_final:\n",
    "        datas.append(d.strftime(\"%Y-%m-%d\"))\n",
    "        d += timedelta(days=1)\n",
    "    \n",
    "    # invertemos para comecar pela data mais recente\n",
    "    datas.reverse()\n",
    "    \n",
    "    print(f\"serao buscadas as carteiras de {len(datas)} dias.\")\n",
    "    print(f\"periodo: de {datas[-1]} (16/08/2025) a {datas[0]} (29/08/2025)\")\n",
    "\n",
    "    jwt = None\n",
    "    # tenta obter um token jwt valido\n",
    "    for token in tokens:\n",
    "        jwt = gerar_jwt(token, cpf)\n",
    "        if jwt:\n",
    "            break\n",
    "    \n",
    "    if not jwt:\n",
    "        print(\"\\n-> todas as tentativas de autenticacao falharam. fim do script.\")\n",
    "        exit()\n",
    "\n",
    "    # itera sobre as datas e baixa cada carteira\n",
    "    for data_carteira in datas:\n",
    "        ok = obter_carteira(jwt, cnpjs, data_carteira, pasta_saida)\n",
    "        if not ok:\n",
    "            print(f\"problema ao obter a carteira para {data_carteira}. continuando...\")\n",
    "        time.sleep(2) # pausa de 2s para nao sobrecarregar a api\n",
    "\n",
    "    print(\"\\n--- downloads concluidos ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6abf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INSPECIONANDO DADOS DA CARTEIRA ---\n",
      "Arquivo de carteira mais recente: carteira_52203615000119_20250818.json\n",
      "DATA DE REFERÊNCIA PARA A PROJEÇÃO (D+0): 18/08/2025\n",
      "--------------------------------------------------\n",
      "\n",
      "--- INSPECIONANDO DADOS DE ESTOQUE ---\n",
      "\n",
      "Formato do Estoque: 1644304 linhas, 33 colunas.\n",
      "\n",
      "Amostra dos dados de Estoque:\n",
      "  Data Vencimento  Valor Presente    Status\n",
      "0      2027-05-04        424.0903  A vencer\n",
      "1      2026-07-04        504.5277  A vencer\n",
      "2      2029-09-04        315.1219  A vencer\n",
      "3      2026-01-04        122.1097  A vencer\n",
      "4      2026-06-04        111.3383  A vencer\n",
      "\n",
      "Intervalo de datas no Estoque:\n",
      "  - Data de Vencimento Mais Antiga: 02/03/2024\n",
      "  - Data de Vencimento Mais Recente: 26/10/2033\n",
      "--------------------------------------------------\n",
      "\n",
      "--- INSPECIONANDO DADOS DE DESPESAS ---\n",
      "\n",
      "Formato das Despesas: 146 linhas, 3 colunas.\n",
      "\n",
      "Amostra dos dados de Despesas:\n",
      "  Data Pagamento     Categoria      Valor\n",
      "0     2025-05-09  PROV ADM      -26221.07\n",
      "1     2025-05-09  PROV GESTÃO  -119712.02\n",
      "2     2025-05-09  PROV GESTÃO2  -80771.25\n",
      "3     2025-05-09  TX ESCRT FIX   -2184.92\n",
      "4     2025-05-09  PROV ADM      -23781.26\n",
      "\n",
      "Intervalo de datas nas Despesas:\n",
      "  - Data de Pagamento Mais Antiga: 09/05/2025\n",
      "  - Data de Pagamento Mais Recente: 08/07/2025\n",
      "\n",
      "==================================================\n",
      "ANÁLISE PRELIMINAR:\n",
      "Compare os intervalos de datas acima com a 'DATA DE REFERÊNCIA'.\n",
      "Se as datas de vencimento/pagamento estiverem muito distantes da data de referência, elas não aparecerão na projeção de curto prazo (D+0 a D+63).\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CAMINHOS (sem alterações) ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (copiadas do seu script para garantir consistência) ---\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"\\n--- INSPECIONANDO DADOS DE ESTOQUE ---\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv:\n",
    "        print(\"Nenhum arquivo CSV de estoque encontrado.\")\n",
    "        return pd.DataFrame()\n",
    "    # ... (código da função omitido para brevidade, a lógica é a mesma)\n",
    "    all_dfs = []\n",
    "    float_cols = ['Valor Aquisicao', 'Valor Nominal', 'Valor Presente', 'PDD Vencido','PDD Total', 'Taxa Operada Originador', 'CET Mensal', 'Taxa CCB','Taxa Originador Split', 'Taxa Split FIDC']\n",
    "    date_cols = ['Data Aquisicao', 'Data Vencimento', 'Data Referencia', 'Data de Nascimento']\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                for col in float_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                for col in date_cols:\n",
    "                    if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    df_final = pd.concat(all_dfs, ignore_index=True)\n",
    "    return df_final\n",
    "\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    print(\"\\n--- INSPECIONANDO DADOS DE DESPESAS ---\")\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel:\n",
    "        print(\"Nenhum arquivo 'Despesas_Consolidadas.xlsx' encontrado.\")\n",
    "        return pd.DataFrame()\n",
    "    # ... (código da função omitido para brevidade, a lógica é a mesma)\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception as e: print(f\"Erro ao ler o arquivo de despesa {os.path.basename(arquivo)}: {e}\")\n",
    "    if not lista_df_despesas: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "    df_final = df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO DA DEPURAÇÃO ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Depuração da Carteira\n",
    "    print(\"--- INSPECIONANDO DADOS DA CARTEIRA ---\")\n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(\"Nenhum arquivo de carteira encontrado.\")\n",
    "    else:\n",
    "        arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "        dados_carteira = carregar_dados_carteira(arquivo_recente)\n",
    "        data_referencia = datetime.strptime(dados_carteira['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "        print(f\"Arquivo de carteira mais recente: {os.path.basename(arquivo_recente)}\")\n",
    "        print(f\"DATA DE REFERÊNCIA PARA A PROJEÇÃO (D+0): {data_referencia.strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 2. Depuração do Estoque\n",
    "    df_estoque_debug = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    if not df_estoque_debug.empty:\n",
    "        print(f\"\\nFormato do Estoque: {df_estoque_debug.shape[0]} linhas, {df_estoque_debug.shape[1]} colunas.\")\n",
    "        print(\"\\nAmostra dos dados de Estoque:\")\n",
    "        print(df_estoque_debug[['Data Vencimento', 'Valor Presente', 'Status']].head())\n",
    "        print(\"\\nIntervalo de datas no Estoque:\")\n",
    "        print(f\"  - Data de Vencimento Mais Antiga: {df_estoque_debug['Data Vencimento'].min().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"  - Data de Vencimento Mais Recente: {df_estoque_debug['Data Vencimento'].max().strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 3. Depuração das Despesas\n",
    "    df_despesas_debug = processar_dados_despesas(PATH_DESPESAS)\n",
    "    if not df_despesas_debug.empty:\n",
    "        print(f\"\\nFormato das Despesas: {df_despesas_debug.shape[0]} linhas, {df_despesas_debug.shape[1]} colunas.\")\n",
    "        print(\"\\nAmostra dos dados de Despesas:\")\n",
    "        print(df_despesas_debug.head())\n",
    "        print(\"\\nIntervalo de datas nas Despesas:\")\n",
    "        print(f\"  - Data de Pagamento Mais Antiga: {df_despesas_debug['Data Pagamento'].min().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"  - Data de Pagamento Mais Recente: {df_despesas_debug['Data Pagamento'].max().strftime('%d/%m/%Y')}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ANÁLISE PRELIMINAR:\")\n",
    "    print(\"Compare os intervalos de datas acima com a 'DATA DE REFERÊNCIA'.\")\n",
    "    print(\"Se as datas de vencimento/pagamento estiverem muito distantes da data de referência, elas não aparecerão na projeção de curto prazo (D+0 a D+63).\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18578452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "--- DEPURAÇÃO FINAL: INSPECIONANDO A 'LISTA MESTRA' DE FLUXOS DE CAIXA ---\n",
      "==================================================\n",
      "\n",
      "Total de eventos de caixa encontrados: 1552972\n",
      "\n",
      "--- Análise por Categoria ---\n",
      "\n",
      "Categorias encontradas na lista: ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
      "--------------------\n",
      "Analisando Categoria: 'Conta Corr.'\n",
      ">>> 1 eventos encontrados.\n",
      "Amostra:\n",
      "        data    categoria   valor\n",
      "0 2025-08-18  Conta Corr.  1000.0\n",
      "Intervalo de Datas: de 18/08/2025 a 18/08/2025\n",
      "--------------------\n",
      "Analisando Categoria: 'Fundo inv.'\n",
      ">>> 1 eventos encontrados.\n",
      "Amostra:\n",
      "        data   categoria      valor\n",
      "1 2025-08-19  Fundo inv.  661422.32\n",
      "Intervalo de Datas: de 19/08/2025 a 19/08/2025\n",
      "--------------------\n",
      "Analisando Categoria: 'Pagamentos Estoque'\n",
      ">>> 1552929 eventos encontrados.\n",
      "Amostra:\n",
      "        data           categoria     valor\n",
      "3 2027-05-04  Pagamentos Estoque  424.0903\n",
      "4 2026-07-04  Pagamentos Estoque  504.5277\n",
      "5 2029-09-04  Pagamentos Estoque  315.1219\n",
      "6 2026-01-04  Pagamentos Estoque  122.1097\n",
      "7 2026-06-04  Pagamentos Estoque  111.3383\n",
      "Intervalo de Datas: de 16/10/2025 a 26/10/2033\n",
      "--------------------\n",
      "Analisando Categoria: 'Despesas'\n",
      ">>> 4 eventos encontrados.\n",
      "Amostra:\n",
      "              data categoria      valor\n",
      "1552932 2025-05-09  Despesas  -26221.07\n",
      "1552933 2025-05-09  Despesas -119712.02\n",
      "1552934 2025-05-09  Despesas  -80771.25\n",
      "1552935 2025-05-09  Despesas   -2184.92\n",
      "Intervalo de Datas: de 09/05/2025 a 09/05/2025\n",
      "--------------------\n",
      "Analisando Categoria: 'Amort./ Resgat. Cota'\n",
      ">>> 36 eventos encontrados.\n",
      "Amostra:\n",
      "              data             categoria         valor\n",
      "1552936 2026-01-16  Amort./ Resgat. Cota -3.087009e+06\n",
      "1552937 2026-02-16  Amort./ Resgat. Cota -3.087009e+06\n",
      "1552938 2026-03-16  Amort./ Resgat. Cota -3.087009e+06\n",
      "1552939 2026-04-16  Amort./ Resgat. Cota -3.087009e+06\n",
      "1552940 2026-05-18  Amort./ Resgat. Cota -3.087009e+06\n",
      "Intervalo de Datas: de 16/01/2026 a 18/12/2028\n",
      "\n",
      "==================================================\n",
      "--- INVESTIGAÇÃO EXTRA: FILTRO DE STATUS DO ESTOQUE ---\n",
      "==================================================\n",
      "Status das parcelas de estoque que vencem nos próximos 63 dias:\n",
      "Status\n",
      "Vencido     27778\n",
      "Previsto    16959\n",
      "A vencer     7849\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS (sem alterações) ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO DA DEPURAÇÃO FINAL ---\n",
    "# (Assumindo que você já tem as funções de carregamento definidas na sua sessão)\n",
    "\n",
    "# 1. Carrega todos os dados#\n",
    "df_estoque_completo = df_estoque\n",
    "df_despesas_completo = df_despesas\n",
    "arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "# 2. Gera a \"Lista Mestra\" de fluxos de caixa\n",
    "df_fluxos_detalhados = preparar_fluxos_detalhados(\n",
    "    dados_carteira_recente, \n",
    "    df_estoque_completo, \n",
    "    df_despesas_completo\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- DEPURAÇÃO FINAL: INSPECIONANDO A 'LISTA MESTRA' DE FLUXOS DE CAIXA ---\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if df_fluxos_detalhados.empty:\n",
    "    print(\"\\nAVISO: A lista mestra de fluxos de caixa está vazia. Nenhum evento foi adicionado.\")\n",
    "else:\n",
    "    print(f\"\\nTotal de eventos de caixa encontrados: {len(df_fluxos_detalhados)}\")\n",
    "    \n",
    "    print(\"\\n--- Análise por Categoria ---\")\n",
    "    \n",
    "    # Verifica cada categoria e mostra uma amostra\n",
    "    categorias = df_fluxos_detalhados['categoria'].unique()\n",
    "    \n",
    "    print(f\"\\nCategorias encontradas na lista: {list(categorias)}\")\n",
    "    \n",
    "    for cat in ['Conta Corr.', 'Fundo inv.', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']:\n",
    "        print(\"-\" * 20)\n",
    "        print(f\"Analisando Categoria: '{cat}'\")\n",
    "        df_cat = df_fluxos_detalhados[df_fluxos_detalhados['categoria'] == cat]\n",
    "        \n",
    "        if df_cat.empty:\n",
    "            print(\">>> Nenhum evento encontrado para esta categoria.\")\n",
    "        else:\n",
    "            print(f\">>> {len(df_cat)} eventos encontrados.\")\n",
    "            print(\"Amostra:\")\n",
    "            print(df_cat.head())\n",
    "            print(f\"Intervalo de Datas: de {df_cat['data'].min().strftime('%d/%m/%Y')} a {df_cat['data'].max().strftime('%d/%m/%Y')}\")\n",
    "\n",
    "# Análise específica do filtro de Status do Estoque\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- INVESTIGAÇÃO EXTRA: FILTRO DE STATUS DO ESTOQUE ---\")\n",
    "print(\"=\"*50)\n",
    "if not df_estoque_completo.empty:\n",
    "    data_limite_curto_prazo = data_referencia + timedelta(days=63)\n",
    "    \n",
    "    estoque_curto_prazo = df_estoque_completo[\n",
    "        (df_estoque_completo['Data Vencimento'] >= data_referencia) &\n",
    "        (df_estoque_completo['Data Vencimento'] <= data_limite_curto_prazo)\n",
    "    ]\n",
    "    \n",
    "    if estoque_curto_prazo.empty:\n",
    "        print(\"Nenhum pagamento de estoque programado para os próximos 63 dias.\")\n",
    "    else:\n",
    "        print(\"Status das parcelas de estoque que vencem nos próximos 63 dias:\")\n",
    "        print(estoque_curto_prazo['Status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c58dabbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20250818.json\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (VERSÃO FINAL CORRIGIDA) ---\n",
      "       Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque Despesas Amort./ Resgat. Cota Disponibilidades     Necessidades Caixa Projetado\n",
      "Prazo                                                                                                                                               \n",
      "D+0       1,000.00        0.00               0.00      11,038,307.04     0.00                 0.00    11,039,307.04             0.00   11,039,307.04\n",
      "D+1       1,000.00  661,422.32               0.00      11,059,373.74     0.00                 0.00    11,721,796.06             0.00   11,721,796.06\n",
      "D+5       1,000.00  661,422.32               0.00      12,759,984.37     0.00                 0.00    13,422,406.69             0.00   13,422,406.69\n",
      "D+10      1,000.00  661,422.32               0.00      13,406,135.03     0.00                 0.00    14,068,557.35             0.00   14,068,557.35\n",
      "D+21      1,000.00  661,422.32               0.00      14,060,107.05     0.00                 0.00    14,722,529.37             0.00   14,722,529.37\n",
      "D+63      1,000.00  661,422.32               0.00      25,637,441.20     0.00                 0.00    26,299,863.52             0.00   26,299,863.52\n",
      "D+1200    1,000.00  661,422.32               0.00     174,634,821.10     0.00      -108,045,302.10   175,297,243.42  -108,045,302.10   67,251,941.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\1338505837.py:132: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_relatorio.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS PARA AS FONTES DE DADOS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO (Completas) ---\n",
    "def carregar_dados_carteira(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)[0]\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"Carregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                df['Valor Presente'] = pd.to_numeric(df['Valor Presente'].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                df['Data Vencimento'] = pd.to_datetime(df['Data Vencimento'], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception as e: print(f\"Erro ao processar o arquivo de estoque {os.path.basename(file)}: {e}\")\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    print(\"Carregando e consolidando arquivos de despesas...\")\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame()\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception as e: print(f\"Erro ao ler o arquivo de despesa {os.path.basename(arquivo)}: {e}\")\n",
    "    if not lista_df_despesas: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "    return df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "\n",
    "# --- FUNÇÃO DE PREPARAÇÃO DE FLUXOS (COM FILTRO CORRIGIDO) ---\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # Disponibilidades\n",
    "    disponibilidade = next((a['Disponibilidade'] for a in dados_carteira_recente['ativos'] if 'Disponibilidade' in a and a['Disponibilidade']), None)\n",
    "    if disponibilidade:\n",
    "        fluxos.append({'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "\n",
    "    cotas = next((a['Cotas'] for a in dados_carteira_recente['ativos'] if 'Cotas' in a and a['Cotas']), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': cota['valorBruto']})\n",
    "            \n",
    "    # Pagamentos do Estoque (COM FILTRO CORRIGIDO)\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente', 'Status'])\n",
    "        \n",
    "        # ### A CORREÇÃO ESTÁ AQUI ###\n",
    "        # Inclui todos os status que representam uma entrada de caixa esperada\n",
    "        status_a_incluir = ['A vencer', 'Previsto', 'Vencido']\n",
    "        estoque_filtrado = estoque_valido[estoque_valido['Status'].isin(status_a_incluir)]\n",
    "        \n",
    "        for _, row in estoque_filtrado.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Pagamentos Estoque', 'valor': row['Valor Presente']})\n",
    "\n",
    "    # Necessidades (apenas as que vencem no futuro)\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base]\n",
    "        for _, despesa in despesas_futuras.iterrows():\n",
    "            fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas', 'valor': despesa['Valor']})\n",
    "            \n",
    "    # Amortização de cotas (não muda)\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "            \n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "# --- FUNÇÃO DE GERAÇÃO DO RELATÓRIO (sem alterações) ---\n",
    "def gerar_relatorio_d_mais(df_fluxos, data_base):\n",
    "    \"\"\"\n",
    "    Gera a tabela final no formato D+N solicitado pelo chefe.\n",
    "    \"\"\"\n",
    "    # ### ALTERAÇÃO AQUI: Adicione um prazo longo para o teste ###\n",
    "    prazos = [0, 1, 5, 10, 21, 63, 1200] # Adicionamos 1200 dias\n",
    "    # ###########################################################\n",
    "    \n",
    "    colunas_relatorio = ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
    "    \n",
    "    linhas_relatorio = []\n",
    "\n",
    "    for dias in prazos:\n",
    "        data_limite = data_base + timedelta(days=dias)\n",
    "        \n",
    "        fluxos_ate_data = df_fluxos[df_fluxos['data'] <= data_limite]\n",
    "        saldos_acumulados = fluxos_ate_data.groupby('categoria')['valor'].sum()\n",
    "        \n",
    "        linha = {'Prazo': f\"D+{dias}\"}\n",
    "        for col in colunas_relatorio:\n",
    "            linha[col] = saldos_acumulados.get(col, 0.0)\n",
    "        \n",
    "        linhas_relatorio.append(linha)\n",
    "        \n",
    "    df_relatorio = pd.DataFrame(linhas_relatorio).set_index('Prazo')\n",
    "    \n",
    "    df_relatorio['Disponibilidades'] = df_relatorio['Conta Corr.'] + df_relatorio['Fundo inv.'] + df_relatorio['Títulos Renda Fixa'] + df_relatorio['Pagamentos Estoque']\n",
    "    df_relatorio['Necessidades'] = df_relatorio['Despesas'] + df_relatorio['Amort./ Resgat. Cota']\n",
    "    df_relatorio['Caixa Projetado'] = df_relatorio['Disponibilidades'] + df_relatorio['Necessidades']\n",
    "    \n",
    "    return df_relatorio.applymap('{:,.2f}'.format)\n",
    "# --- BLOCO DE EXECUÇÃO FINAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    #df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    #df_despesas = processar_dados_despesas(PATH_DESPESAS)\n",
    "    \n",
    "    arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "    if not arquivos_carteira:\n",
    "        print(\"ERRO: Nenhum arquivo de carteira encontrado.\")\n",
    "        exit()\n",
    "    arquivo_recente = max(arquivos_carteira, key=os.path.getctime)\n",
    "    print(f\"\\nUsando a carteira mais recente para a projeção: {os.path.basename(arquivo_recente)}\")\n",
    "\n",
    "    dados_carteira_recente = carregar_dados_carteira(arquivo_recente)\n",
    "    data_referencia = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "    \n",
    "    relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "\n",
    "    print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (VERSÃO FINAL CORRIGIDA) ---\")\n",
    "    print(relatorio_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac558b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DEPURAÇÃO CORRIGIDA: Encontrando o arquivo de carteira pela data interna ---\n",
      "Analisando 10 arquivos para encontrar o mais recente...\n",
      "\n",
      "------------------------------------------------------------------\n",
      "✅ Arquivo mais recente encontrado (pela data interna): carteira_52203615000119_20250829.json\n",
      "Data do Relatório (D+0): 29/08/2025\n",
      "------------------------------------------------------------------\n",
      "\n",
      "--- Inspecionando o conteúdo deste arquivo para 'RendaFixa' ---\n",
      "\n",
      "✅ SUCESSO: A seção 'RendaFixa' foi encontrada no arquivo!\n",
      "Conteúdo:\n",
      "{\n",
      "    \"tipo\": \"Renda Fixa\",\n",
      "    \"plTotal\": 111802909,\n",
      "    \"ativos\": [\n",
      "        {\n",
      "            \"carteira\": \"15543\",\n",
      "            \"nome\": \"FIDC FCT II SR2\",\n",
      "            \"nomeMercado\": \"CETIP\",\n",
      "            \"tipo\": \"Outros\",\n",
      "            \"codigoCustodia\": \"09H00003977-\",\n",
      "            \"emissor\": \"******\",\n",
      "            \"dataCompra\": \"2024-12-16\",\n",
      "            \"dataEmissao\": \"2024-12-16\",\n",
      "            \"dataVencimento\": \"2028-12-18\",\n",
      "            \"indexador\": \"DI1\",\n",
      "            \"porcentagemIndexador\": \"100%\",\n",
      "            \"taxa\": \"3,0\",\n",
      "            \"quantidadeLivre\": 100000,\n",
      "            \"quantidadeBloqueio\": 0,\n",
      "            \"valorCompra\": 100000000,\n",
      "            \"puCusto\": 1118.029,\n",
      "            \"curvaAtual\": 111802909,\n",
      "            \"puMercado\": 1118.029,\n",
      "            \"mercadoAtual\": 111802909,\n",
      "            \"ateVencimento\": \"Não\",\n",
      "            \"isAtivoVortx\": false,\n",
      "            \"codigoAtivoVortx\": null,\n",
      "            \"isin\": \"BR0000000000\",\n",
      "            \"tipoMoeda\": \"BRL\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CAMINHOS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "\n",
    "# --- BLOCO DE DEPURAÇÃO CORRIGIDO ---\n",
    "\n",
    "print(\"--- DEPURAÇÃO CORRIGIDA: Encontrando o arquivo de carteira pela data interna ---\")\n",
    "\n",
    "# 1. Encontra todos os arquivos .json na pasta\n",
    "arquivos_carteira = glob.glob(os.path.join(PATH_CARTEIRAS_HISTORICO, \"*.json\"))\n",
    "\n",
    "if not arquivos_carteira:\n",
    "    print(\"ERRO: Nenhum arquivo de carteira (.json) encontrado na pasta.\")\n",
    "else:\n",
    "    arquivo_mais_recente = None\n",
    "    data_mais_recente = None\n",
    "\n",
    "    # 2. Itera sobre cada arquivo para encontrar a data mais recente\n",
    "    print(f\"Analisando {len(arquivos_carteira)} arquivos para encontrar o mais recente...\")\n",
    "    for arquivo in arquivos_carteira:\n",
    "        try:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                # Carrega o JSON corretamente\n",
    "                dados = json.load(f)\n",
    "                # Acessa a data interna do relatório\n",
    "                data_atual_str = dados[0]['carteiras'][0]['dataAtual']\n",
    "                data_atual_obj = datetime.strptime(data_atual_str.split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "                # Compara com a data mais recente encontrada até agora\n",
    "                if data_mais_recente is None or data_atual_obj > data_mais_recente:\n",
    "                    data_mais_recente = data_atual_obj\n",
    "                    arquivo_mais_recente = arquivo\n",
    "        except (json.JSONDecodeError, IndexError, KeyError, TypeError) as e:\n",
    "            print(f\"AVISO: Não foi possível ler a data do arquivo '{os.path.basename(arquivo)}'. Erro: {e}\")\n",
    "\n",
    "    if not arquivo_mais_recente:\n",
    "        print(\"ERRO: Não foi possível determinar o arquivo de carteira mais recente.\")\n",
    "    else:\n",
    "        # 3. Agora que temos o arquivo correto, fazemos a inspeção\n",
    "        print(\"\\n------------------------------------------------------------------\")\n",
    "        print(f\"✅ Arquivo mais recente encontrado (pela data interna): {os.path.basename(arquivo_mais_recente)}\")\n",
    "        print(f\"Data do Relatório (D+0): {data_mais_recente.strftime('%d/%m/%Y')}\")\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "        \n",
    "        print(\"\\n--- Inspecionando o conteúdo deste arquivo para 'RendaFixa' ---\")\n",
    "        \n",
    "        with open(arquivo_mais_recente, 'r', encoding='utf-8') as f:\n",
    "            dados_carteira_recente = json.load(f)[0]\n",
    "\n",
    "        # Tenta extrair a seção \"RendaFixa\"\n",
    "        renda_fixa_bloco = next(\n",
    "            (ativo.get('RendaFixa') for ativo in dados_carteira_recente.get('ativos', []) if 'RendaFixa' in ativo and ativo.get('RendaFixa')),\n",
    "            None\n",
    "        )\n",
    "\n",
    "        if renda_fixa_bloco:\n",
    "            print(\"\\n✅ SUCESSO: A seção 'RendaFixa' foi encontrada no arquivo!\")\n",
    "            print(\"Conteúdo:\")\n",
    "            print(json.dumps(renda_fixa_bloco, indent=4, ensure_ascii=False))\n",
    "        else:\n",
    "            print(\"\\n❌ FALHA: A seção 'RendaFixa' NÃO foi encontrada ou está vazia (null) no arquivo de carteira deste dia.\")\n",
    "            print(\"Isso confirma que a coluna no relatório final está corretamente zerada para esta data de referência.\")\n",
    "        print(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6697784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procurando o arquivo de carteira mais recente...\n",
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20250829.json\n",
      "Carregando dados de estoque...\n",
      "Carregando e consolidando arquivos de despesas...\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (VERSÃO DEFINITIVA) ---\n",
      "       Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque Despesas Amort./ Resgat. Cota Disponibilidades     Necessidades Caixa Projetado\n",
      "Prazo                                                                                                                                               \n",
      "D+0       1,000.00        0.00               0.00      13,448,387.14     0.00                 0.00    13,449,387.14             0.00   13,449,387.14\n",
      "D+1       1,000.00  440,304.72               0.00      13,500,473.05     0.00                 0.00    13,941,777.77             0.00   13,941,777.77\n",
      "D+5       1,000.00  440,304.72               0.00      13,728,677.28     0.00                 0.00    14,169,982.00             0.00   14,169,982.00\n",
      "D+10      1,000.00  440,304.72               0.00      14,060,107.05     0.00                 0.00    14,501,411.77             0.00   14,501,411.77\n",
      "D+21      1,000.00  440,304.72               0.00      16,929,321.16     0.00                 0.00    17,370,625.88             0.00   17,370,625.88\n",
      "D+63      1,000.00  440,304.72               0.00      27,287,355.18     0.00                 0.00    27,728,659.90             0.00   27,728,659.90\n",
      "D+365     1,000.00  440,304.72               0.00      87,195,087.53     0.00       -24,845,090.89    87,636,392.25   -24,845,090.89   62,791,301.36\n",
      "D+730     1,000.00  440,304.72               0.00     135,929,948.76     0.00       -62,112,727.22   136,371,253.48   -62,112,727.22   74,258,526.26\n",
      "D+1200    1,000.00  440,304.72               0.00     174,807,393.82     0.00      -108,697,272.64   175,248,698.54  -108,697,272.64   66,551,425.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\175266382.py:157: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_relatorio.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS PARA AS FONTES DE DADOS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO FINAIS ---\n",
    "def encontrar_e_carregar_carteira_recente(caminho_pasta):\n",
    "    \"\"\"\n",
    "    Encontra o arquivo de carteira mais recente pela data interna e carrega seus dados.\n",
    "    \"\"\"\n",
    "    print(\"Procurando o arquivo de carteira mais recente...\")\n",
    "    arquivos_json = glob.glob(os.path.join(caminho_pasta, \"*.json\"))\n",
    "    if not arquivos_json:\n",
    "        return None, None\n",
    "\n",
    "    arquivo_mais_recente = None\n",
    "    data_mais_recente = None\n",
    "\n",
    "    for arquivo in arquivos_json:\n",
    "        try:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                dados = json.load(f)\n",
    "                data_atual_str = dados[0]['carteiras'][0]['dataAtual']\n",
    "                data_atual_obj = datetime.strptime(data_atual_str.split('T')[0], '%Y-%m-%d')\n",
    "                if data_mais_recente is None or data_atual_obj > data_mais_recente:\n",
    "                    data_mais_recente = data_atual_obj\n",
    "                    arquivo_mais_recente = arquivo\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    if arquivo_mais_recente:\n",
    "        print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_mais_recente)}\")\n",
    "        with open(arquivo_mais_recente, 'r', encoding='utf-8') as f:\n",
    "            dados_carteira = json.load(f)[0]\n",
    "        return dados_carteira, data_mais_recente\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    # (função completa que já usamos, sem alterações)\n",
    "    print(\"Carregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                df['Valor Presente'] = pd.to_numeric(df['Valor Presente'].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                df['Data Vencimento'] = pd.to_datetime(df['Data Vencimento'], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception:\n",
    "            continue\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta):\n",
    "    # (função completa que já usamos, sem alterações)\n",
    "    print(\"Carregando e consolidando arquivos de despesas...\")\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame()\n",
    "    lista_df_despesas = []\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df = pd.read_excel(arquivo, header=6) \n",
    "            lista_df_despesas.append(df)\n",
    "        except Exception:\n",
    "            continue\n",
    "    if not lista_df_despesas: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_df_despesas, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'}, inplace=True)\n",
    "    df_consolidado['Data Pagamento'] = pd.to_datetime(df_consolidado['Data Pagamento'], errors='coerce')\n",
    "    df_consolidado['Valor'] = pd.to_numeric(df_consolidado['Valor'], errors='coerce')\n",
    "    df_consolidado['Valor'] = -df_consolidado['Valor'].abs()\n",
    "    return df_consolidado[['Data Pagamento', 'Categoria', 'Valor']].dropna()\n",
    "\n",
    "\n",
    "# --- FUNÇÃO DE PREPARAÇÃO DE FLUXOS (FINAL) ---\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # ... (lógica completa e corrigida que já usamos) ...\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade:\n",
    "        fluxos.append({'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': cota['valorBruto']})\n",
    "            \n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': titulo['mercadoAtual']})\n",
    "\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente', 'Status'])\n",
    "        status_a_incluir = ['A vencer', 'Previsto', 'Vencido']\n",
    "        estoque_filtrado = estoque_valido[estoque_valido['Status'].isin(status_a_incluir)]\n",
    "        for _, row in estoque_filtrado.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Pagamentos Estoque', 'valor': row['Valor Presente']})\n",
    "\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base]\n",
    "        for _, despesa in despesas_futuras.iterrows():\n",
    "            fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas', 'valor': despesa['Valor']})\n",
    "            \n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "            \n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "# --- FUNÇÃO DE GERAÇÃO DO RELATÓRIO (FINAL) ---\n",
    "def gerar_relatorio_d_mais(df_fluxos, data_base):\n",
    "    # Adicionando prazos longos para ver todos os fluxos\n",
    "    prazos = [0, 1, 5, 10, 21, 63, 365, 730, 1200]\n",
    "    colunas_relatorio = ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
    "    \n",
    "    linhas_relatorio = []\n",
    "    for dias in prazos:\n",
    "        data_limite = data_base + timedelta(days=dias)\n",
    "        fluxos_ate_data = df_fluxos[df_fluxos['data'] <= data_limite]\n",
    "        saldos_acumulados = fluxos_ate_data.groupby('categoria')['valor'].sum()\n",
    "        \n",
    "        linha = {'Prazo': f\"D+{dias}\"}\n",
    "        for col in colunas_relatorio:\n",
    "            linha[col] = saldos_acumulados.get(col, 0.0)\n",
    "        \n",
    "        linhas_relatorio.append(linha)\n",
    "        \n",
    "    df_relatorio = pd.DataFrame(linhas_relatorio).set_index('Prazo')\n",
    "    \n",
    "    df_relatorio['Disponibilidades'] = df_relatorio[colunas_relatorio[:4]].sum(axis=1)\n",
    "    df_relatorio['Necessidades'] = df_relatorio[colunas_relatorio[4:]].sum(axis=1)\n",
    "    df_relatorio['Caixa Projetado'] = df_relatorio['Disponibilidades'] + df_relatorio['Necessidades']\n",
    "    \n",
    "    return df_relatorio.applymap('{:,.2f}'.format)\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO FINAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    dados_carteira_recente, data_referencia = encontrar_e_carregar_carteira_recente(PATH_CARTEIRAS_HISTORICO)\n",
    "    \n",
    "    if dados_carteira_recente:\n",
    "        df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "        df_despesas = processar_dados_despesas(PATH_DESPESAS)\n",
    "        \n",
    "        df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "        \n",
    "        relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "\n",
    "        print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (VERSÃO DEFINITIVA) ---\")\n",
    "        print(relatorio_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e49b4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AUDITORIA DE DADOS: Verificando arquivos de Despesas ---\n",
      "Encontrados 47 arquivos de despesas para análise:\n",
      "\n",
      "--- Detalhamento por Arquivo ---\n",
      "                                Arquivo Data Mais Antiga Data Mais Recente\n",
      "    143063-Despesas_Consolidadas_143063       09/05/2025        09/05/2025\n",
      "    143489-Despesas_Consolidadas_143489       09/05/2025        09/05/2025\n",
      "    143490-Despesas_Consolidadas_143490       09/05/2025        09/05/2025\n",
      "    143491-Despesas_Consolidadas_143491       09/05/2025        09/05/2025\n",
      "    143492-Despesas_Consolidadas_143492       09/05/2025        09/05/2025\n",
      "    143493-Despesas_Consolidadas_143493       09/05/2025        09/05/2025\n",
      "    143494-Despesas_Consolidadas_143494       09/05/2025        09/05/2025\n",
      "    143495-Despesas_Consolidadas_143495       09/05/2025        09/05/2025\n",
      "    143496-Despesas_Consolidadas_143496       09/05/2025        09/05/2025\n",
      "    143497-Despesas_Consolidadas_143497       09/05/2025        09/05/2025\n",
      "143497-Despesas_Consolidadas_143497 (1)       09/05/2025        09/05/2025\n",
      "    143498-Despesas_Consolidadas_143498       09/05/2025        09/05/2025\n",
      "    143499-Despesas_Consolidadas_143499       09/05/2025        09/05/2025\n",
      "    143500-Despesas_Consolidadas_143500       09/05/2025        09/05/2025\n",
      "    143501-Despesas_Consolidadas_143501       09/05/2025        09/05/2025\n",
      "    143502-Despesas_Consolidadas_143502       09/05/2025        09/05/2025\n",
      "    143503-Despesas_Consolidadas_143503       09/05/2025        09/05/2025\n",
      "    143504-Despesas_Consolidadas_143504       09/05/2025        09/05/2025\n",
      "    143505-Despesas_Consolidadas_143505       09/05/2025        08/07/2025\n",
      "    143506-Despesas_Consolidadas_143506       08/07/2025        08/07/2025\n",
      "    143507-Despesas_Consolidadas_143507       08/07/2025        08/07/2025\n",
      "    143508-Despesas_Consolidadas_143508       08/07/2025        08/07/2025\n",
      "    143509-Despesas_Consolidadas_143509       08/07/2025        08/07/2025\n",
      "    143510-Despesas_Consolidadas_143510       08/07/2025        08/07/2025\n",
      "    143511-Despesas_Consolidadas_143511       08/07/2025        08/07/2025\n",
      "    143512-Despesas_Consolidadas_143512       08/07/2025        08/07/2025\n",
      "    143513-Despesas_Consolidadas_143513       08/07/2025        08/07/2025\n",
      "    143514-Despesas_Consolidadas_143514       08/07/2025        08/07/2025\n",
      "    143515-Despesas_Consolidadas_143515       08/07/2025        08/07/2025\n",
      "    143516-Despesas_Consolidadas_143516       08/07/2025        08/07/2025\n",
      "    143517-Despesas_Consolidadas_143517       08/07/2025        08/07/2025\n",
      "    143518-Despesas_Consolidadas_143518       08/07/2025        08/07/2025\n",
      "    143519-Despesas_Consolidadas_143519       08/07/2025        08/07/2025\n",
      "    143520-Despesas_Consolidadas_143520       08/07/2025        08/07/2025\n",
      "    143521-Despesas_Consolidadas_143521       08/07/2025        08/07/2025\n",
      "    143522-Despesas_Consolidadas_143522       08/07/2025        08/07/2025\n",
      "    143523-Despesas_Consolidadas_143523       08/07/2025        08/07/2025\n",
      "    143524-Despesas_Consolidadas_143524       08/07/2025        08/07/2025\n",
      "    143525-Despesas_Consolidadas_143525       08/07/2025        08/07/2025\n",
      "    143526-Despesas_Consolidadas_143526       08/07/2025        08/07/2025\n",
      "    143528-Despesas_Consolidadas_143528       07/07/2025        07/07/2025\n",
      "    143529-Despesas_Consolidadas_143529       07/07/2025        07/07/2025\n",
      "    143530-Despesas_Consolidadas_143530       07/07/2025        07/07/2025\n",
      "    143531-Despesas_Consolidadas_143531       07/07/2025        07/07/2025\n",
      "    143532-Despesas_Consolidadas_143532       07/07/2025        07/07/2025\n",
      "    143533-Despesas_Consolidadas_143533       07/07/2025        07/07/2025\n",
      "    143534-Despesas_Consolidadas_143534       07/07/2025        07/07/2025\n",
      "\n",
      "------------------------------------------------------------------\n",
      ">>> CONCLUSÃO DA AUDITORIA:\n",
      ">>> A DATA DE PAGAMENTO MAIS RECENTE encontrada em TODOS os arquivos é: 08/07/2025\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Compare esta data com a data de referência da sua projeção (D+0).\n",
      "Se esta data for anterior à data de referência, o resultado 'zero' no relatório está correto, pois não há despesas futuras nos dados.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CAMINHO PARA A PASTA COM OS ARQUIVOS DE DESPESAS ---\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "# --- BLOCO DE DEPURAÇÃO ---\n",
    "\n",
    "print(\"--- AUDITORIA DE DADOS: Verificando arquivos de Despesas ---\")\n",
    "\n",
    "# 1. Encontra todos os arquivos de despesas na pasta e subpastas\n",
    "arquivos_excel = glob.glob(os.path.join(PATH_DESPESAS, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "\n",
    "if not arquivos_excel:\n",
    "    print(\"\\nERRO CRÍTICO: Nenhum arquivo 'Despesas_Consolidadas.xlsx' foi encontrado na pasta especificada.\")\n",
    "else:\n",
    "    print(f\"Encontrados {len(arquivos_excel)} arquivos de despesas para análise:\")\n",
    "    \n",
    "    lista_de_datas = []\n",
    "    detalhes_arquivos = []\n",
    "\n",
    "    # 2. Itera sobre cada arquivo para extrair seu intervalo de datas\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            # Lê o arquivo, pulando as 6 primeiras linhas\n",
    "            df = pd.read_excel(arquivo, header=6)\n",
    "            \n",
    "            # Converte a coluna 'Data Pagamento' para o formato de data\n",
    "            df['Data Pagamento'] = pd.to_datetime(df['Data Pagamento'], errors='coerce')\n",
    "            \n",
    "            # Remove linhas onde a data não pôde ser lida\n",
    "            df.dropna(subset=['Data Pagamento'], inplace=True)\n",
    "            \n",
    "            if not df.empty:\n",
    "                data_min = df['Data Pagamento'].min()\n",
    "                data_max = df['Data Pagamento'].max()\n",
    "                \n",
    "                detalhes_arquivos.append({\n",
    "                    \"Arquivo\": os.path.basename(os.path.dirname(arquivo)), # Pega o nome da pasta pai\n",
    "                    \"Data Mais Antiga\": data_min.strftime('%d/%m/%Y'),\n",
    "                    \"Data Mais Recente\": data_max.strftime('%d/%m/%Y')\n",
    "                })\n",
    "                # Adiciona todas as datas à lista geral\n",
    "                lista_de_datas.extend(df['Data Pagamento'].tolist())\n",
    "            else:\n",
    "                detalhes_arquivos.append({\n",
    "                    \"Arquivo\": os.path.basename(os.path.dirname(arquivo)),\n",
    "                    \"Data Mais Antiga\": \"N/A\",\n",
    "                    \"Data Mais Recente\": \"N/A\"\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAVISO: Falha ao processar o arquivo '{os.path.basename(arquivo)}'. Erro: {e}\")\n",
    "\n",
    "    # 3. Apresenta os resultados da auditoria\n",
    "    print(\"\\n--- Detalhamento por Arquivo ---\")\n",
    "    df_detalhes = pd.DataFrame(detalhes_arquivos)\n",
    "    print(df_detalhes.to_string(index=False))\n",
    "\n",
    "    if lista_de_datas:\n",
    "        data_geral_mais_recente = max(lista_de_datas)\n",
    "        print(\"\\n------------------------------------------------------------------\")\n",
    "        print(\">>> CONCLUSÃO DA AUDITORIA:\")\n",
    "        print(f\">>> A DATA DE PAGAMENTO MAIS RECENTE encontrada em TODOS os arquivos é: {data_geral_mais_recente.strftime('%d/%m/%Y')}\")\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "        print(\"\\nCompare esta data com a data de referência da sua projeção (D+0).\")\n",
    "        print(\"Se esta data for anterior à data de referência, o resultado 'zero' no relatório está correto, pois não há despesas futuras nos dados.\")\n",
    "    else:\n",
    "        print(\"\\nNenhuma data de pagamento válida foi encontrada em nenhum dos arquivos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4798c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO DEPURAÇÃO DO PROCESSAMENTO DE DESPESAS ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Arquivo de despesas mais recente identificado: '143501-Despesas_Consolidadas_143501' (gerado em 08/12/2025)\n",
      "\n",
      "2. Despesas 'molde' extraídas deste arquivo para a projeção:\n",
      "      Categoria     Valor\n",
      "0  PROV ADM      -9305.14\n",
      "1  PROV GESTÃO  -31017.12\n",
      "2  TX ESCRT FIX   -794.32\n",
      "\n",
      "3. Projetando despesas para os próximos 12 meses, a partir de 29/08/2025\n",
      "\n",
      "4. Tabela final de despesas futuras geradas:\n",
      "  Data Pagamento     Categoria     Valor\n",
      "0     2025-09-05  PROV ADM      -9305.14\n",
      "1     2025-09-05  PROV GESTÃO  -31017.12\n",
      "2     2025-09-05  TX ESCRT FIX   -794.32\n",
      "3     2025-10-06  PROV ADM      -9305.14\n",
      "4     2025-10-06  PROV GESTÃO  -31017.12\n",
      "5     2025-10-06  TX ESCRT FIX   -794.32\n",
      "6     2025-11-05  PROV ADM      -9305.14\n",
      "7     2025-11-05  PROV GESTÃO  -31017.12\n",
      "8     2025-11-05  TX ESCRT FIX   -794.32\n",
      "9     2025-12-05  PROV ADM      -9305.14\n",
      "\n",
      "--- FIM DA DEPURAÇÃO ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2373365679.py:31: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# --- CAMINHOS ---\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "# Defina a data de referência da sua projeção para o teste\n",
    "DATA_BASE_PROJECAO_TESTE = datetime(2025, 8, 29)\n",
    "\n",
    "\n",
    "def depurar_processamento_despesas(caminho_pasta, data_base_projecao, meses_a_projetar=12):\n",
    "    \"\"\"\n",
    "    Função de depuração para inspecionar o processamento de despesas passo a passo.\n",
    "    \"\"\"\n",
    "    print(\"--- INICIANDO DEPURAÇÃO DO PROCESSAMENTO DE DESPESAS ---\")\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel:\n",
    "        print(\"1. Nenhum arquivo de despesa encontrado.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_mais_recente = None\n",
    "    data_relatorio_recente = None\n",
    "    arquivo_usado = None\n",
    "\n",
    "    # 1. Encontra o arquivo com a 'Data' (data de geração do relatório) mais recente\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df_temp = pd.read_excel(arquivo, header=6)\n",
    "            df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
    "            data_atual = df_temp['Data'].max()\n",
    "            if data_relatorio_recente is None or data_atual > data_relatorio_recente:\n",
    "                data_relatorio_recente = data_atual\n",
    "                df_mais_recente = df_temp\n",
    "                arquivo_usado = os.path.basename(os.path.dirname(arquivo)) # Pega o nome da pasta\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    if df_mais_recente is None:\n",
    "        print(\"1. Nenhum arquivo de despesa válido pôde ser lido.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"1. Arquivo de despesas mais recente identificado: '{arquivo_usado}' (gerado em {data_relatorio_recente.strftime('%d/%m/%Y')})\")\n",
    "    \n",
    "    # 2. Limpa o DataFrame mais recente para usá-lo como \"molde\"\n",
    "    df_base = df_mais_recente.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'})\n",
    "    df_base['Valor'] = -pd.to_numeric(df_base['Valor'], errors='coerce').abs()\n",
    "    df_base = df_base[['Categoria', 'Valor']].dropna()\n",
    "    \n",
    "    print(\"\\n2. Despesas 'molde' extraídas deste arquivo para a projeção:\")\n",
    "    print(df_base.to_string())\n",
    "    \n",
    "    despesas_finais = []\n",
    "    \n",
    "    # 3. Projeta as despesas para os meses FUTUROS\n",
    "    print(f\"\\n3. Projetando despesas para os próximos {meses_a_projetar} meses, a partir de {data_base_projecao.strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "    mes_inicial_projecao = data_base_projecao.replace(day=1)\n",
    "\n",
    "    for i in range(meses_a_projetar):\n",
    "        mes_atual = mes_inicial_projecao + relativedelta(months=i)\n",
    "        data_pagamento_proj = mes_atual.replace(day=5)\n",
    "        \n",
    "        while data_pagamento_proj.weekday() >= 5:\n",
    "            data_pagamento_proj += timedelta(days=1)\n",
    "        \n",
    "        # A projeção só deve incluir datas futuras\n",
    "        if data_pagamento_proj >= data_base_projecao:\n",
    "            for _, row in df_base.iterrows():\n",
    "                despesas_finais.append({\n",
    "                    'Data Pagamento': data_pagamento_proj,\n",
    "                    'Categoria': row['Categoria'],\n",
    "                    'Valor': row['Valor']\n",
    "                })\n",
    "\n",
    "    df_final = pd.DataFrame(despesas_finais)\n",
    "    \n",
    "    if df_final.empty:\n",
    "        print(\"\\n4. Nenhuma despesa futura foi gerada. A projeção de despesas está vazia.\")\n",
    "    else:\n",
    "        print(\"\\n4. Tabela final de despesas futuras geradas:\")\n",
    "        print(df_final.head(10).to_string()) # Mostra as 10 primeiras despesas projetadas\n",
    "    \n",
    "    print(\"\\n--- FIM DA DEPURAÇÃO ---\")\n",
    "    return df_final\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO DA DEPURAÇÃO ---\n",
    "df_despesas_depuradas = depurar_processamento_despesas(PATH_DESPESAS, DATA_BASE_PROJECAO_TESTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3085507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque Despesas Amort./ Resgat. Cota Disponibilidades     Necessidades Caixa Projetado\n",
      "Prazo                                                                                                                                               \n",
      "D+0       1,000.00        0.00               0.00      13,448,387.14     0.00                 0.00    13,449,387.14             0.00   13,449,387.14\n",
      "D+1       1,000.00  440,304.72               0.00      13,500,473.05     0.00                 0.00    13,941,777.77             0.00   13,941,777.77\n",
      "D+5       1,000.00  440,304.72               0.00      13,728,677.28     0.00                 0.00    14,169,982.00             0.00   14,169,982.00\n",
      "D+10      1,000.00  440,304.72               0.00      14,060,107.05     0.00                 0.00    14,501,411.77             0.00   14,501,411.77\n",
      "D+21      1,000.00  440,304.72               0.00      16,929,321.16     0.00                 0.00    17,370,625.88             0.00   17,370,625.88\n",
      "D+63      1,000.00  440,304.72               0.00      27,287,355.18     0.00                 0.00    27,728,659.90             0.00   27,728,659.90\n",
      "D+365     1,000.00  440,304.72               0.00      87,195,087.53     0.00       -24,845,090.89    87,636,392.25   -24,845,090.89   62,791,301.36\n",
      "D+730     1,000.00  440,304.72               0.00     135,929,948.76     0.00       -62,112,727.22   136,371,253.48   -62,112,727.22   74,258,526.26\n",
      "D+1200    1,000.00  440,304.72               0.00     174,807,393.82     0.00      -108,697,272.64   175,248,698.54  -108,697,272.64   66,551,425.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\175266382.py:157: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_relatorio.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS PARA AS FONTES DE DADOS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÃO DE PROCESSAMENTO DE DESPESAS (VERSÃO FINAL E INTELIGENTE) ---\n",
    "\n",
    "\n",
    "def processar_dados_despesas(caminho_pasta, data_base_projecao, meses_a_projetar=12):\n",
    "    \"\"\"\n",
    "    Encontra o relatório de despesas mais recente e projeta suas provisões para o futuro.\n",
    "    \"\"\"\n",
    "    print(\"\\nCarregando despesas com a lógica final...\")\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_mais_recente = None\n",
    "    data_relatorio_recente = None\n",
    "\n",
    "    # 1. Encontra o arquivo com a 'Data' (data de geração) mais recente\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df_temp = pd.read_excel(arquivo, header=6)\n",
    "            df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
    "            data_atual = df_temp['Data'].max()\n",
    "            if data_relatorio_recente is None or data_atual > data_relatorio_recente:\n",
    "                data_relatorio_recente = data_atual\n",
    "                df_mais_recente = df_temp\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    if df_mais_recente is None:\n",
    "        print(\"Nenhum arquivo de despesa válido encontrado.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Usando o relatório de despesas gerado em: {data_relatorio_recente.strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "    # 2. Limpa o DataFrame mais recente e o usa como base\n",
    "    df_base = df_mais_recente.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor', 'Data Pagamento': 'Data_Pagamento'})\n",
    "    df_base['Valor'] = -pd.to_numeric(df_base['Valor'], errors='coerce').abs()\n",
    "    df_base = df_base[['Categoria', 'Valor']].dropna()\n",
    "    \n",
    "    despesas_finais = []\n",
    "    \n",
    "    # 3. Projeta as despesas para os próximos meses\n",
    "    print(f\"Projetando {len(df_base)} categorias de despesas para os próximos {meses_a_projetar} meses.\")\n",
    "    \n",
    "    # Começa a projeção no primeiro mês após ou igual à data de referência\n",
    "    mes_inicial_projecao = data_base_projecao.replace(day=1)\n",
    "\n",
    "    for i in range(meses_a_projetar):\n",
    "        mes_atual = mes_inicial_projecao + relativedelta(months=i)\n",
    "        # Define a data de pagamento para o 5º dia\n",
    "        data_pagamento_proj = mes_atual.replace(day=5)\n",
    "        \n",
    "        # Ajusta para o próximo dia útil\n",
    "        while data_pagamento_proj.weekday() >= 5: # 5=Sábado, 6=Domingo\n",
    "            data_pagamento_proj += timedelta(days=1)\n",
    "\n",
    "        for _, row in df_base.iterrows():\n",
    "            despesas_finais.append({\n",
    "                'Data Pagamento': data_pagamento_proj,\n",
    "                'Categoria': row['Categoria'],\n",
    "                'Valor': row['Valor']\n",
    "            })\n",
    "\n",
    "    df_final = pd.DataFrame(despesas_finais)\n",
    "    print(f\"{len(df_final)} eventos de despesas futuras foram criados.\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# --- FUNÇÃO DE PREPARAÇÃO DE FLUXOS (VERSÃO OTIMIZADA) ---\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    \"\"\"\n",
    "    Cria uma lista de TODOS os eventos de fluxo de caixa futuros,\n",
    "    usando operações vetorizadas para alta performance.\n",
    "    \"\"\"\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    lista_de_fluxos_df = []\n",
    "\n",
    "    # Disponibilidades (da carteira)\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade:\n",
    "        df_cc = pd.DataFrame([{'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']}])\n",
    "        lista_de_fluxos_df.append(df_cc)\n",
    "\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        df_cotas = pd.DataFrame([{'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': c['valorBruto']} for c in cotas['ativos']])\n",
    "        lista_de_fluxos_df.append(df_cotas)\n",
    "            \n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        df_rf = pd.DataFrame([{'data': datetime.strptime(t['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': t['mercadoAtual']} for t in renda_fixa['ativos']])\n",
    "        lista_de_fluxos_df.append(df_rf)\n",
    "\n",
    "    # Pagamentos do Estoque (OTIMIZAÇÃO APLICADA AQUI)\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente', 'Status'])\n",
    "        status_a_incluir = ['A vencer', 'Previsto', 'Vencido']\n",
    "        estoque_filtrado = estoque_valido[estoque_valido['Status'].isin(status_a_incluir)].copy()\n",
    "        \n",
    "        # Cria o DataFrame de fluxos do estoque diretamente, sem loop\n",
    "        estoque_fluxos = estoque_filtrado[['Data Vencimento', 'Valor Presente']].rename(columns={'Data Vencimento': 'data', 'Valor Presente': 'valor'})\n",
    "        estoque_fluxos['categoria'] = 'Pagamentos Estoque'\n",
    "        lista_de_fluxos_df.append(estoque_fluxos)\n",
    "\n",
    "    # Necessidades\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base].copy()\n",
    "        despesas_fluxos = despesas_futuras[['Data Pagamento', 'Valor']].rename(columns={'Data Pagamento': 'data', 'Valor': 'valor'})\n",
    "        despesas_fluxos['categoria'] = 'Despesas'\n",
    "        lista_de_fluxos_df.append(despesas_fluxos)\n",
    "            \n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        amort_fluxos_lista = []\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            amort_fluxos_lista.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "        df_amort = pd.DataFrame(amort_fluxos_lista)\n",
    "        lista_de_fluxos_df.append(df_amort)\n",
    "            \n",
    "    # Concatena todos os DataFrames de uma só vez\n",
    "    return pd.concat(lista_de_fluxos_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# --- DEMAIS FUNÇÕES (sem alterações) ---\n",
    "# copiar dps\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO ---\n",
    "if __name__ == \"__main__\":\n",
    "    # (O bloco de execução principal permanece o mesmo,\n",
    "    # ele simplesmente chamará a nova e mais inteligente função 'processar_dados_despesas')\n",
    "    \n",
    "    # dados_carteira_recente, data_referencia = encontrar_e_carregar_carteira_recente(PATH_CARTEIRAS_HISTORICO)\n",
    "    # df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "    # df_despesas = processar_dados_despesas(PATH_DESPESAS)\n",
    "    \n",
    "    df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "    relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "    \n",
    "    print(relatorio_final.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8e751b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procurando o arquivo de carteira mais recente...\n",
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20250829.json\n",
      "Carregando dados de estoque...\n",
      "\n",
      "Carregando despesas com a lógica final...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n",
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2392868282.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando o relatório de despesas gerado em: 08/12/2025\n",
      "Projetando 3 categorias de despesas para os próximos 12 meses.\n",
      "36 eventos de despesas futuras foram criados.\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (LÓGICA FINAL) ---\n",
      "      Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque    Despesas Amort./ Resgat. Cota Disponibilidades Necessidades Caixa Projetado\n",
      "Prazo                                                                                                                                             \n",
      "D+0      1,000.00        0.00               0.00      13,448,387.14        0.00                 0.00    13,449,387.14         0.00   13,449,387.14\n",
      "D+1      1,000.00  440,304.72               0.00      13,500,473.05        0.00                 0.00    13,941,777.77         0.00   13,941,777.77\n",
      "D+5      1,000.00  440,304.72               0.00      13,728,677.28        0.00                 0.00    14,169,982.00         0.00   14,169,982.00\n",
      "D+10     1,000.00  440,304.72               0.00      14,060,107.05  -41,116.58                 0.00    14,501,411.77   -41,116.58   14,460,295.19\n",
      "D+21     1,000.00  440,304.72               0.00      16,929,321.16  -41,116.58                 0.00    17,370,625.88   -41,116.58   17,329,509.30\n",
      "D+63     1,000.00  440,304.72               0.00      27,287,355.18  -82,233.16                 0.00    27,728,659.90   -82,233.16   27,646,426.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\1707903179.py:163: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_relatorio.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS PARA AS FONTES DE DADOS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO FINAIS E CORRIGIDAS ---\n",
    "\n",
    "def encontrar_e_carregar_carteira_recente(caminho_pasta):\n",
    "    \"\"\"Encontra o arquivo de carteira mais recente pela data interna e carrega seus dados.\"\"\"\n",
    "    print(\"Procurando o arquivo de carteira mais recente...\")\n",
    "    arquivos_json = glob.glob(os.path.join(caminho_pasta, \"*.json\"))\n",
    "    if not arquivos_json: return None, None\n",
    "    arquivo_mais_recente, data_mais_recente = None, None\n",
    "    for arquivo in arquivos_json:\n",
    "        try:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                dados = json.load(f)\n",
    "                data_atual_str = dados[0]['carteiras'][0]['dataAtual']\n",
    "                data_atual_obj = datetime.strptime(data_atual_str.split('T')[0], '%Y-%m-%d')\n",
    "                if data_mais_recente is None or data_atual_obj > data_mais_recente:\n",
    "                    data_mais_recente, arquivo_mais_recente = data_atual_obj, arquivo\n",
    "        except Exception: continue\n",
    "    if arquivo_mais_recente:\n",
    "        print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_mais_recente)}\")\n",
    "        with open(arquivo_mais_recente, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)[0], data_mais_recente\n",
    "    return None, None\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"Carregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                df['Valor Presente'] = pd.to_numeric(df['Valor Presente'].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                df['Data Vencimento'] = pd.to_datetime(df['Data Vencimento'], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception: continue\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# --- FUNÇÃO DE PREPARAÇÃO DE FLUXOS (VERSÃO OTIMIZADA) ---\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    \"\"\"\n",
    "    Cria uma lista de TODOS os eventos de fluxo de caixa futuros,\n",
    "    usando operações vetorizadas para alta performance.\n",
    "    \"\"\"\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    lista_de_fluxos_df = []\n",
    "\n",
    "    # Disponibilidades (da carteira)\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade:\n",
    "        df_cc = pd.DataFrame([{'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']}])\n",
    "        lista_de_fluxos_df.append(df_cc)\n",
    "\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        df_cotas = pd.DataFrame([{'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': c['valorBruto']} for c in cotas['ativos']])\n",
    "        lista_de_fluxos_df.append(df_cotas)\n",
    "            \n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        df_rf = pd.DataFrame([{'data': datetime.strptime(t['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': t['mercadoAtual']} for t in renda_fixa['ativos']])\n",
    "        lista_de_fluxos_df.append(df_rf)\n",
    "\n",
    "    # Pagamentos do Estoque (OTIMIZAÇÃO APLICADA AQUI)\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente', 'Status'])\n",
    "        status_a_incluir = ['A vencer', 'Previsto', 'Vencido']\n",
    "        estoque_filtrado = estoque_valido[estoque_valido['Status'].isin(status_a_incluir)].copy()\n",
    "        \n",
    "        # Cria o DataFrame de fluxos do estoque diretamente, sem loop\n",
    "        estoque_fluxos = estoque_filtrado[['Data Vencimento', 'Valor Presente']].rename(columns={'Data Vencimento': 'data', 'Valor Presente': 'valor'})\n",
    "        estoque_fluxos['categoria'] = 'Pagamentos Estoque'\n",
    "        lista_de_fluxos_df.append(estoque_fluxos)\n",
    "\n",
    "    # Necessidades\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base].copy()\n",
    "        despesas_fluxos = despesas_futuras[['Data Pagamento', 'Valor']].rename(columns={'Data Pagamento': 'data', 'Valor': 'valor'})\n",
    "        despesas_fluxos['categoria'] = 'Despesas'\n",
    "        lista_de_fluxos_df.append(despesas_fluxos)\n",
    "            \n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        amort_fluxos_lista = []\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            amort_fluxos_lista.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "        df_amort = pd.DataFrame(amort_fluxos_lista)\n",
    "        lista_de_fluxos_df.append(df_amort)\n",
    "            \n",
    "    # Concatena todos os DataFrames de uma só vez\n",
    "    return pd.concat(lista_de_fluxos_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# --- DEMAIS FUNÇÕES FINAIS ---\n",
    "\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade: fluxos.append({'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']: fluxos.append({'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': cota['valorBruto']})\n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']: fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': titulo['mercadoAtual']})\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente', 'Status'])\n",
    "        status_a_incluir = ['A vencer', 'Previsto', 'Vencido']\n",
    "        estoque_filtrado = estoque_valido[estoque_valido['Status'].isin(status_a_incluir)]\n",
    "        for _, row in estoque_filtrado.iterrows(): fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Pagamentos Estoque', 'valor': row['Valor Presente']})\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base]\n",
    "        for _, despesa in despesas_futuras.iterrows(): fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas', 'valor': despesa['Valor']})\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "def gerar_relatorio_d_mais(df_fluxos, data_base):\n",
    "    prazos = [0, 1, 5, 10, 21, 63]\n",
    "    colunas_relatorio = ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
    "    linhas_relatorio = []\n",
    "    for dias in prazos:\n",
    "        data_limite = data_base + timedelta(days=dias)\n",
    "        fluxos_ate_data = df_fluxos[df_fluxos['data'] <= data_limite]\n",
    "        saldos_acumulados = fluxos_ate_data.groupby('categoria')['valor'].sum()\n",
    "        linha = {'Prazo': f\"D+{dias}\"}\n",
    "        for col in colunas_relatorio: linha[col] = saldos_acumulados.get(col, 0.0)\n",
    "        linhas_relatorio.append(linha)\n",
    "    df_relatorio = pd.DataFrame(linhas_relatorio).set_index('Prazo')\n",
    "    df_relatorio['Disponibilidades'] = df_relatorio[colunas_relatorio[:4]].sum(axis=1)\n",
    "    df_relatorio['Necessidades'] = df_relatorio[colunas_relatorio[4:]].sum(axis=1)\n",
    "    df_relatorio['Caixa Projetado'] = df_relatorio['Disponibilidades'] + df_relatorio['Necessidades']\n",
    "    return df_relatorio.applymap('{:,.2f}'.format)\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO FINAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    dados_carteira_recente, data_referencia = encontrar_e_carregar_carteira_recente(PATH_CARTEIRAS_HISTORICO)\n",
    "    if dados_carteira_recente:\n",
    "        df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "        df_despesas = processar_dados_despesas(PATH_DESPESAS, data_referencia)\n",
    "        df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "        relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "        print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (LÓGICA FINAL) ---\")\n",
    "        print(relatorio_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02d24837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procurando o arquivo de carteira mais recente...\n",
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20250829.json\n",
      "\n",
      "Carregando despesas com a lógica final e corrigida...\n",
      "Usando o relatório de despesas gerado em: 01/09/2025\n",
      "52 eventos de despesas futuras (reais + projetadas) foram criados.\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (LÓGICA FINAL) ---\n",
      "      Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque       Despesas Amort./ Resgat. Cota Disponibilidades    Necessidades Caixa Projetado\n",
      "Prazo                                                                                                                                                   \n",
      "D+0      1,000.00        0.00               0.00      13,448,387.14           0.00                 0.00    13,449,387.14            0.00   13,449,387.14\n",
      "D+1      1,000.00  440,304.72               0.00      13,500,473.05           0.00                 0.00    13,941,777.77            0.00   13,941,777.77\n",
      "D+5      1,000.00  440,304.72               0.00      13,728,677.28           0.00                 0.00    14,169,982.00            0.00   14,169,982.00\n",
      "D+10     1,000.00  440,304.72               0.00      14,060,107.05    -457,778.52                 0.00    14,501,411.77     -457,778.52   14,043,633.25\n",
      "D+21     1,000.00  440,304.72               0.00      16,929,321.16    -457,778.52                 0.00    17,370,625.88     -457,778.52   16,912,847.36\n",
      "D+63     1,000.00  440,304.72               0.00      27,287,355.18    -686,667.78                 0.00    27,728,659.90     -686,667.78   27,041,992.12\n",
      "D+365    1,000.00  440,304.72               0.00      87,195,087.53  -2,975,560.38       -24,845,090.89    87,636,392.25  -27,820,651.27   59,815,740.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\2393327332.py:142: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_relatorio.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS PARA AS FONTES DE DADOS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO FINAIS E CORRIGIDAS ---\n",
    "\n",
    "def encontrar_e_carregar_carteira_recente(caminho_pasta):\n",
    "    \"\"\"Encontra o arquivo de carteira mais recente pela data interna e carrega seus dados.\"\"\"\n",
    "    print(\"Procurando o arquivo de carteira mais recente...\")\n",
    "    arquivos_json = glob.glob(os.path.join(caminho_pasta, \"*.json\"))\n",
    "    if not arquivos_json: return None, None\n",
    "    arquivo_mais_recente, data_mais_recente = None, None\n",
    "    for arquivo in arquivos_json:\n",
    "        try:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                dados = json.load(f)\n",
    "                data_atual_str = dados[0]['carteiras'][0]['dataAtual']\n",
    "                data_atual_obj = datetime.strptime(data_atual_str.split('T')[0], '%Y-%m-%d')\n",
    "                if data_mais_recente is None or data_atual_obj > data_mais_recente:\n",
    "                    data_mais_recente, arquivo_mais_recente = data_atual_obj, arquivo\n",
    "        except Exception: continue\n",
    "    if arquivo_mais_recente:\n",
    "        print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_mais_recente)}\")\n",
    "        with open(arquivo_mais_recente, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)[0], data_mais_recente\n",
    "    return None, None\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    print(\"Carregando dados de estoque...\")\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                df['Valor Presente'] = pd.to_numeric(df['Valor Presente'].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                df['Data Vencimento'] = pd.to_datetime(df['Data Vencimento'], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception: continue\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "def processar_dados_despesas_final(caminho_pasta, data_base_projecao, meses_a_projetar=12):\n",
    "    \"\"\"Encontra o relatório de despesas mais recente e projeta suas provisões para o futuro.\"\"\"\n",
    "    print(\"\\nCarregando despesas com a lógica final e corrigida...\")\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame()\n",
    "    df_mais_recente, data_relatorio_recente = None, None\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df_temp = pd.read_excel(arquivo, header=6)\n",
    "            # ### A CORREÇÃO DEFINITIVA ESTÁ AQUI ###\n",
    "            df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce', dayfirst=True)\n",
    "            data_atual = df_temp['Data'].max()\n",
    "            if data_relatorio_recente is None or data_atual > data_relatorio_recente:\n",
    "                data_relatorio_recente, df_mais_recente = data_atual, df_temp\n",
    "        except Exception: continue\n",
    "    if df_mais_recente is None: return pd.DataFrame()\n",
    "    print(f\"Usando o relatório de despesas gerado em: {data_relatorio_recente.strftime('%d/%m/%Y')}\")\n",
    "    df_base = df_mais_recente.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'})\n",
    "    df_base['Valor'] = -pd.to_numeric(df_base['Valor'], errors='coerce').abs()\n",
    "    df_base['Data Pagamento'] = pd.to_datetime(df_base['Data Pagamento'], errors='coerce', dayfirst=True)\n",
    "    df_base = df_base[['Categoria', 'Valor', 'Data Pagamento']].dropna()\n",
    "    despesas_finais = []\n",
    "    \n",
    "    # Adiciona as despesas reais do arquivo base que são futuras\n",
    "    despesas_reais_futuras = df_base[df_base['Data Pagamento'] >= data_base_projecao]\n",
    "    despesas_finais.extend(despesas_reais_futuras.to_dict('records'))\n",
    "\n",
    "    # Projeta as despesas para os meses seguintes\n",
    "    mes_inicial_projecao = (data_base_projecao.replace(day=1) + relativedelta(months=1))\n",
    "    for i in range(meses_a_projetar):\n",
    "        mes_atual = mes_inicial_projecao + relativedelta(months=i)\n",
    "        data_pagamento_proj = mes_atual.replace(day=5)\n",
    "        while data_pagamento_proj.weekday() >= 5: data_pagamento_proj += timedelta(days=1)\n",
    "        # Cria um \"molde\" das despesas do último relatório para projetar\n",
    "        for _, row in df_base.iterrows():\n",
    "            despesas_finais.append({'Data Pagamento': data_pagamento_proj, 'Categoria': row['Categoria'], 'Valor': row['Valor']})\n",
    "            \n",
    "    df_final = pd.DataFrame(despesas_finais)\n",
    "    print(f\"{len(df_final)} eventos de despesas futuras (reais + projetadas) foram criados.\")\n",
    "    return df_final\n",
    "\n",
    "# --- DEMAIS FUNÇÕES FINAIS ---\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade: fluxos.append({'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']: fluxos.append({'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': cota['valorBruto']})\n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']: fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': titulo['mercadoAtual']})\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente', 'Status'])\n",
    "        status_a_incluir = ['A vencer', 'Previsto', 'Vencido']\n",
    "        estoque_filtrado = estoque_valido[estoque_valido['Status'].isin(status_a_incluir)]\n",
    "        for _, row in estoque_filtrado.iterrows(): fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Pagamentos Estoque', 'valor': row['Valor Presente']})\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base]\n",
    "        for _, despesa in despesas_futuras.iterrows(): fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas', 'valor': despesa['Valor']})\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "def gerar_relatorio_d_mais(df_fluxos, data_base):\n",
    "    prazos = [0, 1, 5, 10, 21, 63, 365]\n",
    "    colunas_relatorio = ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
    "    linhas_relatorio = []\n",
    "    for dias in prazos:\n",
    "        data_limite = data_base + timedelta(days=dias)\n",
    "        fluxos_ate_data = df_fluxos[df_fluxos['data'] <= data_limite]\n",
    "        saldos_acumulados = fluxos_ate_data.groupby('categoria')['valor'].sum()\n",
    "        linha = {'Prazo': f\"D+{dias}\"}\n",
    "        for col in colunas_relatorio: linha[col] = saldos_acumulados.get(col, 0.0)\n",
    "        linhas_relatorio.append(linha)\n",
    "    df_relatorio = pd.DataFrame(linhas_relatorio).set_index('Prazo')\n",
    "    df_relatorio['Disponibilidades'] = df_relatorio[colunas_relatorio[:4]].sum(axis=1)\n",
    "    df_relatorio['Necessidades'] = df_relatorio[colunas_relatorio[4:]].sum(axis=1)\n",
    "    df_relatorio['Caixa Projetado'] = df_relatorio['Disponibilidades'] + df_relatorio['Necessidades']\n",
    "    return df_relatorio.applymap('{:,.2f}'.format)\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO FINAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    dados_carteira_recente, data_referencia = encontrar_e_carregar_carteira_recente(PATH_CARTEIRAS_HISTORICO)\n",
    "    if dados_carteira_recente:\n",
    "        #df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "        df_despesas = processar_dados_despesas_final(PATH_DESPESAS, data_referencia)\n",
    "        df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "        relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "        print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (LÓGICA FINAL) ---\")\n",
    "        print(relatorio_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1da3c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "--- SUMÁRIO DAS FONTES DE DADOS UTILIZADAS ---\n",
      "==================================================\n",
      "1. PONTO DE PARTIDA (D+0):\n",
      "   - Arquivo de Carteira: 'carteira_52203615000119_20250829.json'\n",
      "   - Data de Referência..: 29/08/2025\n",
      "\n",
      "2. ENTRADAS DE CAIXA:\n",
      "   - Arquivo de Estoque..: 1644304 parcelas encontradas.\n",
      "   - Período Coberto.....: de 02/03/2024 a 26/10/2033\n",
      "\n",
      "3. SAÍDAS DE CAIXA:\n",
      "   - Arquivo de Despesas.: Usando o relatório gerado em 01/09/2025 como base.\n",
      "   - Lógica Aplicada.....: Despesas provisionadas neste arquivo foram projetadas para pagamentos futuros (5º dia útil de cada mês).\n",
      "==================================================\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (LÓGICA FINAL) ---\n",
      "      Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque       Despesas Amort./ Resgat. Cota Disponibilidades    Necessidades Caixa Projetado\n",
      "Prazo                                                                                                                                                   \n",
      "D+0      1,000.00        0.00               0.00      13,448,387.14           0.00                 0.00    13,449,387.14            0.00   13,449,387.14\n",
      "D+1      1,000.00  440,304.72               0.00      13,500,473.05           0.00                 0.00    13,941,777.77            0.00   13,941,777.77\n",
      "D+5      1,000.00  440,304.72               0.00      13,728,677.28           0.00                 0.00    14,169,982.00            0.00   14,169,982.00\n",
      "D+10     1,000.00  440,304.72               0.00      14,060,107.05    -457,778.52                 0.00    14,501,411.77     -457,778.52   14,043,633.25\n",
      "D+21     1,000.00  440,304.72               0.00      16,929,321.16    -457,778.52                 0.00    17,370,625.88     -457,778.52   16,912,847.36\n",
      "D+63     1,000.00  440,304.72               0.00      27,287,355.18    -686,667.78                 0.00    27,728,659.90     -686,667.78   27,041,992.12\n",
      "D+365    1,000.00  440,304.72               0.00      87,195,087.53  -2,975,560.38       -24,845,090.89    87,636,392.25  -27,820,651.27   59,815,740.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\3910402492.py:135: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_relatorio.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS PARA AS FONTES DE DADOS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\estoque_consolidado_agosto\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO FINAIS E CORRIGIDAS ---\n",
    "\n",
    "def encontrar_e_carregar_carteira_recente(caminho_pasta):\n",
    "    \"\"\"Encontra o arquivo de carteira mais recente pela data interna e carrega seus dados.\"\"\"\n",
    "    # ... (código da função sem alterações) ...\n",
    "    arquivos_json = glob.glob(os.path.join(caminho_pasta, \"*.json\"))\n",
    "    if not arquivos_json: return None, None\n",
    "    arquivo_mais_recente, data_mais_recente = None, None\n",
    "    for arquivo in arquivos_json:\n",
    "        try:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                dados = json.load(f)\n",
    "                data_atual_str = dados[0]['carteiras'][0]['dataAtual']\n",
    "                data_atual_obj = datetime.strptime(data_atual_str.split('T')[0], '%Y-%m-%d')\n",
    "                if data_mais_recente is None or data_atual_obj > data_mais_recente:\n",
    "                    data_mais_recente, arquivo_mais_recente = data_atual_obj, arquivo\n",
    "        except Exception: continue\n",
    "    if arquivo_mais_recente:\n",
    "        with open(arquivo_mais_recente, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)[0], data_mais_recente, os.path.basename(arquivo_mais_recente)\n",
    "    return None, None, None\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    # ... (código da função sem alterações) ...\n",
    "    arquivos_csv = glob.glob(os.path.join(caminho_pasta, \"*.csv\"))\n",
    "    if not arquivos_csv: return pd.DataFrame()\n",
    "    all_dfs = []\n",
    "    for file in arquivos_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-16', sep='\\t', engine='python', on_bad_lines='warn', header=0)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if not df.empty:\n",
    "                df['Valor Presente'] = pd.to_numeric(df['Valor Presente'].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "                df['Data Vencimento'] = pd.to_datetime(df['Data Vencimento'], errors='coerce', format='%Y-%m-%d', dayfirst=False)\n",
    "                all_dfs.append(df)\n",
    "        except Exception: continue\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "def processar_dados_despesas_final(caminho_pasta, data_base_projecao, meses_a_projetar=12):\n",
    "    \"\"\"Encontra o relatório de despesas mais recente e projeta suas provisões para o futuro.\"\"\"\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame(), None\n",
    "    df_mais_recente, data_relatorio_recente = None, None\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df_temp = pd.read_excel(arquivo, header=6)\n",
    "            df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce', dayfirst=True)\n",
    "            data_atual = df_temp['Data'].max()\n",
    "            if data_relatorio_recente is None or data_atual > data_relatorio_recente:\n",
    "                data_relatorio_recente, df_mais_recente = data_atual, df_temp\n",
    "        except Exception: continue\n",
    "    if df_mais_recente is None: return pd.DataFrame(), None\n",
    "    \n",
    "    df_base = df_mais_recente.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'})\n",
    "    df_base['Valor'] = -pd.to_numeric(df_base['Valor'], errors='coerce').abs()\n",
    "    df_base['Data Pagamento'] = pd.to_datetime(df_base['Data Pagamento'], errors='coerce', dayfirst=True)\n",
    "    df_base = df_base[['Categoria', 'Valor', 'Data Pagamento']].dropna()\n",
    "    despesas_finais = []\n",
    "    despesas_reais_futuras = df_base[df_base['Data Pagamento'] >= data_base_projecao]\n",
    "    despesas_finais.extend(despesas_reais_futuras.to_dict('records'))\n",
    "    mes_inicial_projecao = (data_base_projecao.replace(day=1) + relativedelta(months=1))\n",
    "    for i in range(meses_a_projetar):\n",
    "        mes_atual = mes_inicial_projecao + relativedelta(months=i)\n",
    "        data_pagamento_proj = mes_atual.replace(day=5)\n",
    "        while data_pagamento_proj.weekday() >= 5: data_pagamento_proj += timedelta(days=1)\n",
    "        if data_pagamento_proj >= data_base_projecao:\n",
    "            for _, row in df_base.iterrows():\n",
    "                despesas_finais.append({'Data Pagamento': data_pagamento_proj, 'Categoria': row['Categoria'], 'Valor': row['Valor']})\n",
    "    df_final = pd.DataFrame(despesas_finais)\n",
    "    return df_final, data_relatorio_recente\n",
    "\n",
    "# --- DEMAIS FUNÇÕES FINAIS ---\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    # ... (código da função sem alterações) ...\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade: fluxos.append({'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']: fluxos.append({'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': cota['valorBruto']})\n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']: fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': titulo['mercadoAtual']})\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente', 'Status'])\n",
    "        status_a_incluir = ['A vencer', 'Previsto', 'Vencido']\n",
    "        estoque_filtrado = estoque_valido[estoque_valido['Status'].isin(status_a_incluir)]\n",
    "        for _, row in estoque_filtrado.iterrows(): fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Pagamentos Estoque', 'valor': row['Valor Presente']})\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base]\n",
    "        for _, despesa in despesas_futuras.iterrows(): fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas', 'valor': despesa['Valor']})\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "def gerar_relatorio_d_mais(df_fluxos, data_base):\n",
    "    # ... (código da função sem alterações) ...\n",
    "    prazos = [0, 1, 5, 10, 21, 63, 365]\n",
    "    colunas_relatorio = ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
    "    linhas_relatorio = []\n",
    "    for dias in prazos:\n",
    "        data_limite = data_base + timedelta(days=dias)\n",
    "        fluxos_ate_data = df_fluxos[df_fluxos['data'] <= data_limite]\n",
    "        saldos_acumulados = fluxos_ate_data.groupby('categoria')['valor'].sum()\n",
    "        linha = {'Prazo': f\"D+{dias}\"}\n",
    "        for col in colunas_relatorio: linha[col] = saldos_acumulados.get(col, 0.0)\n",
    "        linhas_relatorio.append(linha)\n",
    "    df_relatorio = pd.DataFrame(linhas_relatorio).set_index('Prazo')\n",
    "    df_relatorio['Disponibilidades'] = df_relatorio[colunas_relatorio[:4]].sum(axis=1)\n",
    "    df_relatorio['Necessidades'] = df_relatorio[colunas_relatorio[4:]].sum(axis=1)\n",
    "    df_relatorio['Caixa Projetado'] = df_relatorio['Disponibilidades'] + df_relatorio['Necessidades']\n",
    "    return df_relatorio.applymap('{:,.2f}'.format)\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO FINAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Carrega todas as fontes de dados\n",
    "    dados_carteira_recente, data_referencia, nome_arquivo_carteira = encontrar_e_carregar_carteira_recente(PATH_CARTEIRAS_HISTORICO)\n",
    "    \n",
    "    if dados_carteira_recente:\n",
    "        df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "        df_despesas, data_relatorio_despesas = processar_dados_despesas_final(PATH_DESPESAS, data_referencia)\n",
    "        \n",
    "        # 2. **NOVO** Bloco de Sumário de Datas\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"--- SUMÁRIO DAS FONTES DE DADOS UTILIZADAS ---\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"1. PONTO DE PARTIDA (D+0):\")\n",
    "        print(f\"   - Arquivo de Carteira: '{nome_arquivo_carteira}'\")\n",
    "        print(f\"   - Data de Referência..: {data_referencia.strftime('%d/%m/%Y')}\")\n",
    "        \n",
    "        print(f\"\\n2. ENTRADAS DE CAIXA:\")\n",
    "        if not df_estoque.empty:\n",
    "            print(f\"   - Arquivo de Estoque..: {df_estoque.shape[0]} parcelas encontradas.\")\n",
    "            data_min_estoque = df_estoque['Data Vencimento'].dropna().min()\n",
    "            data_max_estoque = df_estoque['Data Vencimento'].dropna().max()\n",
    "            print(f\"   - Período Coberto.....: de {data_min_estoque.strftime('%d/%m/%Y')} a {data_max_estoque.strftime('%d/%m/%Y')}\")\n",
    "        \n",
    "        print(f\"\\n3. SAÍDAS DE CAIXA:\")\n",
    "        if data_relatorio_despesas:\n",
    "            print(f\"   - Arquivo de Despesas.: Usando o relatório gerado em {data_relatorio_despesas.strftime('%d/%m/%Y')} como base.\")\n",
    "            print(f\"   - Lógica Aplicada.....: Despesas provisionadas neste arquivo foram projetadas para pagamentos futuros (5º dia útil de cada mês).\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 3. Prepara e gera o relatório final\n",
    "        df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "        relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "\n",
    "        print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (LÓGICA FINAL) ---\")\n",
    "        print(relatorio_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b4646b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando dados do novo estoque...\n",
      "Usando o conjunto de estoque da data: 29.08.25\n",
      "Dados do novo estoque consolidados: 1644304 linhas.\n",
      "\n",
      "==================================================\n",
      "--- SUMÁRIO DAS FONTES DE DADOS UTILIZADAS ---\n",
      "==================================================\n",
      "1. PONTO DE PARTIDA (D+0):\n",
      "   - Arquivo de Carteira: 'carteira_52203615000119_20250829.json'\n",
      "   - Data de Referência..: 29/08/2025\n",
      "\n",
      "2. ENTRADAS DE CAIXA:\n",
      "   - Arquivo de Estoque..: 1644304 parcelas encontradas.\n",
      "   - Período Coberto.....: de 02/03/2024 a 26/10/2033\n",
      "\n",
      "3. SAÍDAS DE CAIXA:\n",
      "   - Arquivo de Despesas.: Usando o relatório gerado em 01/09/2025 como base.\n",
      "   - Lógica Aplicada.....: Despesas provisionadas neste arquivo foram projetadas para pagamentos futuros (5º dia útil de cada mês).\n",
      "==================================================\n",
      "\n",
      "1589899 parcelas do estoque com vencimento futuro foram incluídas na projeção.\n",
      "\n",
      "--- PROJEÇÃO DE FLUXO DE CAIXA (LÓGICA FINAL) ---\n",
      "      Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque       Despesas Amort./ Resgat. Cota Disponibilidades    Necessidades Caixa Projetado\n",
      "Prazo                                                                                                                                                   \n",
      "D+0      1,000.00        0.00               0.00          42,252.11           0.00                 0.00        43,252.11            0.00       43,252.11\n",
      "D+1      1,000.00  440,304.72               0.00          94,338.02           0.00                 0.00       535,642.74            0.00      535,642.74\n",
      "D+5      1,000.00  440,304.72               0.00         322,542.25           0.00                 0.00       763,846.97            0.00      763,846.97\n",
      "D+10     1,000.00  440,304.72               0.00         653,972.02    -457,778.52                 0.00     1,095,276.74     -457,778.52      637,498.22\n",
      "D+21     1,000.00  440,304.72               0.00       3,523,186.13    -457,778.52                 0.00     3,964,490.85     -457,778.52    3,506,712.33\n",
      "D+63     1,000.00  440,304.72               0.00      13,881,220.15    -686,667.78                 0.00    14,322,524.87     -686,667.78   13,635,857.09\n",
      "D+365    1,000.00  440,304.72               0.00      73,788,952.50  -2,975,560.38       -24,845,090.89    74,230,257.22  -27,820,651.27   46,409,605.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_16300\\514727119.py:166: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df_relatorio.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "# --- CAMINHOS PARA AS FONTES DE DADOS FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Estoques\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO FINAIS E CORRIGIDAS ---\n",
    "\n",
    "def encontrar_e_carregar_carteira_recente(caminho_pasta):\n",
    "    \"\"\"Encontra o arquivo de carteira mais recente pela data interna e carrega seus dados.\"\"\"\n",
    "    # ... (código da função sem alterações) ...\n",
    "    arquivos_json = glob.glob(os.path.join(caminho_pasta, \"*.json\"))\n",
    "    if not arquivos_json: return None, None\n",
    "    arquivo_mais_recente, data_mais_recente = None, None\n",
    "    for arquivo in arquivos_json:\n",
    "        try:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                dados = json.load(f)\n",
    "                data_atual_str = dados[0]['carteiras'][0]['dataAtual']\n",
    "                data_atual_obj = datetime.strptime(data_atual_str.split('T')[0], '%Y-%m-%d')\n",
    "                if data_mais_recente is None or data_atual_obj > data_mais_recente:\n",
    "                    data_mais_recente, arquivo_mais_recente = data_atual_obj, arquivo\n",
    "        except Exception: continue\n",
    "    if arquivo_mais_recente:\n",
    "        with open(arquivo_mais_recente, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)[0], data_mais_recente, os.path.basename(arquivo_mais_recente)\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def processar_dados_estoque(caminho_pasta):\n",
    "    \"\"\"Lê o conjunto de arquivos de estoque mais recente da pasta e o prepara para a análise.\"\"\"\n",
    "    print(\"\\nCarregando dados do novo estoque...\")\n",
    "    todos_arquivos = glob.glob(os.path.join(caminho_pasta, '**/*.csv'), recursive=True)\n",
    "    if not todos_arquivos: return pd.DataFrame()\n",
    "    data_recente = None\n",
    "    regex_data = re.compile(r'(\\d{2}\\.\\d{2}\\.\\d{2})')\n",
    "    for arquivo in todos_arquivos:\n",
    "        match = regex_data.search(os.path.basename(arquivo))\n",
    "        if match:\n",
    "            data_obj = datetime.strptime(match.group(1), '%d.%m.%y')\n",
    "            if data_recente is None or data_obj > data_recente: data_recente = data_obj\n",
    "    if data_recente is None: return pd.DataFrame()\n",
    "    data_recente_str = data_recente.strftime('%d.%m.%y')\n",
    "    print(f\"Usando o conjunto de estoque da data: {data_recente_str}\")\n",
    "    arquivos_para_ler = [f for f in todos_arquivos if data_recente_str in os.path.basename(f)]\n",
    "    lista_dfs_partes = []\n",
    "    for arquivo in arquivos_para_ler:\n",
    "        try:\n",
    "            df_parte = pd.read_csv(arquivo, sep=';', decimal=',', encoding='utf-8', on_bad_lines='warn')\n",
    "            lista_dfs_partes.append(df_parte)\n",
    "        except Exception: continue\n",
    "    if not lista_dfs_partes: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_dfs_partes, ignore_index=True)\n",
    "    df_consolidado.rename(columns={'DataVencimento': 'Data Vencimento', 'ValorPresente': 'Valor Presente'}, inplace=True)\n",
    "    df_consolidado['Data Vencimento'] = pd.to_datetime(df_consolidado['Data Vencimento'], dayfirst=True, errors='coerce')\n",
    "    df_consolidado['Valor Presente'] = pd.to_numeric(df_consolidado['Valor Presente'], errors='coerce')\n",
    "    print(f\"Dados do novo estoque consolidados: {len(df_consolidado)} linhas.\")\n",
    "    return df_consolidado\n",
    "\n",
    "def processar_dados_despesas_final(caminho_pasta, data_base_projecao, meses_a_projetar=12):\n",
    "    \"\"\"Encontra o relatório de despesas mais recente e projeta suas provisões para o futuro.\"\"\"\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame(), None\n",
    "    df_mais_recente, data_relatorio_recente = None, None\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df_temp = pd.read_excel(arquivo, header=6)\n",
    "            df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce', dayfirst=True)\n",
    "            data_atual = df_temp['Data'].max()\n",
    "            if data_relatorio_recente is None or data_atual > data_relatorio_recente:\n",
    "                data_relatorio_recente, df_mais_recente = data_atual, df_temp\n",
    "        except Exception: continue\n",
    "    if df_mais_recente is None: return pd.DataFrame(), None\n",
    "    \n",
    "    df_base = df_mais_recente.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'})\n",
    "    df_base['Valor'] = -pd.to_numeric(df_base['Valor'], errors='coerce').abs()\n",
    "    df_base['Data Pagamento'] = pd.to_datetime(df_base['Data Pagamento'], errors='coerce', dayfirst=True)\n",
    "    df_base = df_base[['Categoria', 'Valor', 'Data Pagamento']].dropna()\n",
    "    despesas_finais = []\n",
    "    despesas_reais_futuras = df_base[df_base['Data Pagamento'] >= data_base_projecao]\n",
    "    despesas_finais.extend(despesas_reais_futuras.to_dict('records'))\n",
    "    mes_inicial_projecao = (data_base_projecao.replace(day=1) + relativedelta(months=1))\n",
    "    for i in range(meses_a_projetar):\n",
    "        mes_atual = mes_inicial_projecao + relativedelta(months=i)\n",
    "        data_pagamento_proj = mes_atual.replace(day=5)\n",
    "        while data_pagamento_proj.weekday() >= 5: data_pagamento_proj += timedelta(days=1)\n",
    "        if data_pagamento_proj >= data_base_projecao:\n",
    "            for _, row in df_base.iterrows():\n",
    "                despesas_finais.append({'Data Pagamento': data_pagamento_proj, 'Categoria': row['Categoria'], 'Valor': row['Valor']})\n",
    "    df_final = pd.DataFrame(despesas_finais)\n",
    "    return df_final, data_relatorio_recente\n",
    "\n",
    "# --- DEMAIS FUNÇÕES FINAIS ---\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # Disponibilidades\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade: fluxos.append({'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo']})\n",
    "\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']: fluxos.append({'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': cota['valorBruto']})\n",
    "\n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']: fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': titulo['mercadoAtual']})\n",
    "\n",
    "    # Pagamentos do Estoque (COM FILTRO APENAS POR DATA)\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente'])\n",
    "        \n",
    "        # ### A LÓGICA CORRIGIDA E SIMPLIFICADA ESTÁ AQUI ###\n",
    "        estoque_futuro = estoque_valido[estoque_valido['Data Vencimento'] >= data_base]\n",
    "        \n",
    "        print(f\"\\n{len(estoque_futuro)} parcelas do estoque com vencimento futuro foram incluídas na projeção.\")\n",
    "        \n",
    "        for _, row in estoque_futuro.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Pagamentos Estoque', 'valor': row['Valor Presente']})\n",
    "\n",
    "    # Necessidades\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base]\n",
    "        for _, despesa in despesas_futuras.iterrows(): fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas', 'valor': despesa['Valor']})\n",
    "\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao})\n",
    "            \n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "def gerar_relatorio_d_mais(df_fluxos, data_base):\n",
    "    # ... (código da função sem alterações) ...\n",
    "    prazos = [0, 1, 5, 10, 21, 63, 365]\n",
    "    colunas_relatorio = ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
    "    linhas_relatorio = []\n",
    "    for dias in prazos:\n",
    "        data_limite = data_base + timedelta(days=dias)\n",
    "        fluxos_ate_data = df_fluxos[df_fluxos['data'] <= data_limite]\n",
    "        saldos_acumulados = fluxos_ate_data.groupby('categoria')['valor'].sum()\n",
    "        linha = {'Prazo': f\"D+{dias}\"}\n",
    "        for col in colunas_relatorio: linha[col] = saldos_acumulados.get(col, 0.0)\n",
    "        linhas_relatorio.append(linha)\n",
    "    df_relatorio = pd.DataFrame(linhas_relatorio).set_index('Prazo')\n",
    "    df_relatorio['Disponibilidades'] = df_relatorio[colunas_relatorio[:4]].sum(axis=1)\n",
    "    df_relatorio['Necessidades'] = df_relatorio[colunas_relatorio[4:]].sum(axis=1)\n",
    "    df_relatorio['Caixa Projetado'] = df_relatorio['Disponibilidades'] + df_relatorio['Necessidades']\n",
    "    return df_relatorio.applymap('{:,.2f}'.format)\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO FINAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Carrega todas as fontes de dados\n",
    "    dados_carteira_recente, data_referencia, nome_arquivo_carteira = encontrar_e_carregar_carteira_recente(PATH_CARTEIRAS_HISTORICO)\n",
    "    \n",
    "    if dados_carteira_recente:\n",
    "        df_estoque = processar_dados_estoque(PATH_ESTOQUE)\n",
    "        df_despesas, data_relatorio_despesas = processar_dados_despesas_final(PATH_DESPESAS, data_referencia)\n",
    "        \n",
    "        # 2. **NOVO** Bloco de Sumário de Datas\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"--- SUMÁRIO DAS FONTES DE DADOS UTILIZADAS ---\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"1. PONTO DE PARTIDA (D+0):\")\n",
    "        print(f\"   - Arquivo de Carteira: '{nome_arquivo_carteira}'\")\n",
    "        print(f\"   - Data de Referência..: {data_referencia.strftime('%d/%m/%Y')}\")\n",
    "        \n",
    "        print(f\"\\n2. ENTRADAS DE CAIXA:\")\n",
    "        if not df_estoque.empty:\n",
    "            print(f\"   - Arquivo de Estoque..: {df_estoque.shape[0]} parcelas encontradas.\")\n",
    "            data_min_estoque = df_estoque['Data Vencimento'].dropna().min()\n",
    "            data_max_estoque = df_estoque['Data Vencimento'].dropna().max()\n",
    "            print(f\"   - Período Coberto.....: de {data_min_estoque.strftime('%d/%m/%Y')} a {data_max_estoque.strftime('%d/%m/%Y')}\")\n",
    "        \n",
    "        print(f\"\\n3. SAÍDAS DE CAIXA:\")\n",
    "        if data_relatorio_despesas:\n",
    "            print(f\"   - Arquivo de Despesas.: Usando o relatório gerado em {data_relatorio_despesas.strftime('%d/%m/%Y')} como base.\")\n",
    "            print(f\"   - Lógica Aplicada.....: Despesas provisionadas neste arquivo foram projetadas para pagamentos futuros (5º dia útil de cada mês).\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 3. Prepara e gera o relatório final\n",
    "        df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "        relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "\n",
    "        print(\"\\n--- PROJEÇÃO DE FLUXO DE CAIXA (LÓGICA FINAL) ---\")\n",
    "        print(relatorio_final.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35ac0643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relatório HTML gerado com sucesso: 'c:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\relatorio_fluxo_de_caixa.html'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CONFIGURAÇÕES ---\n",
    "\n",
    "# !! IMPORTANTE !!\n",
    "# 1. Coloque o caminho para o arquivo da sua logo aqui.\n",
    "#    Se o logo estiver na mesma pasta do script, basta o nome do arquivo (ex: \"logo.png\")\n",
    "CAMINHO_DO_LOGO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\images\\logo_inv.png\"\n",
    "\n",
    "# 2. Informações para o cabeçalho do relatório\n",
    "NOME_DO_FUNDO = \"FIDC FCT CONSIGNADO II\"\n",
    "NOME_ARQUIVO_SAIDA = \"relatorio_fluxo_de_caixa.html\"\n",
    "\n",
    "# (Assumindo que o DataFrame 'relatorio_final' e 'data_referencia' já existem no seu notebook)\n",
    "# Se não existirem, descomente e ajuste as linhas abaixo para teste:\n",
    "# data_referencia = datetime(2025, 8, 29)\n",
    "# relatorio_final = pd.DataFrame({\n",
    "#     'Conta Corr.': ['1,000.00', '1,000.00'], 'Fundo inv.': ['0.00', '440,304.72'],\n",
    "#     'Títulos Renda Fixa': ['0.00', '0.00'], 'Pagamentos Estoque': ['42,252.11', '94,338.02'],\n",
    "#     'Despesas': ['0.00', '0.00'], 'Amort./ Resgat. Cota': ['0.00', '0.00'],\n",
    "#     'Disponibilidades': ['43,252.11', '535,642.74'], 'Necessidades': ['0.00', '0.00'],\n",
    "#     'Caixa Projetado': ['43,252.11', '535,642.74']\n",
    "# }, index=pd.Index(['D+0', 'D+1'], name='Prazo'))\n",
    "\n",
    "\n",
    "# --- FUNÇÃO PARA CODIFICAR A LOGO ---\n",
    "\n",
    "def codificar_imagem_base64(caminho_imagem):\n",
    "    \"\"\"Lê um arquivo de imagem e o converte para o formato base64.\"\"\"\n",
    "    try:\n",
    "        with open(caminho_imagem, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"AVISO: Arquivo de logo não encontrado em '{caminho_imagem}'. Um placeholder será usado.\")\n",
    "        # Retorna um pixel transparente como placeholder\n",
    "        return \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\"\n",
    "\n",
    "\n",
    "# --- GERAÇÃO DO HTML ---\n",
    "\n",
    "def gerar_relatorio_html(df, nome_fundo, data_ref, caminho_logo, arquivo_saida):\n",
    "    \"\"\"Gera o arquivo HTML completo com base no DataFrame e nas especificações de estilo.\"\"\"\n",
    "    \n",
    "    logo_base64 = codificar_imagem_base64(caminho_logo)\n",
    "    \n",
    "    # Converte o DataFrame para uma tabela HTML, adicionando classes para estilização\n",
    "    tabela_html = df.to_html(classes=\"display compact\", table_id=\"relatorioTabela\", border=0)\n",
    "\n",
    "    # Template HTML completo com CSS e JavaScript\n",
    "    html_template = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"pt-BR\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Relatório de Fluxo de Caixa</title>\n",
    "        \n",
    "        <link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css\">\n",
    "        <link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.datatables.net/fixedcolumns/4.3.0/css/fixedColumns.dataTables.min.css\">\n",
    "\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: \"Gill Sans MT\", Arial, sans-serif;\n",
    "                background-color: #FFFFFF;\n",
    "                color: #313131;\n",
    "                font-size: 1.1em;\n",
    "                padding: 20px;\n",
    "            }}\n",
    "            h1 {{\n",
    "                font-size: 2.2em;\n",
    "                color: #163f3f;\n",
    "                margin: 0;\n",
    "            }}\n",
    "            h2 {{\n",
    "                font-size: 1.5em;\n",
    "                color: #163f3f;\n",
    "                border-bottom: 2px solid #163f3f;\n",
    "                padding-bottom: 5px;\n",
    "            }}\n",
    "            .header-container {{\n",
    "                display: flex;\n",
    "                align-items: center;\n",
    "                margin-bottom: 20px;\n",
    "            }}\n",
    "            .info-box {{\n",
    "                border: 1px solid #e0e0e0;\n",
    "                background-color: #f5f5f5;\n",
    "                padding: 15px;\n",
    "                margin-bottom: 30px;\n",
    "            }}\n",
    "            \n",
    "            /* Estilos da Tabela 📊 */\n",
    "            table.dataTable thead th {{\n",
    "                background-color: #163f3f !important;\n",
    "                color: white !important;\n",
    "                border-bottom: 2px solid #0e3030;\n",
    "            }}\n",
    "            table.dataTable.display tbody tr.odd {{\n",
    "                background-color: #f5f5f5;\n",
    "            }}\n",
    "            table.dataTable.display tbody tr.even {{\n",
    "                background-color: #e0e0e0;\n",
    "            }}\n",
    "            table.dataTable tbody tr:hover {{\n",
    "                background-color: #FFD8A7 !important;\n",
    "            }}\n",
    "            \n",
    "            /* Coluna Fixa */\n",
    "            table.dataTable tbody th {{\n",
    "                font-weight: bold;\n",
    "                background-color: #0e3030;\n",
    "                color: white;\n",
    "            }}\n",
    "\n",
    "            /* Corte de texto no cabeçalho */\n",
    "            th.truncate {{\n",
    "                white-space: nowrap;\n",
    "                overflow: hidden;\n",
    "                text-overflow: ellipsis;\n",
    "                max-width: 150px; /* Ajuste conforme necessário */\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "\n",
    "        <div class=\"header-container\">\n",
    "            <img src=\"data:image/png;base64,{logo_base64}\" style=\"max-height:80px; margin-right:20px;\">\n",
    "            <h1>Relatório de Fluxo de Caixa</h1>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"info-box\">\n",
    "            <strong>Fundo:</strong> {nome_fundo}<br>\n",
    "            <strong>Data do Relatório:</strong> {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}<br>\n",
    "            <strong>Data de Referência (D+0):</strong> {data_ref.strftime('%d/%m/%Y')}\n",
    "        </div>\n",
    "\n",
    "        <h2>Projeção de Caixa por Prazo</h2>\n",
    "        \n",
    "        {tabela_html}\n",
    "\n",
    "        <script type=\"text/javascript\" src=\"https://code.jquery.com/jquery-3.7.0.js\"></script>\n",
    "        <script type=\"text/javascript\" src=\"https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js\"></script>\n",
    "        <script type=\"text/javascript\" src=\"https://cdn.datatables.net/fixedcolumns/4.3.0/js/dataTables.fixedColumns.min.js\"></script>\n",
    "        \n",
    "        <script type=\"text/javascript\">\n",
    "            jQuery.fn.dataTable.ext.type.order['brazilian-number-pre'] = function ( a ) {{\n",
    "                var x = a.replace( /[.\\\\sR$]/g, '' ).replace( ',', '.' );\n",
    "                return parseFloat( x );\n",
    "            }};\n",
    "        </script>\n",
    "\n",
    "        <script>\n",
    "            $(document).ready(function() {{\n",
    "                $('#relatorioTabela').DataTable({{\n",
    "                    \"scrollX\": true,\n",
    "                    \"fixedColumns\": {{\n",
    "                        left: 1 // Fixa a primeira coluna (Prazo)\n",
    "                    }},\n",
    "                    \"paging\": false,\n",
    "                    \"searching\": false,\n",
    "                    \"info\": false,\n",
    "                    \"columnDefs\": [\n",
    "                        {{ \"type\": \"brazilian-number\", \"targets\": \"_all\" }}\n",
    "                    ]\n",
    "                }});\n",
    "\n",
    "                // Adiciona tooltip aos cabeçalhos com texto cortado\n",
    "                $('th.truncate').each(function(){{\n",
    "                    $(this).attr('title', $(this).text());\n",
    "                }});\n",
    "            }});\n",
    "        </script>\n",
    "\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Salva o conteúdo em um arquivo .html\n",
    "    try:\n",
    "        with open(arquivo_saida, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_template)\n",
    "        print(f\"✅ Relatório HTML gerado com sucesso: '{os.path.abspath(arquivo_saida)}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao salvar o arquivo HTML: {e}\")\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO ---\n",
    "if __name__ == \"__main__\":\n",
    "    gerar_relatorio_html(\n",
    "        df=relatorio_final, \n",
    "        nome_fundo=NOME_DO_FUNDO, \n",
    "        data_ref=data_referencia, \n",
    "        caminho_logo=CAMINHO_DO_LOGO,\n",
    "        arquivo_saida=NOME_ARQUIVO_SAIDA\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c798fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relatório HTML interativo gerado com sucesso: 'c:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\relatorio_fluxo_de_caixa.html'\n"
     ]
    }
   ],
   "source": [
    "# --- FUNÇÃO PARA CODIFICAR A LOGO ---\n",
    "def codificar_imagem_base64(caminho_imagem):\n",
    "    try:\n",
    "        with open(caminho_imagem, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"AVISO: Arquivo de logo não encontrado. Um placeholder será usado.\")\n",
    "        return \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\"\n",
    "\n",
    "# --- NOVA GERAÇÃO DO HTML ---\n",
    "\n",
    "def gerar_relatorio_html_interativo(df_summary, df_details, nome_fundo, data_ref, caminho_logo, arquivo_saida):\n",
    "    \"\"\"Gera o arquivo HTML interativo com funcionalidade de drill-down.\"\"\"\n",
    "    \n",
    "    logo_base64 = codificar_imagem_base64(caminho_logo)\n",
    "    \n",
    "    # Prepara os dados detalhados para serem embutidos como JSON no HTML\n",
    "    df_details['data'] = df_details['data'].dt.strftime('%d/%m/%Y')\n",
    "    dados_detalhados_json = df_details.to_json(orient='records')\n",
    "\n",
    "    # ---- Construção manual da tabela principal para adicionar atributos de dados ----\n",
    "    tabela_html = '<table id=\"relatorioTabela\" class=\"display compact\"><thead><tr><th>Prazo</th>'\n",
    "    for col in df_summary.columns:\n",
    "        tabela_html += f'<th>{col}</th>'\n",
    "    tabela_html += '</tr></thead><tbody>'\n",
    "    \n",
    "    for prazo, row in df_summary.iterrows():\n",
    "        tabela_html += f'<tr><th>{prazo}</th>'\n",
    "        for col, value in row.items():\n",
    "            # Adiciona os atributos data-* nas células para identificar o que foi clicado\n",
    "            tabela_html += f'<td data-prazo=\"{prazo}\" data-categoria=\"{col}\">{value}</td>'\n",
    "        tabela_html += '</tr>'\n",
    "        \n",
    "    tabela_html += '</tbody></table>'\n",
    "\n",
    "    # Template HTML completo com a nova estrutura do modal e JavaScript\n",
    "    html_template = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"pt-BR\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Relatório de Fluxo de Caixa Interativo</title>\n",
    "        \n",
    "        <link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css\">\n",
    "        <link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.datatables.net/fixedcolumns/4.3.0/css/fixedColumns.dataTables.min.css\">\n",
    "\n",
    "        <style>\n",
    "            /* (Estilos CSS da versão anterior, omitidos para brevidade) */\n",
    "            body {{ font-family: \"Gill Sans MT\", Arial, sans-serif; background-color: #FFFFFF; color: #313131; font-size: 1.1em; padding: 20px; }}\n",
    "            h1 {{ font-size: 2.2em; color: #163f3f; margin: 0; }}\n",
    "            .header-container {{ display: flex; align-items: center; margin-bottom: 20px; }}\n",
    "            .info-box {{ border: 1px solid #e0e0e0; background-color: #f5f5f5; padding: 15px; margin-bottom: 30px; }}\n",
    "            table.dataTable thead th {{ background-color: #163f3f !important; color: white !important; }}\n",
    "            table.dataTable.display tbody tr.odd {{ background-color: #f5f5f5; }}\n",
    "            table.dataTable.display tbody tr.even {{ background-color: #e0e0e0; }}\n",
    "            table.dataTable tbody tr:hover {{ background-color: #FFD8A7 !important; }}\n",
    "            table.dataTable tbody th {{ font-weight: bold; background-color: #0e3030; color: white; }}\n",
    "\n",
    "            /* Estilos para células clicáveis e modal */\n",
    "            #relatorioTabela tbody td:not(:empty) {{ cursor: pointer; }}\n",
    "            .modal {{ display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgba(0,0,0,0.5); }}\n",
    "            .modal-content {{ background-color: #fefefe; margin: 5% auto; padding: 20px; border: 1px solid #888; width: 80%; max-width: 900px; }}\n",
    "            .close-button {{ color: #aaa; float: right; font-size: 28px; font-weight: bold; cursor: pointer; }}\n",
    "            #modal-table-container table {{ width: 100%; border-collapse: collapse; }}\n",
    "            #modal-table-container th, #modal-table-container td {{ border: 1px solid #ddd; padding: 8px; }}\n",
    "            #modal-table-container th {{ background-color: #f2f2f2; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "\n",
    "        <div class=\"header-container\">\n",
    "            <img src=\"data:image/png;base64,{logo_base64}\" style=\"max-height:80px; margin-right:20px;\">\n",
    "            <h1>Relatório de Fluxo de Caixa Interativo</h1>\n",
    "        </div>\n",
    "        <div class=\"info-box\">\n",
    "            <strong>Fundo:</strong> {nome_fundo}<br>\n",
    "            <strong>Data do Relatório:</strong> {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}<br>\n",
    "            <strong>Data de Referência (D+0):</strong> {data_ref.strftime('%d/%m/%Y')}\n",
    "        </div>\n",
    "        \n",
    "        {tabela_html}\n",
    "\n",
    "        <div id=\"detailModal\" class=\"modal\">\n",
    "            <div class=\"modal-content\">\n",
    "                <span class=\"close-button\">&times;</span>\n",
    "                <h2 id=\"modal-title\">Detalhamento</h2>\n",
    "                <div id=\"modal-table-container\" style=\"max-height: 400px; overflow-y: auto;\"></div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <script src=\"https://code.jquery.com/jquery-3.7.0.js\"></script>\n",
    "        <script src=\"https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js\"></script>\n",
    "        <script src=\"https://cdn.datatables.net/fixedcolumns/4.3.0/js/dataTables.fixedColumns.min.js\"></script>\n",
    "\n",
    "        <script>\n",
    "            var dadosDetalhados = {dados_detalhados_json};\n",
    "            var dataReferencia = new Date('{data_ref.strftime(\"%Y-%m-%d\")}T00:00:00');\n",
    "        </script>\n",
    "\n",
    "        <script>\n",
    "        $(document).ready(function() {{\n",
    "            // Inicializa a tabela principal\n",
    "            $('#relatorioTabela').DataTable({{ \"scrollX\": true, \"fixedColumns\": {{ left: 1 }}, \"paging\": false, \"searching\": false, \"info\": false, \"ordering\": false }});\n",
    "\n",
    "            var modal = $('#detailModal');\n",
    "            \n",
    "            // Lógica para ABRIR o modal\n",
    "            $('#relatorioTabela tbody').on('click', 'td', function() {{\n",
    "                var cell = $(this);\n",
    "                var prazo = cell.data('prazo');\n",
    "                var categoria = cell.data('categoria');\n",
    "                \n",
    "                // Ignora cliques em colunas de resumo ou células vazias\n",
    "                if (!prazo || !categoria || ['Disponibilidades', 'Necessidades', 'Caixa Projetado'].includes(categoria) || cell.text() === '0.00') {{\n",
    "                    return;\n",
    "                }}\n",
    "\n",
    "                var dias = parseInt(prazo.replace('D+', ''));\n",
    "                var dataLimite = new Date(dataReferencia);\n",
    "                dataLimite.setDate(dataLimite.getDate() + dias);\n",
    "\n",
    "                // Filtra os dados detalhados\n",
    "                var itensFiltrados = dadosDetalhados.filter(function(item) {{\n",
    "                    var dataItem = new Date(item.data.split('/').reverse().join('-'));\n",
    "                    return item.categoria === categoria && dataItem <= dataLimite;\n",
    "                }});\n",
    "\n",
    "                // Cria a tabela de detalhes\n",
    "                var tableHtml = '<table><thead><tr><th>Data</th><th>Valor</th></tr></thead><tbody>';\n",
    "                var total = 0;\n",
    "                itensFiltrados.forEach(function(item) {{\n",
    "                    total += item.valor;\n",
    "                    tableHtml += '<tr><td>' + item.data + '</td><td>' + item.valor.toLocaleString('pt-BR', {{style: 'currency', currency: 'BRL'}}) + '</td></tr>';\n",
    "                }});\n",
    "                tableHtml += '</tbody><tfoot><tr><th>Total</th><th>' + total.toLocaleString('pt-BR', {{style: 'currency', currency: 'BRL'}}) + '</th></tr></tfoot></table>';\n",
    "\n",
    "                // Preenche e exibe o modal\n",
    "                $('#modal-title').text('Detalhamento de: ' + categoria + ' (até ' + prazo + ')');\n",
    "                $('#modal-table-container').html(tableHtml);\n",
    "                modal.show();\n",
    "            }});\n",
    "\n",
    "            // Lógica para FECHAR o modal\n",
    "            $('.close-button').on('click', function() {{\n",
    "                modal.hide();\n",
    "            }});\n",
    "            $(window).on('click', function(event) {{\n",
    "                if (event.target == modal[0]) {{\n",
    "                    modal.hide();\n",
    "                }}\n",
    "            }});\n",
    "        }});\n",
    "        </script>\n",
    "\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(arquivo_saida, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_template)\n",
    "        print(f\"✅ Relatório HTML interativo gerado com sucesso: '{os.path.abspath(arquivo_saida)}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao salvar o arquivo HTML: {e}\")\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO ---\n",
    "# (Certifique-se de que os DataFrames 'relatorio_final' e 'df_fluxos_detalhados'\n",
    "#  e a variável 'data_referencia' existam no seu ambiente Jupyter)\n",
    "if 'relatorio_final' in locals() and 'df_fluxos_detalhados' in locals():\n",
    "    gerar_relatorio_html_interativo(\n",
    "        df_summary=relatorio_final, \n",
    "        df_details=df_fluxos_detalhados,\n",
    "        nome_fundo=NOME_DO_FUNDO, \n",
    "        data_ref=data_referencia, \n",
    "        caminho_logo=CAMINHO_DO_LOGO,\n",
    "        arquivo_saida=NOME_ARQUIVO_SAIDA\n",
    "    )\n",
    "else:\n",
    "    print(\"AVISO: DataFrame 'relatorio_final' ou 'df_fluxos_detalhados' não encontrado. Execute o script principal primeiro.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DEPURAÇÃO: Inspecionando o carregamento do Novo Estoque ---\n",
      "1. Usando o conjunto de estoque da data: 29.08.25\n",
      "\n",
      "2. Arquivos lidos e consolidados. Total de 1644304 linhas.\n",
      "\n",
      "3. Amostra dos dados brutos (primeiras 5 linhas):\n",
      "       Situacao PES_TIPO_PESSOA      CedenteCnpjCpf  TIT_CEDENTE_ENT_CODIGO  \\\n",
      "0  Sem cobrança               J  34.337.707/0001-00                  318853   \n",
      "1  Sem cobrança               J  34.337.707/0001-00                  318853   \n",
      "2  Sem cobrança               J  34.337.707/0001-00                  318853   \n",
      "3  Sem cobrança               J  34.337.707/0001-00                  318853   \n",
      "4  Sem cobrança               J  34.337.707/0001-00                  318853   \n",
      "\n",
      "                                      CedenteNome     Cnae  \\\n",
      "0  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  6499999   \n",
      "1  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  6499999   \n",
      "2  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  6499999   \n",
      "3  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  6499999   \n",
      "4  BMP MONEY PLUS SOCIEDADE DE CREDITO DIRETO S.A  6499999   \n",
      "\n",
      "                                  SecaoCNAEDescricao NotaPdd SAC_TIPO_PESSOA  \\\n",
      "0  OUTRAS ATIVIDADES DE SERVIÇOS FINANCEIROS NÃO ...      AA               J   \n",
      "1  OUTRAS ATIVIDADES DE SERVIÇOS FINANCEIROS NÃO ...      AA               J   \n",
      "2  OUTRAS ATIVIDADES DE SERVIÇOS FINANCEIROS NÃO ...      AA               J   \n",
      "3  OUTRAS ATIVIDADES DE SERVIÇOS FINANCEIROS NÃO ...      AA               J   \n",
      "4  OUTRAS ATIVIDADES DE SERVIÇOS FINANCEIROS NÃO ...      AA               J   \n",
      "\n",
      "    SacadoCnpjCpf  ... CampoAdicional2  CampoAdicional3 CampoAdicional4  \\\n",
      "0  504.105.391-04  ...             NaN              NaN             NaN   \n",
      "1  504.105.391-04  ...             NaN              NaN             NaN   \n",
      "2  775.326.783-34  ...             NaN              NaN             NaN   \n",
      "3  602.655.033-02  ...             NaN              NaN             NaN   \n",
      "4  602.655.033-02  ...             NaN              NaN             NaN   \n",
      "\n",
      "  CampoAdicional5 PDDEfeitoVagao PercentagemEfeitoVagao  \\\n",
      "0             NaN       424.0903                    1.0   \n",
      "1             NaN       504.5277                    1.0   \n",
      "2             NaN       315.1219                    1.0   \n",
      "3             NaN         0.0000                    0.0   \n",
      "4             NaN         0.0000                    0.0   \n",
      "\n",
      "   IdTituloVortxOriginador  Registradora  IdContratoRegistradora  \\\n",
      "0                 32759652           NaN                     NaN   \n",
      "1                 32759652           NaN                     NaN   \n",
      "2                 34747680           NaN                     NaN   \n",
      "3                        0           NaN                     NaN   \n",
      "4                        0           NaN                     NaN   \n",
      "\n",
      "   IdTituloRegistradora  \n",
      "0                   NaN  \n",
      "1                   NaN  \n",
      "2                   NaN  \n",
      "3                   NaN  \n",
      "4                   NaN  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "\n",
      "4. Nomes das colunas encontrados no arquivo:\n",
      "['Situacao', 'PES_TIPO_PESSOA', 'CedenteCnpjCpf', 'TIT_CEDENTE_ENT_CODIGO', 'CedenteNome', 'Cnae', 'SecaoCNAEDescricao', 'NotaPdd', 'SAC_TIPO_PESSOA', 'SacadoCnpjCpf', 'SacadoNome', 'IdTituloVortx', 'TipoAtivo', 'DataEmissao', 'DataAquisicao', 'DataVencimento', 'NumeroBoleto', 'NumeroTitulo', 'CampoChave', 'ValorAquisicao', 'ValorNominal', 'ValorPresente', 'PDDNota', 'PDDVencido', 'PagamentoParcial', 'Coobricacao', 'DataGeracao', 'PDDTotal', 'CampoAdicional1', 'CampoAdicional2', 'CampoAdicional3', 'CampoAdicional4', 'CampoAdicional5', 'PDDEfeitoVagao', 'PercentagemEfeitoVagao', 'IdTituloVortxOriginador', 'Registradora', 'IdContratoRegistradora', 'IdTituloRegistradora']\n",
      "\n",
      "5. Análise da coluna 'Situacao' (que será o nosso 'Status'):\n",
      "Valores únicos encontrados:\n",
      "['Sem cobrança' 'Aditado']\n",
      "\n",
      "6. Simulando o filtro que o script principal aplica...\n",
      "   - O script procura por status em: ['A vencer', 'Previsto', 'Vencido']\n",
      "   - Resultado: Após o filtro, restaram 0 linhas.\n",
      "\n",
      "------------------------------------------------------------------\n",
      ">>> DIAGNÓSTICO: O filtro de 'Status' está removendo todas as linhas.\n",
      "Os valores na coluna 'Situacao' do novo arquivo não correspondem a 'A vencer', 'Previsto' ou 'Vencido'.\n",
      "A solução é ajustar a lista 'status_a_incluir' no script principal para usar os valores corretos (ex: ['Sem cobrança']).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# depuracao apenas \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# --- CAMINHO PARA A PASTA COM OS NOVOS ARQUIVOS DE ESTOQUE ---\n",
    "PATH_ESTOQUE_NOVO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Estoques\"\n",
    "\n",
    "# --- BLOCO DE DEPURAÇÃO FOCADO NO ESTOQUE ---\n",
    "\n",
    "print(\"--- DEPURAÇÃO: Inspecionando o carregamento do Novo Estoque ---\")\n",
    "\n",
    "todos_arquivos = glob.glob(os.path.join(PATH_ESTOQUE_NOVO, '**/*.csv'), recursive=True)\n",
    "if not todos_arquivos:\n",
    "    print(\"ERRO: Nenhum arquivo de estoque (.csv) encontrado.\")\n",
    "else:\n",
    "    # 1. Encontra a data mais recente nos nomes dos arquivos\n",
    "    data_recente = None\n",
    "    regex_data = re.compile(r'(\\d{2}\\.\\d{2}\\.\\d{2})')\n",
    "    for arquivo in todos_arquivos:\n",
    "        match = regex_data.search(os.path.basename(arquivo))\n",
    "        if match:\n",
    "            data_str = match.group(1)\n",
    "            data_obj = datetime.strptime(data_str, '%d.%m.%y')\n",
    "            if data_recente is None or data_obj > data_recente:\n",
    "                data_recente = data_obj\n",
    "\n",
    "    if data_recente is None:\n",
    "        print(\"ERRO: Não foi possível determinar a data mais recente dos arquivos.\")\n",
    "    else:\n",
    "        data_recente_str = data_recente.strftime('%d.%m.%y')\n",
    "        print(f\"1. Usando o conjunto de estoque da data: {data_recente_str}\")\n",
    "        arquivos_para_ler = [f for f in todos_arquivos if data_recente_str in os.path.basename(f)]\n",
    "        \n",
    "        # 2. Lê e concatena as partes\n",
    "        lista_dfs_partes = []\n",
    "        for arquivo in arquivos_para_ler:\n",
    "            try:\n",
    "                df_parte = pd.read_csv(arquivo, sep=';', decimal=',', encoding='utf-8', on_bad_lines='warn')\n",
    "                lista_dfs_partes.append(df_parte)\n",
    "            except Exception as e:\n",
    "                print(f\"AVISO ao ler '{os.path.basename(arquivo)}': {e}\")\n",
    "        \n",
    "        if lista_dfs_partes:\n",
    "            df_consolidado = pd.concat(lista_dfs_partes, ignore_index=True)\n",
    "            print(f\"\\n2. Arquivos lidos e consolidados. Total de {len(df_consolidado)} linhas.\")\n",
    "            \n",
    "            print(\"\\n3. Amostra dos dados brutos (primeiras 5 linhas):\")\n",
    "            print(df_consolidado.head())\n",
    "            \n",
    "            print(\"\\n4. Nomes das colunas encontrados no arquivo:\")\n",
    "            print(df_consolidado.columns.tolist())\n",
    "\n",
    "            # 5. Inspeciona a coluna 'Situacao'\n",
    "            if 'Situacao' in df_consolidado.columns:\n",
    "                print(\"\\n5. Análise da coluna 'Situacao' (que será o nosso 'Status'):\")\n",
    "                print(\"Valores únicos encontrados:\")\n",
    "                print(df_consolidado['Situacao'].unique())\n",
    "            else:\n",
    "                print(\"\\n5. ALERTA: A coluna 'Situacao' não foi encontrada!\")\n",
    "\n",
    "            # 6. Simula o filtro do script principal\n",
    "            print(\"\\n6. Simulando o filtro que o script principal aplica...\")\n",
    "            \n",
    "            # Renomeia Situacao -> Status para o teste\n",
    "            df_teste = df_consolidado.rename(columns={'Situacao': 'Status'})\n",
    "            \n",
    "            status_a_incluir = ['A vencer', 'Previsto', 'Vencido']\n",
    "            print(f\"   - O script procura por status em: {status_a_incluir}\")\n",
    "            \n",
    "            df_filtrado = df_teste[df_teste['Status'].isin(status_a_incluir)]\n",
    "            \n",
    "            print(f\"   - Resultado: Após o filtro, restaram {len(df_filtrado)} linhas.\")\n",
    "            \n",
    "            print(\"\\n------------------------------------------------------------------\")\n",
    "            if len(df_filtrado) == 0:\n",
    "                print(\">>> DIAGNÓSTICO: O filtro de 'Status' está removendo todas as linhas.\")\n",
    "                print(\"Os valores na coluna 'Situacao' do novo arquivo não correspondem a 'A vencer', 'Previsto' ou 'Vencido'.\")\n",
    "                print(\"A solução é ajustar a lista 'status_a_incluir' no script principal para usar os valores corretos (ex: ['Sem cobrança']).\")\n",
    "            else:\n",
    "                 print(\">>> DIAGNÓSTICO: O filtro de 'Status' está funcionando. O problema pode estar na conversão das datas ou valores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9faf0b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conta Corr.</th>\n",
       "      <th>Fundo inv.</th>\n",
       "      <th>Títulos Renda Fixa</th>\n",
       "      <th>Pagamentos Estoque</th>\n",
       "      <th>Despesas</th>\n",
       "      <th>Amort./ Resgat. Cota</th>\n",
       "      <th>Disponibilidades</th>\n",
       "      <th>Necessidades</th>\n",
       "      <th>Caixa Projetado</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prazo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D+0</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13,448,387.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13,449,387.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13,449,387.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D+1</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>440,304.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13,500,473.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13,941,777.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13,941,777.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D+5</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>440,304.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13,728,677.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14,169,982.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14,169,982.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D+10</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>440,304.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14,060,107.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14,501,411.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14,501,411.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D+21</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>440,304.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16,929,321.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17,370,625.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17,370,625.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D+63</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>440,304.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27,287,355.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27,728,659.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27,728,659.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D+365</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>440,304.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87,195,087.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-24,845,090.89</td>\n",
       "      <td>87,636,392.25</td>\n",
       "      <td>-24,845,090.89</td>\n",
       "      <td>62,791,301.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D+730</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>440,304.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135,929,948.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-62,112,727.22</td>\n",
       "      <td>136,371,253.48</td>\n",
       "      <td>-62,112,727.22</td>\n",
       "      <td>74,258,526.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D+1200</th>\n",
       "      <td>1,000.00</td>\n",
       "      <td>440,304.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>174,807,393.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-108,697,272.64</td>\n",
       "      <td>175,248,698.54</td>\n",
       "      <td>-108,697,272.64</td>\n",
       "      <td>66,551,425.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Conta Corr.  Fundo inv. Títulos Renda Fixa Pagamentos Estoque Despesas  \\\n",
       "Prazo                                                                           \n",
       "D+0       1,000.00        0.00               0.00      13,448,387.14     0.00   \n",
       "D+1       1,000.00  440,304.72               0.00      13,500,473.05     0.00   \n",
       "D+5       1,000.00  440,304.72               0.00      13,728,677.28     0.00   \n",
       "D+10      1,000.00  440,304.72               0.00      14,060,107.05     0.00   \n",
       "D+21      1,000.00  440,304.72               0.00      16,929,321.16     0.00   \n",
       "D+63      1,000.00  440,304.72               0.00      27,287,355.18     0.00   \n",
       "D+365     1,000.00  440,304.72               0.00      87,195,087.53     0.00   \n",
       "D+730     1,000.00  440,304.72               0.00     135,929,948.76     0.00   \n",
       "D+1200    1,000.00  440,304.72               0.00     174,807,393.82     0.00   \n",
       "\n",
       "       Amort./ Resgat. Cota Disponibilidades     Necessidades Caixa Projetado  \n",
       "Prazo                                                                          \n",
       "D+0                    0.00    13,449,387.14             0.00   13,449,387.14  \n",
       "D+1                    0.00    13,941,777.77             0.00   13,941,777.77  \n",
       "D+5                    0.00    14,169,982.00             0.00   14,169,982.00  \n",
       "D+10                   0.00    14,501,411.77             0.00   14,501,411.77  \n",
       "D+21                   0.00    17,370,625.88             0.00   17,370,625.88  \n",
       "D+63                   0.00    27,728,659.90             0.00   27,728,659.90  \n",
       "D+365        -24,845,090.89    87,636,392.25   -24,845,090.89   62,791,301.36  \n",
       "D+730        -62,112,727.22   136,371,253.48   -62,112,727.22   74,258,526.26  \n",
       "D+1200      -108,697,272.64   175,248,698.54  -108,697,272.64   66,551,425.90  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(relatorio_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9da6d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- FUNÇÃO DE PREPARAÇÃO DE FLUXOS (COM DESCRIÇÃO DETALHADA) ---\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    \"\"\"Cria uma lista de TODOS os eventos de fluxo de caixa, com descrição detalhada para cada um.\"\"\"\n",
    "    fluxos = []\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "\n",
    "    # Disponibilidades\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade:\n",
    "        fluxos.append({'data': data_base, 'categoria': 'Conta Corr.', 'valor': disponibilidade['ativos'][0]['saldo'], 'descricao': 'Saldo Inicial'})\n",
    "\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        for cota in cotas['ativos']:\n",
    "            fluxos.append({'data': data_base + timedelta(days=1), 'categoria': 'Fundo inv.', 'valor': cota['valorBruto'], 'descricao': f\"Resgate {cota.get('titulo', 'Fundo')}\"})\n",
    "            \n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        for titulo in renda_fixa['ativos']:\n",
    "            fluxos.append({'data': datetime.strptime(titulo['dataVencimento'], '%Y-%m-%d'), 'categoria': 'Títulos Renda Fixa', 'valor': titulo['mercadoAtual'], 'descricao': f\"Venc. {titulo.get('codigoCustodia', 'Título RF')}\"})\n",
    "\n",
    "    # Pagamentos do Estoque\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Presente'])\n",
    "        estoque_futuro = estoque_valido[estoque_valido['Data Vencimento'] >= data_base]\n",
    "        for _, row in estoque_futuro.iterrows():\n",
    "            fluxos.append({'data': row['Data Vencimento'], 'categoria': 'Pagamentos Estoque', 'valor': row['Valor Presente'], 'descricao': f\"Título Nº {row.get('NumeroTitulo', 'N/A')}\"})\n",
    "\n",
    "    # Necessidades\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base]\n",
    "        for _, despesa in despesas_futuras.iterrows():\n",
    "            fluxos.append({'data': despesa['Data Pagamento'], 'categoria': 'Despesas', 'valor': despesa['Valor'], 'descricao': despesa['Categoria']})\n",
    "            \n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        data_amortizacao = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_amortizacao + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5: data_pagamento += pd.Timedelta(days=1)\n",
    "            fluxos.append({'data': data_pagamento, 'categoria': 'Amort./ Resgat. Cota', 'valor': valor_amortizacao, 'descricao': f\"Parcela {i+1}/36\"})\n",
    "            \n",
    "    return pd.DataFrame(fluxos)\n",
    "\n",
    "\n",
    "df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049fb45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procurando o arquivo de carteira mais recente...\n",
      "Usando a carteira mais recente para a projeção: carteira_52203615000119_20250930.json\n",
      "\n",
      "Carregando dados do novo estoque...\n",
      "Usando o conjunto de estoque da data: 30.09.25\n",
      "Dados do novo estoque consolidados: 1724011 linhas.\n",
      "\n",
      "Carregando despesas com a lógica final...\n",
      "Usando o relatório de despesas gerado em: 30/09/2025\n",
      "52 eventos de despesas futuras (reais + projetadas) foram criados.\n",
      "\n",
      "1669666 parcelas do estoque com vencimento futuro foram incluídas na projeção.\n",
      "✅ Relatório HTML interativo (versão leve) gerado com sucesso: 'c:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\relatorio_fluxo_caixa_final.html'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\AppData\\Local\\Temp\\ipykernel_14628\\3610487332.py:252: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_summary_formatted = df_summary.applymap('{:,.2f}'.format)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import base64\n",
    "\n",
    "# --- CAMINHOS E CONFIGURAÇÕES FINAIS ---\n",
    "PATH_CARTEIRAS_HISTORICO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Carteiras\"\n",
    "PATH_ESTOQUE_NOVO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Estoques\"\n",
    "PATH_DESPESAS = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\src\\vortx_estoques\\data\\Despesas\"\n",
    "CAMINHO_DO_LOGO = r\"C:\\Users\\Leo\\Desktop\\Porto_Real\\portoauto\\images\\logo_inv.png\" \n",
    "NOME_DO_FUNDO = \"FIDC FCT CONSIGNADO II\"\n",
    "NOME_ARQUIVO_SAIDA = \"relatorio_fluxo_caixa_final.html\"\n",
    "\n",
    "# --- FUNÇÕES DE CARREGAMENTO FINAIS ---\n",
    "\n",
    "def encontrar_e_carregar_carteira_recente(caminho_pasta):\n",
    "    \"\"\"Encontra o arquivo de carteira mais recente pela data interna e carrega seus dados.\"\"\"\n",
    "    print(\"Procurando o arquivo de carteira mais recente...\")\n",
    "    arquivos_json = glob.glob(os.path.join(caminho_pasta, \"*.json\"))\n",
    "    if not arquivos_json: return None, None, None\n",
    "    arquivo_mais_recente, data_mais_recente = None, None\n",
    "    for arquivo in arquivos_json:\n",
    "        try:\n",
    "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                dados = json.load(f)\n",
    "                data_atual_str = dados[0]['carteiras'][0]['dataAtual']\n",
    "                data_atual_obj = datetime.strptime(data_atual_str.split('T')[0], '%Y-%m-%d')\n",
    "                if data_mais_recente is None or data_atual_obj > data_mais_recente:\n",
    "                    data_mais_recente, arquivo_mais_recente = data_atual_obj, arquivo\n",
    "        except Exception: continue\n",
    "    if arquivo_mais_recente:\n",
    "        print(f\"Usando a carteira mais recente para a projeção: {os.path.basename(arquivo_mais_recente)}\")\n",
    "        with open(arquivo_mais_recente, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)[0], data_mais_recente, os.path.basename(arquivo_mais_recente)\n",
    "    return None, None, None\n",
    "\n",
    "def processar_dados_estoque_novo(caminho_pasta):\n",
    "    \"\"\"Lê o conjunto de arquivos de estoque mais recente da pasta e o prepara para a análise.\"\"\"\n",
    "    print(\"\\nCarregando dados do novo estoque...\")\n",
    "    todos_arquivos = glob.glob(os.path.join(caminho_pasta, '**/*.csv'), recursive=True)\n",
    "    if not todos_arquivos: return pd.DataFrame()\n",
    "    data_recente = None\n",
    "    regex_data = re.compile(r'(\\d{2}\\.\\d{2}\\.\\d{2})')\n",
    "    for arquivo in todos_arquivos:\n",
    "        match = regex_data.search(os.path.basename(arquivo))\n",
    "        if match:\n",
    "            data_obj = datetime.strptime(match.group(1), '%d.%m.%y')\n",
    "            if data_recente is None or data_obj > data_recente: data_recente = data_obj\n",
    "    if data_recente is None: return pd.DataFrame()\n",
    "    data_recente_str = data_recente.strftime('%d.%m.%y')\n",
    "    print(f\"Usando o conjunto de estoque da data: {data_recente_str}\")\n",
    "    arquivos_para_ler = [f for f in todos_arquivos if data_recente_str in os.path.basename(f)]\n",
    "    lista_dfs_partes = []\n",
    "    for arquivo in arquivos_para_ler:\n",
    "        try:\n",
    "            df_parte = pd.read_csv(arquivo, sep=';', decimal=',', encoding='utf-8', on_bad_lines='warn')\n",
    "            lista_dfs_partes.append(df_parte)\n",
    "        except Exception: continue\n",
    "    if not lista_dfs_partes: return pd.DataFrame()\n",
    "    df_consolidado = pd.concat(lista_dfs_partes, ignore_index=True)\n",
    "    df_consolidado.rename(columns={\n",
    "        'DataVencimento': 'Data Vencimento', \n",
    "        'ValorPresente': 'Valor Presente',\n",
    "        'ValorNominal': 'Valor Nominal'  # Adiciona o Valor Nominal\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Converte as colunas de data e valor\n",
    "    df_consolidado['Data Vencimento'] = pd.to_datetime(df_consolidado['Data Vencimento'], dayfirst=True, errors='coerce')\n",
    "    df_consolidado['Valor Presente'] = pd.to_numeric(df_consolidado['Valor Presente'], errors='coerce')\n",
    "    \n",
    "    # ### ALTERAÇÃO AQUI: Converte também o Valor Nominal ###\n",
    "    df_consolidado['Valor Nominal'] = pd.to_numeric(df_consolidado['Valor Nominal'], errors='coerce')\n",
    "    \n",
    "    print(f\"Dados do novo estoque consolidados: {len(df_consolidado)} linhas.\")\n",
    "    return df_consolidado\n",
    "\n",
    "def processar_dados_despesas_final(caminho_pasta, data_base_projecao, meses_a_projetar=12):\n",
    "    \"\"\"Encontra o relatório de despesas mais recente e projeta suas provisões para o futuro.\"\"\"\n",
    "    print(\"\\nCarregando despesas com a lógica final...\")\n",
    "    arquivos_excel = glob.glob(os.path.join(caminho_pasta, '**/Despesas_Consolidadas.xlsx'), recursive=True)\n",
    "    if not arquivos_excel: return pd.DataFrame(), None\n",
    "    df_mais_recente, data_relatorio_recente = None, None\n",
    "    for arquivo in arquivos_excel:\n",
    "        try:\n",
    "            df_temp = pd.read_excel(arquivo, header=6)\n",
    "            df_temp['Data'] = pd.to_datetime(df_temp['Data'], errors='coerce', dayfirst=True)\n",
    "            data_atual = df_temp['Data'].max()\n",
    "            if data_relatorio_recente is None or data_atual > data_relatorio_recente:\n",
    "                data_relatorio_recente, df_mais_recente = data_atual, df_temp\n",
    "        except Exception: continue\n",
    "    if df_mais_recente is None: return pd.DataFrame(), None\n",
    "    print(f\"Usando o relatório de despesas gerado em: {data_relatorio_recente.strftime('%d/%m/%Y')}\")\n",
    "    df_base = df_mais_recente.rename(columns={'Título': 'Categoria', 'Valor Mercado': 'Valor'})\n",
    "    df_base['Valor'] = -pd.to_numeric(df_base['Valor'], errors='coerce').abs()\n",
    "    df_base['Data Pagamento'] = pd.to_datetime(df_base['Data Pagamento'], errors='coerce', dayfirst=True)\n",
    "    df_base = df_base[['Categoria', 'Valor', 'Data Pagamento']].dropna()\n",
    "    despesas_finais = []\n",
    "    despesas_reais_futuras = df_base[df_base['Data Pagamento'] >= data_base_projecao]\n",
    "    despesas_finais.extend(despesas_reais_futuras.to_dict('records'))\n",
    "    mes_inicial_projecao = (data_base_projecao.replace(day=1) + relativedelta(months=1))\n",
    "    for i in range(meses_a_projetar):\n",
    "        mes_atual = mes_inicial_projecao + relativedelta(months=i)\n",
    "        data_pagamento_proj = mes_atual.replace(day=5)\n",
    "        while data_pagamento_proj.weekday() >= 5: data_pagamento_proj += timedelta(days=1)\n",
    "        if data_pagamento_proj >= data_base_projecao:\n",
    "            for _, row in df_base.iterrows():\n",
    "                despesas_finais.append({'Data Pagamento': data_pagamento_proj, 'Categoria': row['Categoria'], 'Valor': row['Valor']})\n",
    "    df_final = pd.DataFrame(despesas_finais)\n",
    "    print(f\"{len(df_final)} eventos de despesas futuras (reais + projetadas) foram criados.\")\n",
    "    return df_final, data_relatorio_recente\n",
    "\n",
    "def preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas_datadas):\n",
    "    \"\"\"\n",
    "    Cria uma lista de TODOS os eventos de fluxo de caixa, com descrição detalhada para cada um.\n",
    "    VERSÃO VETORIZADA para maior eficiência.\n",
    "    \"\"\"\n",
    "    data_base = datetime.strptime(dados_carteira_recente['carteiras'][0]['dataAtual'].split('T')[0], '%Y-%m-%d')\n",
    "    \n",
    "    # Lista para armazenar os DataFrames de cada categoria de fluxo\n",
    "    lista_de_fluxos_df = []\n",
    "\n",
    "    # --- Disponibilidades ---\n",
    "    \n",
    "    # 1. Conta Corrente e Fundo Investido (geralmente poucos itens, vetorização simples)\n",
    "    disponibilidade = next((a.get('Disponibilidade') for a in dados_carteira_recente['ativos'] if a.get('Disponibilidade')), None)\n",
    "    if disponibilidade:\n",
    "        df_cc = pd.DataFrame([{\n",
    "            'data': data_base, 'categoria': 'Conta Corr.', \n",
    "            'valor': disponibilidade['ativos'][0]['saldo'], 'descricao': 'Saldo Inicial'\n",
    "        }])\n",
    "        lista_de_fluxos_df.append(df_cc)\n",
    "\n",
    "    cotas = next((a.get('Cotas') for a in dados_carteira_recente['ativos'] if a.get('Cotas')), None)\n",
    "    if cotas:\n",
    "        df_fundos = pd.DataFrame(cotas['ativos'])\n",
    "        df_fundos['data'] = data_base # Alterado para D+0 conforme solicitado\n",
    "        df_fundos['categoria'] = 'Fundo inv.'\n",
    "        df_fundos['valor'] = df_fundos['valorBruto']\n",
    "        df_fundos['descricao'] = \"Resgate \" + df_fundos['titulo']\n",
    "        lista_de_fluxos_df.append(df_fundos[['data', 'categoria', 'valor', 'descricao']])\n",
    "\n",
    "    # 2. Renda Fixa\n",
    "    renda_fixa = next((a.get('RendaFixa') for a in dados_carteira_recente['ativos'] if a.get('RendaFixa')), None)\n",
    "    if renda_fixa:\n",
    "        df_rf = pd.DataFrame(renda_fixa['ativos'])\n",
    "        df_rf['data'] = pd.to_datetime(df_rf['dataVencimento'])\n",
    "        df_rf['categoria'] = 'Títulos Renda Fixa'\n",
    "        df_rf['valor'] = df_rf['mercadoAtual']\n",
    "        df_rf['descricao'] = \"Venc. \" + df_rf['codigoCustodia']\n",
    "        lista_de_fluxos_df.append(df_rf[['data', 'categoria', 'valor', 'descricao']])\n",
    "\n",
    "    # 3. Pagamentos do Estoque (onde a vetorização faz mais diferença)\n",
    "    if not df_estoque.empty:\n",
    "        estoque_valido = df_estoque.dropna(subset=['Data Vencimento', 'Valor Nominal'])\n",
    "        estoque_futuro = estoque_valido[estoque_valido['Data Vencimento'] >= data_base].copy()\n",
    "        \n",
    "        print(f\"\\n{len(estoque_futuro)} parcelas do estoque com vencimento futuro foram incluídas na projeção.\")\n",
    "        \n",
    "        # Operações vetorizadas: criar e modificar colunas inteiras de uma vez\n",
    "        estoque_futuro['categoria'] = 'Pagamentos Estoque'\n",
    "        estoque_futuro['descricao'] = \"Título Nº \" + estoque_futuro['NumeroTitulo'].astype(str)\n",
    "        \n",
    "        # Renomeia as colunas para o formato final, selecionando apenas o que precisamos\n",
    "        df_estoque_final = estoque_futuro.rename(columns={'Data Vencimento': 'data', 'Valor Nominal': 'valor'})\n",
    "        lista_de_fluxos_df.append(df_estoque_final[['data', 'categoria', 'valor', 'descricao']])\n",
    "\n",
    "    # --- Necessidades ---\n",
    "\n",
    "    # 4. Despesas\n",
    "    if not df_despesas_datadas.empty:\n",
    "        despesas_futuras = df_despesas_datadas[df_despesas_datadas['Data Pagamento'] >= data_base].copy()\n",
    "        despesas_futuras['categoria'] = 'Despesas'\n",
    "        despesas_futuras['descricao'] = despesas_futuras['Categoria'] # Usa a categoria original como descrição\n",
    "        df_despesas_final = despesas_futuras.rename(columns={'Data Pagamento': 'data', 'Valor': 'valor'})\n",
    "        lista_de_fluxos_df.append(df_despesas_final[['data', 'categoria', 'valor', 'descricao']])\n",
    "\n",
    "    # 5. Amortização de Cotas\n",
    "    carteira_senior = next((c for c in dados_carteira_recente['carteiras'] if 'SR2' in c['nome']), None)\n",
    "    if carteira_senior:\n",
    "        pl_senior = carteira_senior['pl']\n",
    "        valor_amortizacao = (pl_senior / 36) * -1\n",
    "        \n",
    "        # Gera a lista de datas e descrições primeiro\n",
    "        datas_amortizacao = []\n",
    "        descricoes_amortizacao = []\n",
    "        data_base_amort = datetime(2026, 1, 16)\n",
    "        for i in range(36):\n",
    "            data_pagamento = data_base_amort + relativedelta(months=i)\n",
    "            while data_pagamento.weekday() >= 5:\n",
    "                data_pagamento += pd.Timedelta(days=1)\n",
    "            datas_amortizacao.append(data_pagamento)\n",
    "            descricoes_amortizacao.append(f\"Parcela {i+1}/36\")\n",
    "            \n",
    "        # Cria o DataFrame de uma só vez\n",
    "        df_amort = pd.DataFrame({\n",
    "            'data': datas_amortizacao,\n",
    "            'categoria': 'Amort./ Resgat. Cota',\n",
    "            'valor': valor_amortizacao,\n",
    "            'descricao': descricoes_amortizacao\n",
    "        })\n",
    "        lista_de_fluxos_df.append(df_amort)\n",
    "    \n",
    "    # Concatena todos os DataFrames de uma vez no final\n",
    "    if not lista_de_fluxos_df:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    return pd.concat(lista_de_fluxos_df, ignore_index=True)\n",
    "\n",
    "def gerar_relatorio_d_mais(df_fluxos, data_base):\n",
    "    \"\"\"Gera a tabela de resumo no formato D+N.\"\"\"\n",
    "    prazos = [0, 1, 5, 10, 21, 63, 365]\n",
    "    colunas_relatorio = ['Conta Corr.', 'Fundo inv.', 'Títulos Renda Fixa', 'Pagamentos Estoque', 'Despesas', 'Amort./ Resgat. Cota']\n",
    "    linhas_relatorio = []\n",
    "    for dias in prazos:\n",
    "        data_limite = data_base + timedelta(days=dias)\n",
    "        fluxos_ate_data = df_fluxos[df_fluxos['data'] <= data_limite]\n",
    "        saldos_acumulados = fluxos_ate_data.groupby('categoria')['valor'].sum()\n",
    "        linha = {'Prazo': f\"D+{dias}\"}\n",
    "        for col in colunas_relatorio: linha[col] = saldos_acumulados.get(col, 0.0)\n",
    "        linhas_relatorio.append(linha)\n",
    "    df_relatorio = pd.DataFrame(linhas_relatorio).set_index('Prazo')\n",
    "    df_relatorio['Disponibilidades'] = df_relatorio[colunas_relatorio[:4]].sum(axis=1)\n",
    "    df_relatorio['Necessidades'] = df_relatorio[colunas_relatorio[4:]].sum(axis=1)\n",
    "    df_relatorio['Caixa Projetado'] = df_relatorio['Disponibilidades'] + df_relatorio['Necessidades']\n",
    "    return df_relatorio # Retorna o DataFrame com números para a função de HTML\n",
    "\n",
    "def codificar_imagem_base64(caminho_imagem):\n",
    "    try:\n",
    "        with open(caminho_imagem, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        return \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\"\n",
    "\n",
    "def gerar_relatorio_html_final(df_summary, df_details, nome_fundo, data_ref, caminho_logo, arquivo_saida):\n",
    "    \"\"\"\n",
    "    Gera o arquivo HTML final, com detalhamento para todas as categorias,\n",
    "    EXCETO para 'Pagamentos Estoque' para manter o arquivo leve.\n",
    "    \"\"\"\n",
    "    logo_base64 = codificar_imagem_base64(caminho_logo)\n",
    "    \n",
    "    # Prepara os dados detalhados (excluindo o estoque)\n",
    "    df_details_leve = df_details[df_details['categoria'] != 'Pagamentos Estoque'].copy()\n",
    "    df_details_leve['data'] = pd.to_datetime(df_details_leve['data'], errors='coerce')\n",
    "    df_details_leve.dropna(subset=['data'], inplace=True)\n",
    "    df_details_leve['data'] = df_details_leve['data'].dt.strftime('%d/%m/%Y')\n",
    "    dados_detalhados_json = df_details_leve.to_json(orient='records', force_ascii=False)\n",
    "\n",
    "    df_summary_formatted = df_summary.applymap('{:,.2f}'.format)\n",
    "    tabela_html = '<table id=\"relatorioTabela\" class=\"display compact\"><thead><tr><th>Prazo</th>'\n",
    "    for col in df_summary_formatted.columns:\n",
    "        tabela_html += f'<th>{col}</th>'\n",
    "    tabela_html += '</tr></thead><tbody>'\n",
    "    for prazo, row in df_summary_formatted.iterrows():\n",
    "        tabela_html += f'<tr><th>{prazo}</th>'\n",
    "        for col, value in row.items():\n",
    "            tabela_html += f'<td data-prazo=\"{prazo}\" data-categoria=\"{col}\">{value}</td>'\n",
    "        tabela_html += '</tr>'\n",
    "    tabela_html += '</tbody></table>'\n",
    "\n",
    "    html_template = f\"\"\"\n",
    "    <!DOCTYPE html><html lang=\"pt-BR\"><head><meta charset=\"UTF-8\"><title>Relatório de Fluxo de Caixa Interativo</title>\n",
    "    <link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css\">\n",
    "    <style>\n",
    "        body {{ font-family: \"Gill Sans MT\", Arial, sans-serif; background-color: #FFFFFF; color: #313131; font-size: 1.1em; padding: 20px; }}\n",
    "        h1 {{ font-size: 2.2em; color: #163f3f; margin: 0; }} .header-container {{ display: flex; align-items: center; margin-bottom: 20px; }}\n",
    "        .info-box {{ border: 1px solid #e0e0e0; background-color: #f5f5f5; padding: 15px; margin-bottom: 30px; }}\n",
    "        table.dataTable thead th {{ background-color: #163f3f !important; color: white !important; }}\n",
    "        table.dataTable.display tbody tr.odd {{ background-color: #f5f5f5; }} table.dataTable.display tbody tr.even {{ background-color: #e0e0e0; }}\n",
    "        table.dataTable tbody tr:hover {{ background-color: #FFD8A7 !important; }} table.dataTable tbody th {{ font-weight: bold; background-color: #0e3030; color: white; }}\n",
    "        \n",
    "        /* Modificação: O cursor só vira 'pointer' para células que não são do estoque */\n",
    "        #relatorioTabela tbody td[data-categoria=\"Pagamentos Estoque\"] {{ cursor: default; }}\n",
    "        #relatorioTabela tbody td:not([data-categoria=\"Pagamentos Estoque\"]):not(:empty) {{ cursor: pointer; }}\n",
    "\n",
    "        .modal {{ display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgba(0,0,0,0.5); }}\n",
    "        .modal-content {{ background-color: #fefefe; margin: 5% auto; padding: 20px; border: 1px solid #888; width: 80%; max-width: 900px; }}\n",
    "        .close-button {{ color: #aaa; float: right; font-size: 28px; font-weight: bold; cursor: pointer; }}\n",
    "        #modal-table-container table {{ width: 100%; border-collapse: collapse; }} #modal-table-container th, #modal-table-container td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "        #modal-table-container th {{ background-color: #f2f2f2; }}\n",
    "    </style></head><body>\n",
    "    <div class=\"header-container\"><img src=\"data:image/png;base64,{logo_base64}\" style=\"max-height:80px; margin-right:20px;\"><h1>Relatório de Fluxo de Caixa Interativo</h1></div>\n",
    "    <div class=\"info-box\"><strong>Fundo:</strong> {nome_fundo}<br><strong>Data do Relatório:</strong> {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}<br><strong>Data de Referência (D+0):</strong> {data_ref.strftime('%d/%m/%Y')}</div>\n",
    "    {tabela_html}\n",
    "    <div id=\"detailModal\" class=\"modal\"><div class=\"modal-content\"><span class=\"close-button\">&times;</span><h2 id=\"modal-title\">Detalhamento</h2><div id=\"modal-table-container\" style=\"max-height: 400px; overflow-y: auto;\"></div></div></div>\n",
    "    <script src=\"https://code.jquery.com/jquery-3.7.0.js\"></script><script src=\"https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js\"></script>\n",
    "    <script>var dadosDetalhados = {dados_detalhados_json}; var dataReferencia = new Date('{data_ref.strftime(\"%Y-%m-%d\")}T00:00:00');</script>\n",
    "    <script>\n",
    "    $(document).ready(function() {{\n",
    "        $('#relatorioTabela').DataTable({{ \"paging\": false, \"searching\": false, \"info\": false, \"ordering\": false }});\n",
    "        var modal = $('#detailModal');\n",
    "        $('#relatorioTabela tbody').on('click', 'td', function() {{\n",
    "            var cell = $(this); var prazo = cell.data('prazo'); var categoria = cell.data('categoria');\n",
    "\n",
    "            // ### A CORREÇÃO ESTÁ AQUI ###\n",
    "            // Ignora o clique se for uma coluna de resumo, vazia, ou a coluna de Estoque\n",
    "            if (!prazo || !categoria || \n",
    "                ['Disponibilidades', 'Necessidades', 'Caixa Projetado', 'Pagamentos Estoque'].includes(categoria) || \n",
    "                cell.text().trim() === '0.00' || cell.text().trim() === '0,00') \n",
    "            {{\n",
    "                return;\n",
    "            }}\n",
    "\n",
    "            var dias = parseInt(prazo.replace('D+', '')); var dataLimite = new Date(dataReferencia); dataLimite.setDate(dataLimite.getDate() + dias);\n",
    "            var itensFiltrados = dadosDetalhados.filter(function(item) {{\n",
    "                var dataItem = new Date(item.data.split('/').reverse().join('-') + 'T00:00:00');\n",
    "                return item.categoria === categoria && dataItem <= dataLimite;\n",
    "            }});\n",
    "            var tableHtml = '<table><thead><tr><th>Data</th><th>Descrição</th><th style=\"text-align:right;\">Valor</th></tr></thead><tbody>';\n",
    "            var total = 0;\n",
    "            itensFiltrados.forEach(function(item) {{\n",
    "                total += item.valor;\n",
    "                tableHtml += '<tr><td>' + item.data + '</td><td>' + (item.descricao || '') + '</td><td style=\"text-align:right;\">' + item.valor.toLocaleString('pt-BR', {{style: 'currency', currency: 'BRL'}}) + '</td></tr>';\n",
    "            }});\n",
    "            tableHtml += '</tbody><tfoot><tr><th colspan=\"2\">Total</th><th style=\"text-align:right;\">' + total.toLocaleString('pt-BR', {{style: 'currency', currency: 'BRL'}}) + '</th></tr></tfoot></table>';\n",
    "            $('#modal-title').text('Detalhamento de: ' + categoria + ' (até ' + prazo + ')');\n",
    "            $('#modal-table-container').html(tableHtml);\n",
    "            modal.show();\n",
    "        }});\n",
    "        $('.close-button').on('click', function() {{ modal.hide(); }});\n",
    "        $(window).on('click', function(event) {{ if (event.target == modal[0]) modal.hide(); }});\n",
    "    }});\n",
    "    </script></body></html>\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(arquivo_saida, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_template)\n",
    "        print(f\"✅ Relatório HTML interativo (versão leve) gerado com sucesso: '{os.path.abspath(arquivo_saida)}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao salvar o arquivo HTML: {e}\")\n",
    "\n",
    "\n",
    "# --- BLOCO DE EXECUÇÃO FINAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    dados_carteira_recente, data_referencia, _ = encontrar_e_carregar_carteira_recente(PATH_CARTEIRAS_HISTORICO)\n",
    "    if dados_carteira_recente:\n",
    "        df_estoque = processar_dados_estoque_novo(PATH_ESTOQUE_NOVO)\n",
    "        df_despesas, _ = processar_dados_despesas_final(PATH_DESPESAS, data_referencia)\n",
    "        df_fluxos_detalhados = preparar_fluxos_detalhados(dados_carteira_recente, df_estoque, df_despesas)\n",
    "        relatorio_final = gerar_relatorio_d_mais(df_fluxos_detalhados, data_referencia)\n",
    "        gerar_relatorio_html_final(relatorio_final, df_fluxos_detalhados, NOME_DO_FUNDO, data_referencia, CAMINHO_DO_LOGO, NOME_ARQUIVO_SAIDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d914f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Situacao', 'PES_TIPO_PESSOA', 'CedenteCnpjCpf',\n",
       "       'TIT_CEDENTE_ENT_CODIGO', 'CedenteNome', 'Cnae', 'SecaoCNAEDescricao',\n",
       "       'NotaPdd', 'SAC_TIPO_PESSOA', 'SacadoCnpjCpf', 'SacadoNome',\n",
       "       'IdTituloVortx', 'TipoAtivo', 'DataEmissao', 'DataAquisicao',\n",
       "       'Data Vencimento', 'NumeroBoleto', 'NumeroTitulo', 'CampoChave',\n",
       "       'ValorAquisicao', 'Valor Nominal', 'Valor Presente', 'PDDNota',\n",
       "       'PDDVencido', 'PagamentoParcial', 'Coobricacao', 'DataGeracao',\n",
       "       'PDDTotal', 'CampoAdicional1', 'CampoAdicional2', 'CampoAdicional3',\n",
       "       'CampoAdicional4', 'CampoAdicional5', 'PDDEfeitoVagao',\n",
       "       'PercentagemEfeitoVagao', 'IdTituloVortxOriginador', 'Registradora',\n",
       "       'IdContratoRegistradora', 'IdTituloRegistradora'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estoque.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4ff876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          424.0903\n",
       "1          504.5277\n",
       "2          315.1219\n",
       "3            0.0000\n",
       "4            0.0000\n",
       "             ...   \n",
       "1644299      0.0000\n",
       "1644300      0.0000\n",
       "1644301      0.0000\n",
       "1644302      0.0000\n",
       "1644303      0.0000\n",
       "Name: PDDTotal, Length: 1644304, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estoque[\"PDDTotal\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
